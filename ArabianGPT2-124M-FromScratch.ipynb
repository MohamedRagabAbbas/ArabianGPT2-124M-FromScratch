{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXIy2V4Js8XT",
        "outputId": "3c976ee9-eb3e-44ec-fc24-1b77ba9de5ab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PsXTv7NlkWSt"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, set_seed\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import tiktoken\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 3e-4\n",
        "num_epochs = 10\n",
        "top = 1000000\n",
        "dropout_rate: float = 0.1"
      ],
      "metadata": {
        "id": "JL_LjFHfkqy3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_device():\n",
        "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "j10O6ZHBkv2-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class GPT2Config:\n",
        "    block_size: int = 0\n",
        "    vocab_size: int = 0\n",
        "    n_embd: int = 0\n",
        "    n_layer: int = 0\n",
        "    n_head: int = 0"
      ],
      "metadata": {
        "id": "w_437veGkwN_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q,k,v,mask=None):\n",
        "    d_k = q.size(-1)\n",
        "    qk = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        qk = qk.permute(1, 0, 2, 3) + mask\n",
        "        qk = qk.permute(1, 0, 2, 3)\n",
        "    qk = F.softmax(qk, dim=-1)\n",
        "    new_qkv = torch.matmul(qk, v)\n",
        "    return new_qkv\n",
        "\n",
        "class Multihead_Self_Attention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(Multihead_Self_Attention, self).__init__()\n",
        "        self.n_embd = config.n_embd\n",
        "        self.n_head = config.n_head\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.std_scaler = 1\n",
        "\n",
        "    def forward(self,x,mask=None):\n",
        "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
        "        qkv = self.c_attn(x)\n",
        "        q, k, v = qkv.split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True) # flash attention\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
        "        y = self.c_proj(y)\n",
        "        return y"
      ],
      "metadata": {
        "id": "YFmok2nSkybf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class mlp(nn.Module):\n",
        "    def __init__(self,config):\n",
        "        super(mlp,self).__init__()\n",
        "        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd)\n",
        "        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd)\n",
        "        self.activation = nn.GELU(approximate='tanh')\n",
        "        self.std_scaler = 1\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.c_fc(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.c_proj(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "B-DJ__fCkzau"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self,config):\n",
        "        super(Block, self).__init__()\n",
        "        self.attn = Multihead_Self_Attention(config)\n",
        "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
        "        self.mlp = mlp(config)\n",
        "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.std_scaler = 1\n",
        "    def forward(self, x):\n",
        "\n",
        "        resdual_x = x\n",
        "        x = self.ln_1(x)\n",
        "        x = self.attn(x) + resdual_x\n",
        "\n",
        "        resdual_x = x\n",
        "        x = self.ln_2(x)\n",
        "        x = self.mlp(x) + resdual_x\n",
        "        return x"
      ],
      "metadata": {
        "id": "LdMhjT_ik0z_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myGPT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(myGPT, self).__init__()\n",
        "        self.config = config\n",
        "        self.transformer = nn.ModuleDict({\n",
        "            'wte': nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            'wpe': nn.Embedding(config.block_size, config.n_embd),\n",
        "            'h': nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            'ln_f': nn.LayerNorm(config.n_embd)\n",
        "        })\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "        # weight sharing\n",
        "        self.transformer['wte'].weight = self.lm_head.weight\n",
        "        # apply weight initialization\n",
        "        self.apply(self.initionalization)\n",
        "\n",
        "    def initionalization(self,model):\n",
        "        std_linear = 0.02\n",
        "        std_embedding = 0.01\n",
        "        if hasattr(model, 'std_scaler'):\n",
        "            std_linear = (2 * self.config.n_layer) ** -0.5\n",
        "            std_embedding = (2 * self.config.n_layer) ** -0.5\n",
        "        if isinstance(model,nn.Linear):\n",
        "            nn.init.normal_(model.weight, mean = 0,std = std_linear)\n",
        "            if model.bias is not None:\n",
        "                nn.init.zeros_(model.bias)\n",
        "        elif isinstance(model,nn.Embedding):\n",
        "            nn.init.normal_(model.weight,mean=0,std=std_embedding) # following the offical openAI implementation\n",
        "\n",
        "    def forward(self, x,targets = None):\n",
        "        B, T = x.size()\n",
        "        assert T <= self.config.block_size, f\"Cannot forward sequence of length {T}, block size is only {self.config.block_size}\"\n",
        "        # forward the token and posisition embeddings\n",
        "        pos = torch.arange(0, T, dtype=torch.long, device=x.device) # shape (T)\n",
        "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (T, n_embd)\n",
        "        tok_emb = self.transformer.wte(x) # token embeddings of shape (B, T, n_embd)\n",
        "        x = tok_emb + pos_emb\n",
        "\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "\n",
        "        x = self.transformer.ln_f(x)\n",
        "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
        "        return logits, loss\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, model_type):\n",
        "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
        "        from transformers import GPT2LMHeadModel\n",
        "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
        "\n",
        "        # n_layer, n_head and n_embd are determined from model_type\n",
        "        config_args = {\n",
        "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
        "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
        "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
        "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
        "        }[model_type]\n",
        "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
        "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
        "        # create a from-scratch initialized minGPT model\n",
        "        config = GPT2Config(**config_args)\n",
        "        model = myGPT(config)\n",
        "        sd = model.state_dict()\n",
        "        sd_keys = sd.keys()\n",
        "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
        "\n",
        "        # init a huggingface/transformers model\n",
        "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
        "        sd_hf = model_hf.state_dict()\n",
        "\n",
        "        # copy while ensuring all of the parameters are aligned and match in names and shapes\n",
        "        sd_keys_hf = sd_hf.keys()\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
        "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
        "        # basically the openai checkpoints use a \"Conv1D\" module, but we only want to use a vanilla Linear\n",
        "        # this means that we have to transpose these weights when we import them\n",
        "        assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
        "        for k in sd_keys_hf:\n",
        "            if any(k.endswith(w) for w in transposed):\n",
        "                # special treatment for the Conv1D weights we need to transpose\n",
        "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k].t())\n",
        "            else:\n",
        "                # vanilla copy over the other parameters\n",
        "                assert sd_hf[k].shape == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k])\n",
        "        return model"
      ],
      "metadata": {
        "id": "_gFYgv95k4MS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader:\n",
        "    def __init__(self, batch_size, block_size, percentage=100):\n",
        "        self.batch_size = batch_size\n",
        "        self.block_size = block_size\n",
        "        self.pointer = 0\n",
        "        self.data = ''\n",
        "\n",
        "        with open('combined_texts.txt', 'r', encoding='utf-8', errors='ignore') as file:\n",
        "            self.data = file.read()\n",
        "\n",
        "        # Calculate the number of characters to load based on the percentage\n",
        "        total_chars = len(self.data)\n",
        "        chars_to_load = int((percentage / 100) * total_chars)\n",
        "\n",
        "        # Adjust the data to the desired percentage\n",
        "        self.data = self.data[:chars_to_load]\n",
        "\n",
        "        self.tokens = tiktoken.get_encoding('gpt2').encode(self.data)\n",
        "        self.n_batches = len(self.tokens) // (self.batch_size * self.block_size)\n",
        "\n",
        "    def next_batch(self):\n",
        "        start = self.pointer\n",
        "        end = start + self.batch_size * self.block_size\n",
        "        if end + 1 > len(self.tokens):\n",
        "            raise IndexError(\"End of data reached\")\n",
        "\n",
        "        mini_tokens = self.tokens[start:end + 1]\n",
        "        x = torch.tensor(mini_tokens[:-1], dtype=torch.long).view(self.batch_size, self.block_size)\n",
        "        y = torch.tensor(mini_tokens[1:], dtype=torch.long).view(self.batch_size, self.block_size)\n",
        "        self.pointer += self.batch_size * self.block_size\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "2CJBU-s4k7WT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch._dynamo\n",
        "torch._dynamo.config.suppress_errors = True\n",
        "Block_size = 512\n",
        "Batch_size = 12\n",
        "config = GPT2Config(block_size=Block_size, vocab_size=50304, n_embd=768, n_layer=12, n_head=12)\n",
        "model = myGPT(config)\n",
        "model = model.to(get_device())\n",
        "model = torch.compile(model)\n",
        "x,y = DataLoader(batch_size=Batch_size, block_size=Block_size).next_batch()\n",
        "x,y = x.to(get_device()), y.to(get_device())\n",
        "logits,loss = model.forward(x,y)\n",
        "print(logits.size(), loss) # I am expecting to have a loss equal to the cross entropy loss which is -log(probability)\n",
        "                            # where each word follows uniform distription so the probability should be 1/vocb_size = 1/50257 = 0.0000199\n",
        "                            # so the loss should be -log(0.0000199) = 10.8"
      ],
      "metadata": {
        "id": "RVdDIpUKk8sU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57fd5435-d355-486e-ca3c-ab2afaa4722a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 512, 50304]) tensor(11.0770, device='cuda:0', grad_fn=<CompiledFunctionBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Batch_size = 12\n",
        "torch.set_float32_matmul_precision('high')\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "num_epochs = 1\n",
        "for j in range(num_epochs):\n",
        "  dataloader = DataLoader(Batch_size,Block_size,100)\n",
        "  print(dataloader.n_batches)\n",
        "  for i in range(dataloader.n_batches - 1):\n",
        "      optimizer.zero_grad()\n",
        "      x,y = dataloader.next_batch()\n",
        "      x,y = x.to(get_device()), y.to(get_device())\n",
        "      logits, loss = model(x, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      print(f\"epoch: {j+1}, iteratation {i}, loss: {loss.item()}\")"
      ],
      "metadata": {
        "id": "Bw8rydLCk-UN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f7d891c-e832-4492-d881-f05ea49099c8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16217\n",
            "epoch: 1, iteratation 0, loss: 3.241798162460327\n",
            "epoch: 1, iteratation 1, loss: 2.5473694801330566\n",
            "epoch: 1, iteratation 2, loss: 2.6317977905273438\n",
            "epoch: 1, iteratation 3, loss: 2.653512716293335\n",
            "epoch: 1, iteratation 4, loss: 2.6229326725006104\n",
            "epoch: 1, iteratation 5, loss: 2.6912708282470703\n",
            "epoch: 1, iteratation 6, loss: 2.5843350887298584\n",
            "epoch: 1, iteratation 7, loss: 2.649233341217041\n",
            "epoch: 1, iteratation 8, loss: 2.5634894371032715\n",
            "epoch: 1, iteratation 9, loss: 2.7243590354919434\n",
            "epoch: 1, iteratation 10, loss: 2.595670223236084\n",
            "epoch: 1, iteratation 11, loss: 2.680663585662842\n",
            "epoch: 1, iteratation 12, loss: 2.6017074584960938\n",
            "epoch: 1, iteratation 13, loss: 2.689971446990967\n",
            "epoch: 1, iteratation 14, loss: 2.5787689685821533\n",
            "epoch: 1, iteratation 15, loss: 2.602816581726074\n",
            "epoch: 1, iteratation 16, loss: 2.581268787384033\n",
            "epoch: 1, iteratation 17, loss: 2.6537787914276123\n",
            "epoch: 1, iteratation 18, loss: 2.921766996383667\n",
            "epoch: 1, iteratation 19, loss: 2.719048023223877\n",
            "epoch: 1, iteratation 20, loss: 2.628571033477783\n",
            "epoch: 1, iteratation 21, loss: 2.6338958740234375\n",
            "epoch: 1, iteratation 22, loss: 2.6417558193206787\n",
            "epoch: 1, iteratation 23, loss: 2.5531864166259766\n",
            "epoch: 1, iteratation 24, loss: 2.561758518218994\n",
            "epoch: 1, iteratation 25, loss: 2.6364998817443848\n",
            "epoch: 1, iteratation 26, loss: 2.5955309867858887\n",
            "epoch: 1, iteratation 27, loss: 2.5525078773498535\n",
            "epoch: 1, iteratation 28, loss: 2.5480496883392334\n",
            "epoch: 1, iteratation 29, loss: 2.579232931137085\n",
            "epoch: 1, iteratation 30, loss: 2.5865402221679688\n",
            "epoch: 1, iteratation 31, loss: 2.636101722717285\n",
            "epoch: 1, iteratation 32, loss: 2.564012050628662\n",
            "epoch: 1, iteratation 33, loss: 2.5945374965667725\n",
            "epoch: 1, iteratation 34, loss: 2.5723118782043457\n",
            "epoch: 1, iteratation 35, loss: 2.636018753051758\n",
            "epoch: 1, iteratation 36, loss: 2.499276638031006\n",
            "epoch: 1, iteratation 37, loss: 2.566181182861328\n",
            "epoch: 1, iteratation 38, loss: 2.678496837615967\n",
            "epoch: 1, iteratation 39, loss: 2.611523389816284\n",
            "epoch: 1, iteratation 40, loss: 2.5751407146453857\n",
            "epoch: 1, iteratation 41, loss: 2.5341365337371826\n",
            "epoch: 1, iteratation 42, loss: 2.6179089546203613\n",
            "epoch: 1, iteratation 43, loss: 2.5108227729797363\n",
            "epoch: 1, iteratation 44, loss: 2.63800311088562\n",
            "epoch: 1, iteratation 45, loss: 2.6057515144348145\n",
            "epoch: 1, iteratation 46, loss: 2.556748867034912\n",
            "epoch: 1, iteratation 47, loss: 2.650897979736328\n",
            "epoch: 1, iteratation 48, loss: 2.5135929584503174\n",
            "epoch: 1, iteratation 49, loss: 2.723552703857422\n",
            "epoch: 1, iteratation 50, loss: 2.7685706615448\n",
            "epoch: 1, iteratation 51, loss: 3.294382095336914\n",
            "epoch: 1, iteratation 52, loss: 3.032405376434326\n",
            "epoch: 1, iteratation 53, loss: 2.611675500869751\n",
            "epoch: 1, iteratation 54, loss: 2.6913344860076904\n",
            "epoch: 1, iteratation 55, loss: 2.5981128215789795\n",
            "epoch: 1, iteratation 56, loss: 2.6187174320220947\n",
            "epoch: 1, iteratation 57, loss: 2.647944450378418\n",
            "epoch: 1, iteratation 58, loss: 2.5467453002929688\n",
            "epoch: 1, iteratation 59, loss: 2.642455577850342\n",
            "epoch: 1, iteratation 60, loss: 2.679985761642456\n",
            "epoch: 1, iteratation 61, loss: 2.6535720825195312\n",
            "epoch: 1, iteratation 62, loss: 2.774536609649658\n",
            "epoch: 1, iteratation 63, loss: 2.7235188484191895\n",
            "epoch: 1, iteratation 64, loss: 2.8090827465057373\n",
            "epoch: 1, iteratation 65, loss: 2.795907497406006\n",
            "epoch: 1, iteratation 66, loss: 2.630202054977417\n",
            "epoch: 1, iteratation 67, loss: 2.779989004135132\n",
            "epoch: 1, iteratation 68, loss: 2.6887357234954834\n",
            "epoch: 1, iteratation 69, loss: 2.6194369792938232\n",
            "epoch: 1, iteratation 70, loss: 2.613346815109253\n",
            "epoch: 1, iteratation 71, loss: 2.5801236629486084\n",
            "epoch: 1, iteratation 72, loss: 2.5937294960021973\n",
            "epoch: 1, iteratation 73, loss: 2.563704013824463\n",
            "epoch: 1, iteratation 74, loss: 2.5648772716522217\n",
            "epoch: 1, iteratation 75, loss: 2.611978054046631\n",
            "epoch: 1, iteratation 76, loss: 2.542685031890869\n",
            "epoch: 1, iteratation 77, loss: 2.707477569580078\n",
            "epoch: 1, iteratation 78, loss: 2.5809736251831055\n",
            "epoch: 1, iteratation 79, loss: 2.5838775634765625\n",
            "epoch: 1, iteratation 80, loss: 2.5663599967956543\n",
            "epoch: 1, iteratation 81, loss: 2.5278115272521973\n",
            "epoch: 1, iteratation 82, loss: 2.5691752433776855\n",
            "epoch: 1, iteratation 83, loss: 2.5648317337036133\n",
            "epoch: 1, iteratation 84, loss: 2.6637887954711914\n",
            "epoch: 1, iteratation 85, loss: 2.67012095451355\n",
            "epoch: 1, iteratation 86, loss: 2.624999761581421\n",
            "epoch: 1, iteratation 87, loss: 2.7345504760742188\n",
            "epoch: 1, iteratation 88, loss: 2.5203230381011963\n",
            "epoch: 1, iteratation 89, loss: 2.53342866897583\n",
            "epoch: 1, iteratation 90, loss: 2.5815625190734863\n",
            "epoch: 1, iteratation 91, loss: 2.6669907569885254\n",
            "epoch: 1, iteratation 92, loss: 2.6646995544433594\n",
            "epoch: 1, iteratation 93, loss: 2.6624393463134766\n",
            "epoch: 1, iteratation 94, loss: 2.58530330657959\n",
            "epoch: 1, iteratation 95, loss: 2.7470879554748535\n",
            "epoch: 1, iteratation 96, loss: 2.7022666931152344\n",
            "epoch: 1, iteratation 97, loss: 3.2273776531219482\n",
            "epoch: 1, iteratation 98, loss: 2.7156589031219482\n",
            "epoch: 1, iteratation 99, loss: 2.616821765899658\n",
            "epoch: 1, iteratation 100, loss: 2.5790867805480957\n",
            "epoch: 1, iteratation 101, loss: 2.5368869304656982\n",
            "epoch: 1, iteratation 102, loss: 2.612189769744873\n",
            "epoch: 1, iteratation 103, loss: 2.5657076835632324\n",
            "epoch: 1, iteratation 104, loss: 2.5827043056488037\n",
            "epoch: 1, iteratation 105, loss: 2.640132427215576\n",
            "epoch: 1, iteratation 106, loss: 2.669504165649414\n",
            "epoch: 1, iteratation 107, loss: 2.676631450653076\n",
            "epoch: 1, iteratation 108, loss: 2.617131233215332\n",
            "epoch: 1, iteratation 109, loss: 2.6542301177978516\n",
            "epoch: 1, iteratation 110, loss: 2.616823673248291\n",
            "epoch: 1, iteratation 111, loss: 2.527621269226074\n",
            "epoch: 1, iteratation 112, loss: 2.572178363800049\n",
            "epoch: 1, iteratation 113, loss: 2.60263991355896\n",
            "epoch: 1, iteratation 114, loss: 2.720336437225342\n",
            "epoch: 1, iteratation 115, loss: 2.487022876739502\n",
            "epoch: 1, iteratation 116, loss: 2.592336654663086\n",
            "epoch: 1, iteratation 117, loss: 2.5707449913024902\n",
            "epoch: 1, iteratation 118, loss: 2.552753210067749\n",
            "epoch: 1, iteratation 119, loss: 2.683570384979248\n",
            "epoch: 1, iteratation 120, loss: 2.5982375144958496\n",
            "epoch: 1, iteratation 121, loss: 2.6505439281463623\n",
            "epoch: 1, iteratation 122, loss: 2.588096857070923\n",
            "epoch: 1, iteratation 123, loss: 2.7030189037323\n",
            "epoch: 1, iteratation 124, loss: 2.5752809047698975\n",
            "epoch: 1, iteratation 125, loss: 2.5266761779785156\n",
            "epoch: 1, iteratation 126, loss: 2.816863536834717\n",
            "epoch: 1, iteratation 127, loss: 2.7335946559906006\n",
            "epoch: 1, iteratation 128, loss: 2.5622975826263428\n",
            "epoch: 1, iteratation 129, loss: 2.666393756866455\n",
            "epoch: 1, iteratation 130, loss: 2.6312482357025146\n",
            "epoch: 1, iteratation 131, loss: 2.56290602684021\n",
            "epoch: 1, iteratation 132, loss: 2.59143328666687\n",
            "epoch: 1, iteratation 133, loss: 2.587010145187378\n",
            "epoch: 1, iteratation 134, loss: 2.6219630241394043\n",
            "epoch: 1, iteratation 135, loss: 2.5774552822113037\n",
            "epoch: 1, iteratation 136, loss: 2.587522268295288\n",
            "epoch: 1, iteratation 137, loss: 2.462010145187378\n",
            "epoch: 1, iteratation 138, loss: 2.4708971977233887\n",
            "epoch: 1, iteratation 139, loss: 2.61087703704834\n",
            "epoch: 1, iteratation 140, loss: 2.559927463531494\n",
            "epoch: 1, iteratation 141, loss: 2.561659336090088\n",
            "epoch: 1, iteratation 142, loss: 2.5363194942474365\n",
            "epoch: 1, iteratation 143, loss: 2.5803263187408447\n",
            "epoch: 1, iteratation 144, loss: 2.5717360973358154\n",
            "epoch: 1, iteratation 145, loss: 2.5235419273376465\n",
            "epoch: 1, iteratation 146, loss: 2.563993453979492\n",
            "epoch: 1, iteratation 147, loss: 2.545412063598633\n",
            "epoch: 1, iteratation 148, loss: 2.544002056121826\n",
            "epoch: 1, iteratation 149, loss: 2.492539644241333\n",
            "epoch: 1, iteratation 150, loss: 2.530526876449585\n",
            "epoch: 1, iteratation 151, loss: 2.59844708442688\n",
            "epoch: 1, iteratation 152, loss: 2.6416642665863037\n",
            "epoch: 1, iteratation 153, loss: 2.4990556240081787\n",
            "epoch: 1, iteratation 154, loss: 2.631007432937622\n",
            "epoch: 1, iteratation 155, loss: 2.810091733932495\n",
            "epoch: 1, iteratation 156, loss: 2.6352477073669434\n",
            "epoch: 1, iteratation 157, loss: 2.6024045944213867\n",
            "epoch: 1, iteratation 158, loss: 2.5623998641967773\n",
            "epoch: 1, iteratation 159, loss: 2.4886443614959717\n",
            "epoch: 1, iteratation 160, loss: 2.7995505332946777\n",
            "epoch: 1, iteratation 161, loss: 2.5545434951782227\n",
            "epoch: 1, iteratation 162, loss: 2.5244319438934326\n",
            "epoch: 1, iteratation 163, loss: 2.6096458435058594\n",
            "epoch: 1, iteratation 164, loss: 2.550370216369629\n",
            "epoch: 1, iteratation 165, loss: 2.592820644378662\n",
            "epoch: 1, iteratation 166, loss: 2.616361618041992\n",
            "epoch: 1, iteratation 167, loss: 2.587921142578125\n",
            "epoch: 1, iteratation 168, loss: 2.6779141426086426\n",
            "epoch: 1, iteratation 169, loss: 2.715179443359375\n",
            "epoch: 1, iteratation 170, loss: 2.6486334800720215\n",
            "epoch: 1, iteratation 171, loss: 2.6519975662231445\n",
            "epoch: 1, iteratation 172, loss: 2.4913899898529053\n",
            "epoch: 1, iteratation 173, loss: 2.6491990089416504\n",
            "epoch: 1, iteratation 174, loss: 3.0587425231933594\n",
            "epoch: 1, iteratation 175, loss: 2.5115177631378174\n",
            "epoch: 1, iteratation 176, loss: 2.8773696422576904\n",
            "epoch: 1, iteratation 177, loss: 2.580447196960449\n",
            "epoch: 1, iteratation 178, loss: 2.7193713188171387\n",
            "epoch: 1, iteratation 179, loss: 2.5327188968658447\n",
            "epoch: 1, iteratation 180, loss: 2.662334442138672\n",
            "epoch: 1, iteratation 181, loss: 2.6687495708465576\n",
            "epoch: 1, iteratation 182, loss: 2.6319069862365723\n",
            "epoch: 1, iteratation 183, loss: 2.5802419185638428\n",
            "epoch: 1, iteratation 184, loss: 2.818765163421631\n",
            "epoch: 1, iteratation 185, loss: 2.596618175506592\n",
            "epoch: 1, iteratation 186, loss: 2.5567190647125244\n",
            "epoch: 1, iteratation 187, loss: 2.6196420192718506\n",
            "epoch: 1, iteratation 188, loss: 2.5343453884124756\n",
            "epoch: 1, iteratation 189, loss: 2.887681722640991\n",
            "epoch: 1, iteratation 190, loss: 2.6090762615203857\n",
            "epoch: 1, iteratation 191, loss: 2.619668960571289\n",
            "epoch: 1, iteratation 192, loss: 2.6227691173553467\n",
            "epoch: 1, iteratation 193, loss: 2.717954158782959\n",
            "epoch: 1, iteratation 194, loss: 2.5700631141662598\n",
            "epoch: 1, iteratation 195, loss: 2.592165946960449\n",
            "epoch: 1, iteratation 196, loss: 2.536684513092041\n",
            "epoch: 1, iteratation 197, loss: 2.638197898864746\n",
            "epoch: 1, iteratation 198, loss: 2.6045846939086914\n",
            "epoch: 1, iteratation 199, loss: 2.537904739379883\n",
            "epoch: 1, iteratation 200, loss: 2.595767021179199\n",
            "epoch: 1, iteratation 201, loss: 2.716102123260498\n",
            "epoch: 1, iteratation 202, loss: 2.583738088607788\n",
            "epoch: 1, iteratation 203, loss: 2.5491647720336914\n",
            "epoch: 1, iteratation 204, loss: 2.584557294845581\n",
            "epoch: 1, iteratation 205, loss: 2.55853271484375\n",
            "epoch: 1, iteratation 206, loss: 2.764380931854248\n",
            "epoch: 1, iteratation 207, loss: 2.5314948558807373\n",
            "epoch: 1, iteratation 208, loss: 2.7527835369110107\n",
            "epoch: 1, iteratation 209, loss: 2.5566866397857666\n",
            "epoch: 1, iteratation 210, loss: 2.789219856262207\n",
            "epoch: 1, iteratation 211, loss: 2.545577049255371\n",
            "epoch: 1, iteratation 212, loss: 2.654771566390991\n",
            "epoch: 1, iteratation 213, loss: 2.523409605026245\n",
            "epoch: 1, iteratation 214, loss: 2.5141544342041016\n",
            "epoch: 1, iteratation 215, loss: 2.59836483001709\n",
            "epoch: 1, iteratation 216, loss: 2.5729079246520996\n",
            "epoch: 1, iteratation 217, loss: 2.546468734741211\n",
            "epoch: 1, iteratation 218, loss: 2.627105236053467\n",
            "epoch: 1, iteratation 219, loss: 2.610761880874634\n",
            "epoch: 1, iteratation 220, loss: 2.5638015270233154\n",
            "epoch: 1, iteratation 221, loss: 2.6269993782043457\n",
            "epoch: 1, iteratation 222, loss: 2.5361218452453613\n",
            "epoch: 1, iteratation 223, loss: 2.5585389137268066\n",
            "epoch: 1, iteratation 224, loss: 2.565676689147949\n",
            "epoch: 1, iteratation 225, loss: 2.525735855102539\n",
            "epoch: 1, iteratation 226, loss: 2.6791625022888184\n",
            "epoch: 1, iteratation 227, loss: 2.738659381866455\n",
            "epoch: 1, iteratation 228, loss: 2.5787811279296875\n",
            "epoch: 1, iteratation 229, loss: 2.65805983543396\n",
            "epoch: 1, iteratation 230, loss: 2.622982978820801\n",
            "epoch: 1, iteratation 231, loss: 2.496241331100464\n",
            "epoch: 1, iteratation 232, loss: 2.6483845710754395\n",
            "epoch: 1, iteratation 233, loss: 2.618751287460327\n",
            "epoch: 1, iteratation 234, loss: 2.5887255668640137\n",
            "epoch: 1, iteratation 235, loss: 2.588003635406494\n",
            "epoch: 1, iteratation 236, loss: 2.6186506748199463\n",
            "epoch: 1, iteratation 237, loss: 2.7412338256835938\n",
            "epoch: 1, iteratation 238, loss: 2.600802421569824\n",
            "epoch: 1, iteratation 239, loss: 2.526395320892334\n",
            "epoch: 1, iteratation 240, loss: 2.4701075553894043\n",
            "epoch: 1, iteratation 241, loss: 2.431057929992676\n",
            "epoch: 1, iteratation 242, loss: 2.5240299701690674\n",
            "epoch: 1, iteratation 243, loss: 2.5490455627441406\n",
            "epoch: 1, iteratation 244, loss: 2.5628392696380615\n",
            "epoch: 1, iteratation 245, loss: 2.6374149322509766\n",
            "epoch: 1, iteratation 246, loss: 2.5806796550750732\n",
            "epoch: 1, iteratation 247, loss: 2.6590516567230225\n",
            "epoch: 1, iteratation 248, loss: 2.612065315246582\n",
            "epoch: 1, iteratation 249, loss: 2.598912239074707\n",
            "epoch: 1, iteratation 250, loss: 2.605811834335327\n",
            "epoch: 1, iteratation 251, loss: 2.642655372619629\n",
            "epoch: 1, iteratation 252, loss: 2.5147736072540283\n",
            "epoch: 1, iteratation 253, loss: 2.6359171867370605\n",
            "epoch: 1, iteratation 254, loss: 2.5130553245544434\n",
            "epoch: 1, iteratation 255, loss: 2.489098072052002\n",
            "epoch: 1, iteratation 256, loss: 2.496762275695801\n",
            "epoch: 1, iteratation 257, loss: 2.723973035812378\n",
            "epoch: 1, iteratation 258, loss: 2.635514259338379\n",
            "epoch: 1, iteratation 259, loss: 2.5328783988952637\n",
            "epoch: 1, iteratation 260, loss: 2.527757406234741\n",
            "epoch: 1, iteratation 261, loss: 2.9397971630096436\n",
            "epoch: 1, iteratation 262, loss: 2.5183815956115723\n",
            "epoch: 1, iteratation 263, loss: 2.68245267868042\n",
            "epoch: 1, iteratation 264, loss: 2.530618190765381\n",
            "epoch: 1, iteratation 265, loss: 2.5871329307556152\n",
            "epoch: 1, iteratation 266, loss: 2.545159101486206\n",
            "epoch: 1, iteratation 267, loss: 2.624518871307373\n",
            "epoch: 1, iteratation 268, loss: 2.595510482788086\n",
            "epoch: 1, iteratation 269, loss: 2.584202527999878\n",
            "epoch: 1, iteratation 270, loss: 2.5999209880828857\n",
            "epoch: 1, iteratation 271, loss: 2.525009870529175\n",
            "epoch: 1, iteratation 272, loss: 2.588933229446411\n",
            "epoch: 1, iteratation 273, loss: 2.556102752685547\n",
            "epoch: 1, iteratation 274, loss: 2.77726411819458\n",
            "epoch: 1, iteratation 275, loss: 2.5160446166992188\n",
            "epoch: 1, iteratation 276, loss: 2.7387359142303467\n",
            "epoch: 1, iteratation 277, loss: 2.632215738296509\n",
            "epoch: 1, iteratation 278, loss: 2.5960347652435303\n",
            "epoch: 1, iteratation 279, loss: 2.5198235511779785\n",
            "epoch: 1, iteratation 280, loss: 2.6679439544677734\n",
            "epoch: 1, iteratation 281, loss: 2.661611795425415\n",
            "epoch: 1, iteratation 282, loss: 2.7260499000549316\n",
            "epoch: 1, iteratation 283, loss: 2.512662649154663\n",
            "epoch: 1, iteratation 284, loss: 2.5935192108154297\n",
            "epoch: 1, iteratation 285, loss: 2.551342487335205\n",
            "epoch: 1, iteratation 286, loss: 2.5926437377929688\n",
            "epoch: 1, iteratation 287, loss: 2.5752484798431396\n",
            "epoch: 1, iteratation 288, loss: 2.5692567825317383\n",
            "epoch: 1, iteratation 289, loss: 2.5984978675842285\n",
            "epoch: 1, iteratation 290, loss: 2.596834182739258\n",
            "epoch: 1, iteratation 291, loss: 2.556997299194336\n",
            "epoch: 1, iteratation 292, loss: 2.601484537124634\n",
            "epoch: 1, iteratation 293, loss: 2.5103423595428467\n",
            "epoch: 1, iteratation 294, loss: 2.5950706005096436\n",
            "epoch: 1, iteratation 295, loss: 2.726658344268799\n",
            "epoch: 1, iteratation 296, loss: 2.5205740928649902\n",
            "epoch: 1, iteratation 297, loss: 2.494689702987671\n",
            "epoch: 1, iteratation 298, loss: 2.6389989852905273\n",
            "epoch: 1, iteratation 299, loss: 2.543761730194092\n",
            "epoch: 1, iteratation 300, loss: 2.7393815517425537\n",
            "epoch: 1, iteratation 301, loss: 2.5754780769348145\n",
            "epoch: 1, iteratation 302, loss: 2.9685235023498535\n",
            "epoch: 1, iteratation 303, loss: 2.7049670219421387\n",
            "epoch: 1, iteratation 304, loss: 2.6178879737854004\n",
            "epoch: 1, iteratation 305, loss: 2.5456902980804443\n",
            "epoch: 1, iteratation 306, loss: 2.572993040084839\n",
            "epoch: 1, iteratation 307, loss: 2.498526096343994\n",
            "epoch: 1, iteratation 308, loss: 2.531797409057617\n",
            "epoch: 1, iteratation 309, loss: 2.5520389080047607\n",
            "epoch: 1, iteratation 310, loss: 2.547771692276001\n",
            "epoch: 1, iteratation 311, loss: 2.490295886993408\n",
            "epoch: 1, iteratation 312, loss: 2.62662935256958\n",
            "epoch: 1, iteratation 313, loss: 2.5869832038879395\n",
            "epoch: 1, iteratation 314, loss: 2.6439478397369385\n",
            "epoch: 1, iteratation 315, loss: 2.566605567932129\n",
            "epoch: 1, iteratation 316, loss: 2.5961625576019287\n",
            "epoch: 1, iteratation 317, loss: 2.513428211212158\n",
            "epoch: 1, iteratation 318, loss: 2.5925421714782715\n",
            "epoch: 1, iteratation 319, loss: 2.5938117504119873\n",
            "epoch: 1, iteratation 320, loss: 2.5037014484405518\n",
            "epoch: 1, iteratation 321, loss: 2.610053539276123\n",
            "epoch: 1, iteratation 322, loss: 2.632195234298706\n",
            "epoch: 1, iteratation 323, loss: 2.667893886566162\n",
            "epoch: 1, iteratation 324, loss: 2.6124072074890137\n",
            "epoch: 1, iteratation 325, loss: 2.6393232345581055\n",
            "epoch: 1, iteratation 326, loss: 2.6510751247406006\n",
            "epoch: 1, iteratation 327, loss: 2.494992256164551\n",
            "epoch: 1, iteratation 328, loss: 2.549948215484619\n",
            "epoch: 1, iteratation 329, loss: 2.5411882400512695\n",
            "epoch: 1, iteratation 330, loss: 2.5260982513427734\n",
            "epoch: 1, iteratation 331, loss: 2.589752674102783\n",
            "epoch: 1, iteratation 332, loss: 2.5860507488250732\n",
            "epoch: 1, iteratation 333, loss: 2.5938642024993896\n",
            "epoch: 1, iteratation 334, loss: 2.6569411754608154\n",
            "epoch: 1, iteratation 335, loss: 2.5117321014404297\n",
            "epoch: 1, iteratation 336, loss: 2.5213418006896973\n",
            "epoch: 1, iteratation 337, loss: 2.496936559677124\n",
            "epoch: 1, iteratation 338, loss: 2.6234254837036133\n",
            "epoch: 1, iteratation 339, loss: 2.6178576946258545\n",
            "epoch: 1, iteratation 340, loss: 2.5099568367004395\n",
            "epoch: 1, iteratation 341, loss: 2.5400846004486084\n",
            "epoch: 1, iteratation 342, loss: 2.666968822479248\n",
            "epoch: 1, iteratation 343, loss: 2.633920192718506\n",
            "epoch: 1, iteratation 344, loss: 2.7142837047576904\n",
            "epoch: 1, iteratation 345, loss: 2.994720220565796\n",
            "epoch: 1, iteratation 346, loss: 2.534806966781616\n",
            "epoch: 1, iteratation 347, loss: 2.5306239128112793\n",
            "epoch: 1, iteratation 348, loss: 2.5053787231445312\n",
            "epoch: 1, iteratation 349, loss: 2.5398077964782715\n",
            "epoch: 1, iteratation 350, loss: 2.5260872840881348\n",
            "epoch: 1, iteratation 351, loss: 2.546414375305176\n",
            "epoch: 1, iteratation 352, loss: 2.5328867435455322\n",
            "epoch: 1, iteratation 353, loss: 2.5405359268188477\n",
            "epoch: 1, iteratation 354, loss: 2.5344526767730713\n",
            "epoch: 1, iteratation 355, loss: 2.551752805709839\n",
            "epoch: 1, iteratation 356, loss: 2.637159824371338\n",
            "epoch: 1, iteratation 357, loss: 2.5584285259246826\n",
            "epoch: 1, iteratation 358, loss: 2.547459840774536\n",
            "epoch: 1, iteratation 359, loss: 2.5608139038085938\n",
            "epoch: 1, iteratation 360, loss: 2.530559778213501\n",
            "epoch: 1, iteratation 361, loss: 2.560011863708496\n",
            "epoch: 1, iteratation 362, loss: 2.5392653942108154\n",
            "epoch: 1, iteratation 363, loss: 2.580230236053467\n",
            "epoch: 1, iteratation 364, loss: 2.6144862174987793\n",
            "epoch: 1, iteratation 365, loss: 2.705820083618164\n",
            "epoch: 1, iteratation 366, loss: 2.5190224647521973\n",
            "epoch: 1, iteratation 367, loss: 2.587924003601074\n",
            "epoch: 1, iteratation 368, loss: 2.907646894454956\n",
            "epoch: 1, iteratation 369, loss: 2.5406131744384766\n",
            "epoch: 1, iteratation 370, loss: 2.500300407409668\n",
            "epoch: 1, iteratation 371, loss: 2.5651042461395264\n",
            "epoch: 1, iteratation 372, loss: 2.5128164291381836\n",
            "epoch: 1, iteratation 373, loss: 2.6269450187683105\n",
            "epoch: 1, iteratation 374, loss: 2.5440778732299805\n",
            "epoch: 1, iteratation 375, loss: 2.564777135848999\n",
            "epoch: 1, iteratation 376, loss: 2.6078603267669678\n",
            "epoch: 1, iteratation 377, loss: 2.619732618331909\n",
            "epoch: 1, iteratation 378, loss: 2.5667219161987305\n",
            "epoch: 1, iteratation 379, loss: 2.5097670555114746\n",
            "epoch: 1, iteratation 380, loss: 2.534147024154663\n",
            "epoch: 1, iteratation 381, loss: 2.504652500152588\n",
            "epoch: 1, iteratation 382, loss: 2.5739452838897705\n",
            "epoch: 1, iteratation 383, loss: 2.6221747398376465\n",
            "epoch: 1, iteratation 384, loss: 2.5937039852142334\n",
            "epoch: 1, iteratation 385, loss: 2.5373659133911133\n",
            "epoch: 1, iteratation 386, loss: 2.6076760292053223\n",
            "epoch: 1, iteratation 387, loss: 2.5514917373657227\n",
            "epoch: 1, iteratation 388, loss: 2.5380594730377197\n",
            "epoch: 1, iteratation 389, loss: 2.694232940673828\n",
            "epoch: 1, iteratation 390, loss: 2.5453128814697266\n",
            "epoch: 1, iteratation 391, loss: 2.5757405757904053\n",
            "epoch: 1, iteratation 392, loss: 2.4695029258728027\n",
            "epoch: 1, iteratation 393, loss: 2.5626888275146484\n",
            "epoch: 1, iteratation 394, loss: 2.541496753692627\n",
            "epoch: 1, iteratation 395, loss: 2.6952157020568848\n",
            "epoch: 1, iteratation 396, loss: 2.582305908203125\n",
            "epoch: 1, iteratation 397, loss: 2.5383267402648926\n",
            "epoch: 1, iteratation 398, loss: 2.629067897796631\n",
            "epoch: 1, iteratation 399, loss: 2.5447113513946533\n",
            "epoch: 1, iteratation 400, loss: 2.6654202938079834\n",
            "epoch: 1, iteratation 401, loss: 2.5748372077941895\n",
            "epoch: 1, iteratation 402, loss: 2.541231393814087\n",
            "epoch: 1, iteratation 403, loss: 2.512007713317871\n",
            "epoch: 1, iteratation 404, loss: 2.544760227203369\n",
            "epoch: 1, iteratation 405, loss: 2.5724058151245117\n",
            "epoch: 1, iteratation 406, loss: 2.558704137802124\n",
            "epoch: 1, iteratation 407, loss: 2.626331090927124\n",
            "epoch: 1, iteratation 408, loss: 2.552995204925537\n",
            "epoch: 1, iteratation 409, loss: 2.590444564819336\n",
            "epoch: 1, iteratation 410, loss: 2.531161069869995\n",
            "epoch: 1, iteratation 411, loss: 2.462322235107422\n",
            "epoch: 1, iteratation 412, loss: 2.6138083934783936\n",
            "epoch: 1, iteratation 413, loss: 2.5606136322021484\n",
            "epoch: 1, iteratation 414, loss: 2.5497660636901855\n",
            "epoch: 1, iteratation 415, loss: 2.49959659576416\n",
            "epoch: 1, iteratation 416, loss: 2.515162944793701\n",
            "epoch: 1, iteratation 417, loss: 2.5047266483306885\n",
            "epoch: 1, iteratation 418, loss: 2.7905631065368652\n",
            "epoch: 1, iteratation 419, loss: 2.6083462238311768\n",
            "epoch: 1, iteratation 420, loss: 2.5041284561157227\n",
            "epoch: 1, iteratation 421, loss: 2.578306198120117\n",
            "epoch: 1, iteratation 422, loss: 2.5736587047576904\n",
            "epoch: 1, iteratation 423, loss: 2.526040554046631\n",
            "epoch: 1, iteratation 424, loss: 2.7325167655944824\n",
            "epoch: 1, iteratation 425, loss: 2.5504794120788574\n",
            "epoch: 1, iteratation 426, loss: 2.495272397994995\n",
            "epoch: 1, iteratation 427, loss: 2.4928224086761475\n",
            "epoch: 1, iteratation 428, loss: 2.584057331085205\n",
            "epoch: 1, iteratation 429, loss: 2.5279626846313477\n",
            "epoch: 1, iteratation 430, loss: 2.568563222885132\n",
            "epoch: 1, iteratation 431, loss: 2.6053290367126465\n",
            "epoch: 1, iteratation 432, loss: 2.482931613922119\n",
            "epoch: 1, iteratation 433, loss: 2.5268754959106445\n",
            "epoch: 1, iteratation 434, loss: 2.5210373401641846\n",
            "epoch: 1, iteratation 435, loss: 2.6712405681610107\n",
            "epoch: 1, iteratation 436, loss: 2.5564916133880615\n",
            "epoch: 1, iteratation 437, loss: 2.580214262008667\n",
            "epoch: 1, iteratation 438, loss: 2.531780242919922\n",
            "epoch: 1, iteratation 439, loss: 2.6242828369140625\n",
            "epoch: 1, iteratation 440, loss: 2.518475294113159\n",
            "epoch: 1, iteratation 441, loss: 2.511444330215454\n",
            "epoch: 1, iteratation 442, loss: 2.525132894515991\n",
            "epoch: 1, iteratation 443, loss: 2.511115074157715\n",
            "epoch: 1, iteratation 444, loss: 2.554001808166504\n",
            "epoch: 1, iteratation 445, loss: 2.582237482070923\n",
            "epoch: 1, iteratation 446, loss: 2.5827291011810303\n",
            "epoch: 1, iteratation 447, loss: 2.5661487579345703\n",
            "epoch: 1, iteratation 448, loss: 2.586606740951538\n",
            "epoch: 1, iteratation 449, loss: 2.545093059539795\n",
            "epoch: 1, iteratation 450, loss: 2.4592103958129883\n",
            "epoch: 1, iteratation 451, loss: 2.580967426300049\n",
            "epoch: 1, iteratation 452, loss: 2.574798107147217\n",
            "epoch: 1, iteratation 453, loss: 2.6315081119537354\n",
            "epoch: 1, iteratation 454, loss: 2.5156311988830566\n",
            "epoch: 1, iteratation 455, loss: 2.5825400352478027\n",
            "epoch: 1, iteratation 456, loss: 2.7378287315368652\n",
            "epoch: 1, iteratation 457, loss: 2.6742055416107178\n",
            "epoch: 1, iteratation 458, loss: 2.7631826400756836\n",
            "epoch: 1, iteratation 459, loss: 2.727179527282715\n",
            "epoch: 1, iteratation 460, loss: 2.820244550704956\n",
            "epoch: 1, iteratation 461, loss: 2.584254264831543\n",
            "epoch: 1, iteratation 462, loss: 2.5222268104553223\n",
            "epoch: 1, iteratation 463, loss: 2.504152297973633\n",
            "epoch: 1, iteratation 464, loss: 2.5980098247528076\n",
            "epoch: 1, iteratation 465, loss: 2.5749258995056152\n",
            "epoch: 1, iteratation 466, loss: 2.496649742126465\n",
            "epoch: 1, iteratation 467, loss: 2.5349016189575195\n",
            "epoch: 1, iteratation 468, loss: 2.621957778930664\n",
            "epoch: 1, iteratation 469, loss: 2.653353691101074\n",
            "epoch: 1, iteratation 470, loss: 2.626624584197998\n",
            "epoch: 1, iteratation 471, loss: 2.6108882427215576\n",
            "epoch: 1, iteratation 472, loss: 2.487581491470337\n",
            "epoch: 1, iteratation 473, loss: 2.472500801086426\n",
            "epoch: 1, iteratation 474, loss: 2.5754945278167725\n",
            "epoch: 1, iteratation 475, loss: 2.5752663612365723\n",
            "epoch: 1, iteratation 476, loss: 2.6141068935394287\n",
            "epoch: 1, iteratation 477, loss: 2.5709238052368164\n",
            "epoch: 1, iteratation 478, loss: 2.5064873695373535\n",
            "epoch: 1, iteratation 479, loss: 2.5712156295776367\n",
            "epoch: 1, iteratation 480, loss: 2.5498194694519043\n",
            "epoch: 1, iteratation 481, loss: 2.5401906967163086\n",
            "epoch: 1, iteratation 482, loss: 2.5283756256103516\n",
            "epoch: 1, iteratation 483, loss: 2.5744175910949707\n",
            "epoch: 1, iteratation 484, loss: 2.9462461471557617\n",
            "epoch: 1, iteratation 485, loss: 2.576798915863037\n",
            "epoch: 1, iteratation 486, loss: 2.610830783843994\n",
            "epoch: 1, iteratation 487, loss: 2.575559139251709\n",
            "epoch: 1, iteratation 488, loss: 2.6350486278533936\n",
            "epoch: 1, iteratation 489, loss: 2.580716133117676\n",
            "epoch: 1, iteratation 490, loss: 2.503962516784668\n",
            "epoch: 1, iteratation 491, loss: 2.7271018028259277\n",
            "epoch: 1, iteratation 492, loss: 2.558803081512451\n",
            "epoch: 1, iteratation 493, loss: 2.5194578170776367\n",
            "epoch: 1, iteratation 494, loss: 2.5023655891418457\n",
            "epoch: 1, iteratation 495, loss: 2.508563995361328\n",
            "epoch: 1, iteratation 496, loss: 2.5692732334136963\n",
            "epoch: 1, iteratation 497, loss: 2.595414400100708\n",
            "epoch: 1, iteratation 498, loss: 2.505079507827759\n",
            "epoch: 1, iteratation 499, loss: 2.753920078277588\n",
            "epoch: 1, iteratation 500, loss: 2.4437761306762695\n",
            "epoch: 1, iteratation 501, loss: 2.4831247329711914\n",
            "epoch: 1, iteratation 502, loss: 2.5554845333099365\n",
            "epoch: 1, iteratation 503, loss: 2.5023984909057617\n",
            "epoch: 1, iteratation 504, loss: 2.5512137413024902\n",
            "epoch: 1, iteratation 505, loss: 2.6656148433685303\n",
            "epoch: 1, iteratation 506, loss: 2.6024575233459473\n",
            "epoch: 1, iteratation 507, loss: 2.6000239849090576\n",
            "epoch: 1, iteratation 508, loss: 2.5796585083007812\n",
            "epoch: 1, iteratation 509, loss: 2.504767894744873\n",
            "epoch: 1, iteratation 510, loss: 2.540189504623413\n",
            "epoch: 1, iteratation 511, loss: 2.5518312454223633\n",
            "epoch: 1, iteratation 512, loss: 2.5126852989196777\n",
            "epoch: 1, iteratation 513, loss: 2.54525089263916\n",
            "epoch: 1, iteratation 514, loss: 2.575748920440674\n",
            "epoch: 1, iteratation 515, loss: 2.6040914058685303\n",
            "epoch: 1, iteratation 516, loss: 2.502445936203003\n",
            "epoch: 1, iteratation 517, loss: 2.6483731269836426\n",
            "epoch: 1, iteratation 518, loss: 2.6860978603363037\n",
            "epoch: 1, iteratation 519, loss: 2.5902836322784424\n",
            "epoch: 1, iteratation 520, loss: 2.5728070735931396\n",
            "epoch: 1, iteratation 521, loss: 2.5254600048065186\n",
            "epoch: 1, iteratation 522, loss: 2.7170779705047607\n",
            "epoch: 1, iteratation 523, loss: 2.560539722442627\n",
            "epoch: 1, iteratation 524, loss: 2.524569034576416\n",
            "epoch: 1, iteratation 525, loss: 2.538943290710449\n",
            "epoch: 1, iteratation 526, loss: 2.5066380500793457\n",
            "epoch: 1, iteratation 527, loss: 2.5450987815856934\n",
            "epoch: 1, iteratation 528, loss: 2.5271642208099365\n",
            "epoch: 1, iteratation 529, loss: 2.492371082305908\n",
            "epoch: 1, iteratation 530, loss: 2.549640655517578\n",
            "epoch: 1, iteratation 531, loss: 2.5270166397094727\n",
            "epoch: 1, iteratation 532, loss: 2.564898729324341\n",
            "epoch: 1, iteratation 533, loss: 2.4830880165100098\n",
            "epoch: 1, iteratation 534, loss: 2.480262517929077\n",
            "epoch: 1, iteratation 535, loss: 2.574164628982544\n",
            "epoch: 1, iteratation 536, loss: 2.5903615951538086\n",
            "epoch: 1, iteratation 537, loss: 2.561380386352539\n",
            "epoch: 1, iteratation 538, loss: 2.8775041103363037\n",
            "epoch: 1, iteratation 539, loss: 2.5254976749420166\n",
            "epoch: 1, iteratation 540, loss: 2.513444423675537\n",
            "epoch: 1, iteratation 541, loss: 2.4925074577331543\n",
            "epoch: 1, iteratation 542, loss: 2.580925464630127\n",
            "epoch: 1, iteratation 543, loss: 2.586107015609741\n",
            "epoch: 1, iteratation 544, loss: 2.7014927864074707\n",
            "epoch: 1, iteratation 545, loss: 2.5295777320861816\n",
            "epoch: 1, iteratation 546, loss: 2.5420846939086914\n",
            "epoch: 1, iteratation 547, loss: 2.569120407104492\n",
            "epoch: 1, iteratation 548, loss: 2.46480393409729\n",
            "epoch: 1, iteratation 549, loss: 2.464224338531494\n",
            "epoch: 1, iteratation 550, loss: 2.5839810371398926\n",
            "epoch: 1, iteratation 551, loss: 2.5839953422546387\n",
            "epoch: 1, iteratation 552, loss: 2.5450081825256348\n",
            "epoch: 1, iteratation 553, loss: 2.629256248474121\n",
            "epoch: 1, iteratation 554, loss: 2.806565761566162\n",
            "epoch: 1, iteratation 555, loss: 2.5727038383483887\n",
            "epoch: 1, iteratation 556, loss: 2.557137966156006\n",
            "epoch: 1, iteratation 557, loss: 2.555906295776367\n",
            "epoch: 1, iteratation 558, loss: 2.592473268508911\n",
            "epoch: 1, iteratation 559, loss: 2.4957051277160645\n",
            "epoch: 1, iteratation 560, loss: 2.6405911445617676\n",
            "epoch: 1, iteratation 561, loss: 2.48684024810791\n",
            "epoch: 1, iteratation 562, loss: 2.501931667327881\n",
            "epoch: 1, iteratation 563, loss: 2.6719322204589844\n",
            "epoch: 1, iteratation 564, loss: 2.7855610847473145\n",
            "epoch: 1, iteratation 565, loss: 2.5448708534240723\n",
            "epoch: 1, iteratation 566, loss: 2.5613675117492676\n",
            "epoch: 1, iteratation 567, loss: 2.5882744789123535\n",
            "epoch: 1, iteratation 568, loss: 2.5206799507141113\n",
            "epoch: 1, iteratation 569, loss: 2.4911298751831055\n",
            "epoch: 1, iteratation 570, loss: 2.5307424068450928\n",
            "epoch: 1, iteratation 571, loss: 2.791172504425049\n",
            "epoch: 1, iteratation 572, loss: 2.699326515197754\n",
            "epoch: 1, iteratation 573, loss: 2.6031951904296875\n",
            "epoch: 1, iteratation 574, loss: 2.484696865081787\n",
            "epoch: 1, iteratation 575, loss: 2.4419519901275635\n",
            "epoch: 1, iteratation 576, loss: 2.474944591522217\n",
            "epoch: 1, iteratation 577, loss: 2.63785719871521\n",
            "epoch: 1, iteratation 578, loss: 2.6273837089538574\n",
            "epoch: 1, iteratation 579, loss: 2.653367280960083\n",
            "epoch: 1, iteratation 580, loss: 2.715743064880371\n",
            "epoch: 1, iteratation 581, loss: 2.5330190658569336\n",
            "epoch: 1, iteratation 582, loss: 2.6099486351013184\n",
            "epoch: 1, iteratation 583, loss: 2.5729856491088867\n",
            "epoch: 1, iteratation 584, loss: 2.5034148693084717\n",
            "epoch: 1, iteratation 585, loss: 2.799731731414795\n",
            "epoch: 1, iteratation 586, loss: 2.4634170532226562\n",
            "epoch: 1, iteratation 587, loss: 2.583606481552124\n",
            "epoch: 1, iteratation 588, loss: 2.5301547050476074\n",
            "epoch: 1, iteratation 589, loss: 2.6371078491210938\n",
            "epoch: 1, iteratation 590, loss: 2.588928461074829\n",
            "epoch: 1, iteratation 591, loss: 2.5917506217956543\n",
            "epoch: 1, iteratation 592, loss: 2.549166440963745\n",
            "epoch: 1, iteratation 593, loss: 2.728487730026245\n",
            "epoch: 1, iteratation 594, loss: 2.617125988006592\n",
            "epoch: 1, iteratation 595, loss: 2.567638874053955\n",
            "epoch: 1, iteratation 596, loss: 2.622683525085449\n",
            "epoch: 1, iteratation 597, loss: 2.56943416595459\n",
            "epoch: 1, iteratation 598, loss: 2.48715877532959\n",
            "epoch: 1, iteratation 599, loss: 2.4579620361328125\n",
            "epoch: 1, iteratation 600, loss: 2.5580434799194336\n",
            "epoch: 1, iteratation 601, loss: 2.532015323638916\n",
            "epoch: 1, iteratation 602, loss: 2.5886805057525635\n",
            "epoch: 1, iteratation 603, loss: 2.5268568992614746\n",
            "epoch: 1, iteratation 604, loss: 2.643118143081665\n",
            "epoch: 1, iteratation 605, loss: 2.570657730102539\n",
            "epoch: 1, iteratation 606, loss: 2.5249085426330566\n",
            "epoch: 1, iteratation 607, loss: 2.777284622192383\n",
            "epoch: 1, iteratation 608, loss: 2.4547815322875977\n",
            "epoch: 1, iteratation 609, loss: 2.5072784423828125\n",
            "epoch: 1, iteratation 610, loss: 2.5172605514526367\n",
            "epoch: 1, iteratation 611, loss: 2.4813179969787598\n",
            "epoch: 1, iteratation 612, loss: 2.598806142807007\n",
            "epoch: 1, iteratation 613, loss: 2.7058560848236084\n",
            "epoch: 1, iteratation 614, loss: 2.7540175914764404\n",
            "epoch: 1, iteratation 615, loss: 2.538236618041992\n",
            "epoch: 1, iteratation 616, loss: 2.4855456352233887\n",
            "epoch: 1, iteratation 617, loss: 2.5012528896331787\n",
            "epoch: 1, iteratation 618, loss: 2.6229939460754395\n",
            "epoch: 1, iteratation 619, loss: 2.5238826274871826\n",
            "epoch: 1, iteratation 620, loss: 2.550884246826172\n",
            "epoch: 1, iteratation 621, loss: 2.4275500774383545\n",
            "epoch: 1, iteratation 622, loss: 2.441891670227051\n",
            "epoch: 1, iteratation 623, loss: 2.5484910011291504\n",
            "epoch: 1, iteratation 624, loss: 2.7041633129119873\n",
            "epoch: 1, iteratation 625, loss: 2.492415428161621\n",
            "epoch: 1, iteratation 626, loss: 2.512166738510132\n",
            "epoch: 1, iteratation 627, loss: 2.493610382080078\n",
            "epoch: 1, iteratation 628, loss: 2.681633710861206\n",
            "epoch: 1, iteratation 629, loss: 2.626983404159546\n",
            "epoch: 1, iteratation 630, loss: 2.50781512260437\n",
            "epoch: 1, iteratation 631, loss: 2.530811309814453\n",
            "epoch: 1, iteratation 632, loss: 2.5544419288635254\n",
            "epoch: 1, iteratation 633, loss: 2.6209630966186523\n",
            "epoch: 1, iteratation 634, loss: 2.5133492946624756\n",
            "epoch: 1, iteratation 635, loss: 2.5751280784606934\n",
            "epoch: 1, iteratation 636, loss: 2.6242995262145996\n",
            "epoch: 1, iteratation 637, loss: 2.675617218017578\n",
            "epoch: 1, iteratation 638, loss: 2.529597282409668\n",
            "epoch: 1, iteratation 639, loss: 2.5132386684417725\n",
            "epoch: 1, iteratation 640, loss: 2.489907741546631\n",
            "epoch: 1, iteratation 641, loss: 2.439579725265503\n",
            "epoch: 1, iteratation 642, loss: 2.725773572921753\n",
            "epoch: 1, iteratation 643, loss: 2.556612730026245\n",
            "epoch: 1, iteratation 644, loss: 2.547055721282959\n",
            "epoch: 1, iteratation 645, loss: 2.5108859539031982\n",
            "epoch: 1, iteratation 646, loss: 2.4694151878356934\n",
            "epoch: 1, iteratation 647, loss: 2.5467987060546875\n",
            "epoch: 1, iteratation 648, loss: 2.635918140411377\n",
            "epoch: 1, iteratation 649, loss: 2.507200002670288\n",
            "epoch: 1, iteratation 650, loss: 2.6290407180786133\n",
            "epoch: 1, iteratation 651, loss: 2.520878791809082\n",
            "epoch: 1, iteratation 652, loss: 2.544067859649658\n",
            "epoch: 1, iteratation 653, loss: 2.567441701889038\n",
            "epoch: 1, iteratation 654, loss: 2.6013526916503906\n",
            "epoch: 1, iteratation 655, loss: 2.5921459197998047\n",
            "epoch: 1, iteratation 656, loss: 2.5527243614196777\n",
            "epoch: 1, iteratation 657, loss: 2.708005666732788\n",
            "epoch: 1, iteratation 658, loss: 2.4882514476776123\n",
            "epoch: 1, iteratation 659, loss: 2.4252004623413086\n",
            "epoch: 1, iteratation 660, loss: 2.9392271041870117\n",
            "epoch: 1, iteratation 661, loss: 2.4788966178894043\n",
            "epoch: 1, iteratation 662, loss: 2.506587028503418\n",
            "epoch: 1, iteratation 663, loss: 2.5414493083953857\n",
            "epoch: 1, iteratation 664, loss: 2.488762855529785\n",
            "epoch: 1, iteratation 665, loss: 2.5206241607666016\n",
            "epoch: 1, iteratation 666, loss: 2.5206849575042725\n",
            "epoch: 1, iteratation 667, loss: 2.569931745529175\n",
            "epoch: 1, iteratation 668, loss: 2.4903039932250977\n",
            "epoch: 1, iteratation 669, loss: 2.540034770965576\n",
            "epoch: 1, iteratation 670, loss: 2.8342883586883545\n",
            "epoch: 1, iteratation 671, loss: 2.544447422027588\n",
            "epoch: 1, iteratation 672, loss: 2.4877543449401855\n",
            "epoch: 1, iteratation 673, loss: 2.7177741527557373\n",
            "epoch: 1, iteratation 674, loss: 2.5365121364593506\n",
            "epoch: 1, iteratation 675, loss: 2.505690336227417\n",
            "epoch: 1, iteratation 676, loss: 2.4920597076416016\n",
            "epoch: 1, iteratation 677, loss: 2.5477099418640137\n",
            "epoch: 1, iteratation 678, loss: 2.6496853828430176\n",
            "epoch: 1, iteratation 679, loss: 2.5067338943481445\n",
            "epoch: 1, iteratation 680, loss: 2.4848499298095703\n",
            "epoch: 1, iteratation 681, loss: 2.434622287750244\n",
            "epoch: 1, iteratation 682, loss: 2.51942777633667\n",
            "epoch: 1, iteratation 683, loss: 2.576247453689575\n",
            "epoch: 1, iteratation 684, loss: 2.774393081665039\n",
            "epoch: 1, iteratation 685, loss: 2.539539337158203\n",
            "epoch: 1, iteratation 686, loss: 2.5264339447021484\n",
            "epoch: 1, iteratation 687, loss: 2.5385217666625977\n",
            "epoch: 1, iteratation 688, loss: 2.644224166870117\n",
            "epoch: 1, iteratation 689, loss: 2.545060634613037\n",
            "epoch: 1, iteratation 690, loss: 2.5469274520874023\n",
            "epoch: 1, iteratation 691, loss: 2.523770332336426\n",
            "epoch: 1, iteratation 692, loss: 2.5181212425231934\n",
            "epoch: 1, iteratation 693, loss: 2.5341310501098633\n",
            "epoch: 1, iteratation 694, loss: 2.562654972076416\n",
            "epoch: 1, iteratation 695, loss: 2.504879951477051\n",
            "epoch: 1, iteratation 696, loss: 2.547322988510132\n",
            "epoch: 1, iteratation 697, loss: 2.661661386489868\n",
            "epoch: 1, iteratation 698, loss: 2.663438558578491\n",
            "epoch: 1, iteratation 699, loss: 2.4648945331573486\n",
            "epoch: 1, iteratation 700, loss: 2.461585760116577\n",
            "epoch: 1, iteratation 701, loss: 2.522413730621338\n",
            "epoch: 1, iteratation 702, loss: 2.564581871032715\n",
            "epoch: 1, iteratation 703, loss: 2.531510353088379\n",
            "epoch: 1, iteratation 704, loss: 2.5420265197753906\n",
            "epoch: 1, iteratation 705, loss: 2.522542715072632\n",
            "epoch: 1, iteratation 706, loss: 2.481865882873535\n",
            "epoch: 1, iteratation 707, loss: 2.4703054428100586\n",
            "epoch: 1, iteratation 708, loss: 2.516524314880371\n",
            "epoch: 1, iteratation 709, loss: 2.5517289638519287\n",
            "epoch: 1, iteratation 710, loss: 2.4988608360290527\n",
            "epoch: 1, iteratation 711, loss: 2.452988386154175\n",
            "epoch: 1, iteratation 712, loss: 2.5701494216918945\n",
            "epoch: 1, iteratation 713, loss: 2.7334201335906982\n",
            "epoch: 1, iteratation 714, loss: 2.6107876300811768\n",
            "epoch: 1, iteratation 715, loss: 2.5588440895080566\n",
            "epoch: 1, iteratation 716, loss: 2.5857138633728027\n",
            "epoch: 1, iteratation 717, loss: 2.5830276012420654\n",
            "epoch: 1, iteratation 718, loss: 2.5015602111816406\n",
            "epoch: 1, iteratation 719, loss: 2.560218334197998\n",
            "epoch: 1, iteratation 720, loss: 2.5828893184661865\n",
            "epoch: 1, iteratation 721, loss: 2.4588119983673096\n",
            "epoch: 1, iteratation 722, loss: 2.4594573974609375\n",
            "epoch: 1, iteratation 723, loss: 2.5468645095825195\n",
            "epoch: 1, iteratation 724, loss: 2.512145757675171\n",
            "epoch: 1, iteratation 725, loss: 2.631014108657837\n",
            "epoch: 1, iteratation 726, loss: 2.478684902191162\n",
            "epoch: 1, iteratation 727, loss: 2.5131640434265137\n",
            "epoch: 1, iteratation 728, loss: 2.526296615600586\n",
            "epoch: 1, iteratation 729, loss: 2.615405559539795\n",
            "epoch: 1, iteratation 730, loss: 2.5207223892211914\n",
            "epoch: 1, iteratation 731, loss: 2.4961724281311035\n",
            "epoch: 1, iteratation 732, loss: 2.8778762817382812\n",
            "epoch: 1, iteratation 733, loss: 2.699770450592041\n",
            "epoch: 1, iteratation 734, loss: 2.48341703414917\n",
            "epoch: 1, iteratation 735, loss: 2.4965105056762695\n",
            "epoch: 1, iteratation 736, loss: 2.4942023754119873\n",
            "epoch: 1, iteratation 737, loss: 2.58306622505188\n",
            "epoch: 1, iteratation 738, loss: 2.523613929748535\n",
            "epoch: 1, iteratation 739, loss: 2.5020971298217773\n",
            "epoch: 1, iteratation 740, loss: 2.4851908683776855\n",
            "epoch: 1, iteratation 741, loss: 2.4492928981781006\n",
            "epoch: 1, iteratation 742, loss: 2.4543986320495605\n",
            "epoch: 1, iteratation 743, loss: 2.4340996742248535\n",
            "epoch: 1, iteratation 744, loss: 2.4879069328308105\n",
            "epoch: 1, iteratation 745, loss: 2.5230369567871094\n",
            "epoch: 1, iteratation 746, loss: 2.4540326595306396\n",
            "epoch: 1, iteratation 747, loss: 2.4537532329559326\n",
            "epoch: 1, iteratation 748, loss: 2.540562152862549\n",
            "epoch: 1, iteratation 749, loss: 2.5147690773010254\n",
            "epoch: 1, iteratation 750, loss: 2.443516731262207\n",
            "epoch: 1, iteratation 751, loss: 2.529327869415283\n",
            "epoch: 1, iteratation 752, loss: 2.479673147201538\n",
            "epoch: 1, iteratation 753, loss: 2.4422996044158936\n",
            "epoch: 1, iteratation 754, loss: 2.542410373687744\n",
            "epoch: 1, iteratation 755, loss: 2.4749038219451904\n",
            "epoch: 1, iteratation 756, loss: 2.5050177574157715\n",
            "epoch: 1, iteratation 757, loss: 2.4148640632629395\n",
            "epoch: 1, iteratation 758, loss: 2.5518980026245117\n",
            "epoch: 1, iteratation 759, loss: 2.451286554336548\n",
            "epoch: 1, iteratation 760, loss: 2.5117783546447754\n",
            "epoch: 1, iteratation 761, loss: 2.3762471675872803\n",
            "epoch: 1, iteratation 762, loss: 2.51950740814209\n",
            "epoch: 1, iteratation 763, loss: 2.6145834922790527\n",
            "epoch: 1, iteratation 764, loss: 2.597609281539917\n",
            "epoch: 1, iteratation 765, loss: 2.4760420322418213\n",
            "epoch: 1, iteratation 766, loss: 2.4287033081054688\n",
            "epoch: 1, iteratation 767, loss: 2.463618755340576\n",
            "epoch: 1, iteratation 768, loss: 2.475858211517334\n",
            "epoch: 1, iteratation 769, loss: 2.4582552909851074\n",
            "epoch: 1, iteratation 770, loss: 2.5784833431243896\n",
            "epoch: 1, iteratation 771, loss: 2.399066686630249\n",
            "epoch: 1, iteratation 772, loss: 2.481618881225586\n",
            "epoch: 1, iteratation 773, loss: 2.5111641883850098\n",
            "epoch: 1, iteratation 774, loss: 2.4425392150878906\n",
            "epoch: 1, iteratation 775, loss: 2.463080406188965\n",
            "epoch: 1, iteratation 776, loss: 2.4317986965179443\n",
            "epoch: 1, iteratation 777, loss: 2.367304563522339\n",
            "epoch: 1, iteratation 778, loss: 2.535728931427002\n",
            "epoch: 1, iteratation 779, loss: 2.483124256134033\n",
            "epoch: 1, iteratation 780, loss: 2.528794050216675\n",
            "epoch: 1, iteratation 781, loss: 2.4910402297973633\n",
            "epoch: 1, iteratation 782, loss: 2.4319186210632324\n",
            "epoch: 1, iteratation 783, loss: 2.4375295639038086\n",
            "epoch: 1, iteratation 784, loss: 2.50356125831604\n",
            "epoch: 1, iteratation 785, loss: 2.491854190826416\n",
            "epoch: 1, iteratation 786, loss: 2.6707801818847656\n",
            "epoch: 1, iteratation 787, loss: 2.409296989440918\n",
            "epoch: 1, iteratation 788, loss: 2.4619481563568115\n",
            "epoch: 1, iteratation 789, loss: 2.6533303260803223\n",
            "epoch: 1, iteratation 790, loss: 2.4290199279785156\n",
            "epoch: 1, iteratation 791, loss: 2.4170119762420654\n",
            "epoch: 1, iteratation 792, loss: 2.36898136138916\n",
            "epoch: 1, iteratation 793, loss: 2.430101156234741\n",
            "epoch: 1, iteratation 794, loss: 2.4169373512268066\n",
            "epoch: 1, iteratation 795, loss: 2.377150535583496\n",
            "epoch: 1, iteratation 796, loss: 2.455723285675049\n",
            "epoch: 1, iteratation 797, loss: 2.4429662227630615\n",
            "epoch: 1, iteratation 798, loss: 2.4649596214294434\n",
            "epoch: 1, iteratation 799, loss: 2.455181837081909\n",
            "epoch: 1, iteratation 800, loss: 2.5649876594543457\n",
            "epoch: 1, iteratation 801, loss: 2.5175528526306152\n",
            "epoch: 1, iteratation 802, loss: 2.398099899291992\n",
            "epoch: 1, iteratation 803, loss: 2.6070005893707275\n",
            "epoch: 1, iteratation 804, loss: 2.540076971054077\n",
            "epoch: 1, iteratation 805, loss: 2.374591827392578\n",
            "epoch: 1, iteratation 806, loss: 2.4085605144500732\n",
            "epoch: 1, iteratation 807, loss: 2.3110246658325195\n",
            "epoch: 1, iteratation 808, loss: 2.4725613594055176\n",
            "epoch: 1, iteratation 809, loss: 2.3581960201263428\n",
            "epoch: 1, iteratation 810, loss: 2.4607863426208496\n",
            "epoch: 1, iteratation 811, loss: 2.526094913482666\n",
            "epoch: 1, iteratation 812, loss: 2.4427003860473633\n",
            "epoch: 1, iteratation 813, loss: 2.5605733394622803\n",
            "epoch: 1, iteratation 814, loss: 2.3708529472351074\n",
            "epoch: 1, iteratation 815, loss: 2.4291951656341553\n",
            "epoch: 1, iteratation 816, loss: 2.3736960887908936\n",
            "epoch: 1, iteratation 817, loss: 2.382194995880127\n",
            "epoch: 1, iteratation 818, loss: 2.448890209197998\n",
            "epoch: 1, iteratation 819, loss: 2.4781060218811035\n",
            "epoch: 1, iteratation 820, loss: 2.4432616233825684\n",
            "epoch: 1, iteratation 821, loss: 2.566697359085083\n",
            "epoch: 1, iteratation 822, loss: 2.4042844772338867\n",
            "epoch: 1, iteratation 823, loss: 2.4374427795410156\n",
            "epoch: 1, iteratation 824, loss: 2.4266762733459473\n",
            "epoch: 1, iteratation 825, loss: 2.4180569648742676\n",
            "epoch: 1, iteratation 826, loss: 2.4004464149475098\n",
            "epoch: 1, iteratation 827, loss: 2.3515090942382812\n",
            "epoch: 1, iteratation 828, loss: 2.322514057159424\n",
            "epoch: 1, iteratation 829, loss: 2.404289722442627\n",
            "epoch: 1, iteratation 830, loss: 2.4084482192993164\n",
            "epoch: 1, iteratation 831, loss: 2.419691801071167\n",
            "epoch: 1, iteratation 832, loss: 2.731769323348999\n",
            "epoch: 1, iteratation 833, loss: 2.3594789505004883\n",
            "epoch: 1, iteratation 834, loss: 2.536334753036499\n",
            "epoch: 1, iteratation 835, loss: 2.451578378677368\n",
            "epoch: 1, iteratation 836, loss: 2.3293991088867188\n",
            "epoch: 1, iteratation 837, loss: 2.363062858581543\n",
            "epoch: 1, iteratation 838, loss: 2.321688175201416\n",
            "epoch: 1, iteratation 839, loss: 2.410611629486084\n",
            "epoch: 1, iteratation 840, loss: 2.5197761058807373\n",
            "epoch: 1, iteratation 841, loss: 2.398125171661377\n",
            "epoch: 1, iteratation 842, loss: 2.364816427230835\n",
            "epoch: 1, iteratation 843, loss: 2.409853458404541\n",
            "epoch: 1, iteratation 844, loss: 2.466963529586792\n",
            "epoch: 1, iteratation 845, loss: 2.4440360069274902\n",
            "epoch: 1, iteratation 846, loss: 2.3529162406921387\n",
            "epoch: 1, iteratation 847, loss: 2.4478936195373535\n",
            "epoch: 1, iteratation 848, loss: 2.807887554168701\n",
            "epoch: 1, iteratation 849, loss: 2.391669273376465\n",
            "epoch: 1, iteratation 850, loss: 2.4474997520446777\n",
            "epoch: 1, iteratation 851, loss: 2.417174816131592\n",
            "epoch: 1, iteratation 852, loss: 2.289808988571167\n",
            "epoch: 1, iteratation 853, loss: 2.654958486557007\n",
            "epoch: 1, iteratation 854, loss: 2.3870158195495605\n",
            "epoch: 1, iteratation 855, loss: 2.3562817573547363\n",
            "epoch: 1, iteratation 856, loss: 2.348503351211548\n",
            "epoch: 1, iteratation 857, loss: 2.4271152019500732\n",
            "epoch: 1, iteratation 858, loss: 2.3823657035827637\n",
            "epoch: 1, iteratation 859, loss: 2.5898139476776123\n",
            "epoch: 1, iteratation 860, loss: 2.3245410919189453\n",
            "epoch: 1, iteratation 861, loss: 2.396310806274414\n",
            "epoch: 1, iteratation 862, loss: 2.3138198852539062\n",
            "epoch: 1, iteratation 863, loss: 2.309204578399658\n",
            "epoch: 1, iteratation 864, loss: 2.37518310546875\n",
            "epoch: 1, iteratation 865, loss: 2.4256839752197266\n",
            "epoch: 1, iteratation 866, loss: 2.4182419776916504\n",
            "epoch: 1, iteratation 867, loss: 2.3022994995117188\n",
            "epoch: 1, iteratation 868, loss: 2.3760874271392822\n",
            "epoch: 1, iteratation 869, loss: 2.278151273727417\n",
            "epoch: 1, iteratation 870, loss: 2.408524990081787\n",
            "epoch: 1, iteratation 871, loss: 2.3416154384613037\n",
            "epoch: 1, iteratation 872, loss: 2.2999284267425537\n",
            "epoch: 1, iteratation 873, loss: 2.3373074531555176\n",
            "epoch: 1, iteratation 874, loss: 2.360994577407837\n",
            "epoch: 1, iteratation 875, loss: 2.3872690200805664\n",
            "epoch: 1, iteratation 876, loss: 2.4076809883117676\n",
            "epoch: 1, iteratation 877, loss: 2.353878974914551\n",
            "epoch: 1, iteratation 878, loss: 2.3595643043518066\n",
            "epoch: 1, iteratation 879, loss: 2.4231157302856445\n",
            "epoch: 1, iteratation 880, loss: 2.3146958351135254\n",
            "epoch: 1, iteratation 881, loss: 2.31709623336792\n",
            "epoch: 1, iteratation 882, loss: 2.3515467643737793\n",
            "epoch: 1, iteratation 883, loss: 2.4109129905700684\n",
            "epoch: 1, iteratation 884, loss: 2.4497437477111816\n",
            "epoch: 1, iteratation 885, loss: 2.2545456886291504\n",
            "epoch: 1, iteratation 886, loss: 2.329005241394043\n",
            "epoch: 1, iteratation 887, loss: 2.270106315612793\n",
            "epoch: 1, iteratation 888, loss: 2.324577808380127\n",
            "epoch: 1, iteratation 889, loss: 2.3592660427093506\n",
            "epoch: 1, iteratation 890, loss: 2.34991717338562\n",
            "epoch: 1, iteratation 891, loss: 2.266146421432495\n",
            "epoch: 1, iteratation 892, loss: 2.2661566734313965\n",
            "epoch: 1, iteratation 893, loss: 2.290513038635254\n",
            "epoch: 1, iteratation 894, loss: 2.343507766723633\n",
            "epoch: 1, iteratation 895, loss: 2.3206796646118164\n",
            "epoch: 1, iteratation 896, loss: 2.348886251449585\n",
            "epoch: 1, iteratation 897, loss: 2.2998030185699463\n",
            "epoch: 1, iteratation 898, loss: 2.326449394226074\n",
            "epoch: 1, iteratation 899, loss: 2.345564126968384\n",
            "epoch: 1, iteratation 900, loss: 2.320645332336426\n",
            "epoch: 1, iteratation 901, loss: 2.287538766860962\n",
            "epoch: 1, iteratation 902, loss: 2.3142213821411133\n",
            "epoch: 1, iteratation 903, loss: 2.328484535217285\n",
            "epoch: 1, iteratation 904, loss: 2.2654976844787598\n",
            "epoch: 1, iteratation 905, loss: 2.3348069190979004\n",
            "epoch: 1, iteratation 906, loss: 2.331796169281006\n",
            "epoch: 1, iteratation 907, loss: 2.3551361560821533\n",
            "epoch: 1, iteratation 908, loss: 2.6374545097351074\n",
            "epoch: 1, iteratation 909, loss: 2.3078789710998535\n",
            "epoch: 1, iteratation 910, loss: 2.433584213256836\n",
            "epoch: 1, iteratation 911, loss: 2.3678174018859863\n",
            "epoch: 1, iteratation 912, loss: 2.2668657302856445\n",
            "epoch: 1, iteratation 913, loss: 2.2859959602355957\n",
            "epoch: 1, iteratation 914, loss: 2.3552916049957275\n",
            "epoch: 1, iteratation 915, loss: 2.3518929481506348\n",
            "epoch: 1, iteratation 916, loss: 2.3732199668884277\n",
            "epoch: 1, iteratation 917, loss: 2.3959414958953857\n",
            "epoch: 1, iteratation 918, loss: 2.611610174179077\n",
            "epoch: 1, iteratation 919, loss: 2.408564567565918\n",
            "epoch: 1, iteratation 920, loss: 2.2558276653289795\n",
            "epoch: 1, iteratation 921, loss: 2.255215644836426\n",
            "epoch: 1, iteratation 922, loss: 2.378345012664795\n",
            "epoch: 1, iteratation 923, loss: 2.39341402053833\n",
            "epoch: 1, iteratation 924, loss: 2.3909852504730225\n",
            "epoch: 1, iteratation 925, loss: 2.2771201133728027\n",
            "epoch: 1, iteratation 926, loss: 2.352583885192871\n",
            "epoch: 1, iteratation 927, loss: 2.2975356578826904\n",
            "epoch: 1, iteratation 928, loss: 2.3820953369140625\n",
            "epoch: 1, iteratation 929, loss: 2.3900222778320312\n",
            "epoch: 1, iteratation 930, loss: 2.402578353881836\n",
            "epoch: 1, iteratation 931, loss: 2.1977221965789795\n",
            "epoch: 1, iteratation 932, loss: 2.6212878227233887\n",
            "epoch: 1, iteratation 933, loss: 2.3706741333007812\n",
            "epoch: 1, iteratation 934, loss: 2.239617347717285\n",
            "epoch: 1, iteratation 935, loss: 2.3633038997650146\n",
            "epoch: 1, iteratation 936, loss: 2.2644033432006836\n",
            "epoch: 1, iteratation 937, loss: 2.2850215435028076\n",
            "epoch: 1, iteratation 938, loss: 2.513775587081909\n",
            "epoch: 1, iteratation 939, loss: 2.4099299907684326\n",
            "epoch: 1, iteratation 940, loss: 2.4008891582489014\n",
            "epoch: 1, iteratation 941, loss: 2.3243839740753174\n",
            "epoch: 1, iteratation 942, loss: 2.3031136989593506\n",
            "epoch: 1, iteratation 943, loss: 2.2026326656341553\n",
            "epoch: 1, iteratation 944, loss: 2.2828145027160645\n",
            "epoch: 1, iteratation 945, loss: 2.3958096504211426\n",
            "epoch: 1, iteratation 946, loss: 2.3544983863830566\n",
            "epoch: 1, iteratation 947, loss: 2.436150074005127\n",
            "epoch: 1, iteratation 948, loss: 2.219107151031494\n",
            "epoch: 1, iteratation 949, loss: 2.364584445953369\n",
            "epoch: 1, iteratation 950, loss: 2.279203176498413\n",
            "epoch: 1, iteratation 951, loss: 2.272639751434326\n",
            "epoch: 1, iteratation 952, loss: 2.213104009628296\n",
            "epoch: 1, iteratation 953, loss: 2.2984800338745117\n",
            "epoch: 1, iteratation 954, loss: 2.329145908355713\n",
            "epoch: 1, iteratation 955, loss: 2.3408164978027344\n",
            "epoch: 1, iteratation 956, loss: 2.300077199935913\n",
            "epoch: 1, iteratation 957, loss: 2.1308188438415527\n",
            "epoch: 1, iteratation 958, loss: 2.39315128326416\n",
            "epoch: 1, iteratation 959, loss: 2.2365598678588867\n",
            "epoch: 1, iteratation 960, loss: 2.2549328804016113\n",
            "epoch: 1, iteratation 961, loss: 2.20989990234375\n",
            "epoch: 1, iteratation 962, loss: 2.2771873474121094\n",
            "epoch: 1, iteratation 963, loss: 2.297539472579956\n",
            "epoch: 1, iteratation 964, loss: 2.6251540184020996\n",
            "epoch: 1, iteratation 965, loss: 2.1850438117980957\n",
            "epoch: 1, iteratation 966, loss: 2.4324278831481934\n",
            "epoch: 1, iteratation 967, loss: 2.4769601821899414\n",
            "epoch: 1, iteratation 968, loss: 2.347384452819824\n",
            "epoch: 1, iteratation 969, loss: 2.280909776687622\n",
            "epoch: 1, iteratation 970, loss: 2.3728809356689453\n",
            "epoch: 1, iteratation 971, loss: 2.4663772583007812\n",
            "epoch: 1, iteratation 972, loss: 2.3700168132781982\n",
            "epoch: 1, iteratation 973, loss: 2.2759830951690674\n",
            "epoch: 1, iteratation 974, loss: 2.3613462448120117\n",
            "epoch: 1, iteratation 975, loss: 2.3017592430114746\n",
            "epoch: 1, iteratation 976, loss: 2.2510030269622803\n",
            "epoch: 1, iteratation 977, loss: 2.2393553256988525\n",
            "epoch: 1, iteratation 978, loss: 2.3518009185791016\n",
            "epoch: 1, iteratation 979, loss: 2.2211594581604004\n",
            "epoch: 1, iteratation 980, loss: 2.2610719203948975\n",
            "epoch: 1, iteratation 981, loss: 2.2621846199035645\n",
            "epoch: 1, iteratation 982, loss: 2.2425057888031006\n",
            "epoch: 1, iteratation 983, loss: 2.244734287261963\n",
            "epoch: 1, iteratation 984, loss: 2.2545409202575684\n",
            "epoch: 1, iteratation 985, loss: 2.281214714050293\n",
            "epoch: 1, iteratation 986, loss: 2.2437312602996826\n",
            "epoch: 1, iteratation 987, loss: 2.3515849113464355\n",
            "epoch: 1, iteratation 988, loss: 2.3285298347473145\n",
            "epoch: 1, iteratation 989, loss: 2.196598529815674\n",
            "epoch: 1, iteratation 990, loss: 2.284900188446045\n",
            "epoch: 1, iteratation 991, loss: 2.1920485496520996\n",
            "epoch: 1, iteratation 992, loss: 2.2729618549346924\n",
            "epoch: 1, iteratation 993, loss: 2.3256235122680664\n",
            "epoch: 1, iteratation 994, loss: 2.1565475463867188\n",
            "epoch: 1, iteratation 995, loss: 2.2204947471618652\n",
            "epoch: 1, iteratation 996, loss: 2.178156614303589\n",
            "epoch: 1, iteratation 997, loss: 2.2357146739959717\n",
            "epoch: 1, iteratation 998, loss: 2.237272024154663\n",
            "epoch: 1, iteratation 999, loss: 2.207120895385742\n",
            "epoch: 1, iteratation 1000, loss: 2.099255323410034\n",
            "epoch: 1, iteratation 1001, loss: 2.138619899749756\n",
            "epoch: 1, iteratation 1002, loss: 2.0898187160491943\n",
            "epoch: 1, iteratation 1003, loss: 2.2966716289520264\n",
            "epoch: 1, iteratation 1004, loss: 2.1475625038146973\n",
            "epoch: 1, iteratation 1005, loss: 2.147824287414551\n",
            "epoch: 1, iteratation 1006, loss: 2.267371654510498\n",
            "epoch: 1, iteratation 1007, loss: 2.0805392265319824\n",
            "epoch: 1, iteratation 1008, loss: 2.2265470027923584\n",
            "epoch: 1, iteratation 1009, loss: 2.2938201427459717\n",
            "epoch: 1, iteratation 1010, loss: 2.305698871612549\n",
            "epoch: 1, iteratation 1011, loss: 2.4768598079681396\n",
            "epoch: 1, iteratation 1012, loss: 2.4848809242248535\n",
            "epoch: 1, iteratation 1013, loss: 2.319807767868042\n",
            "epoch: 1, iteratation 1014, loss: 2.2012152671813965\n",
            "epoch: 1, iteratation 1015, loss: 2.312154769897461\n",
            "epoch: 1, iteratation 1016, loss: 2.1963768005371094\n",
            "epoch: 1, iteratation 1017, loss: 2.320782423019409\n",
            "epoch: 1, iteratation 1018, loss: 2.2889585494995117\n",
            "epoch: 1, iteratation 1019, loss: 2.1194584369659424\n",
            "epoch: 1, iteratation 1020, loss: 2.2120349407196045\n",
            "epoch: 1, iteratation 1021, loss: 2.2507009506225586\n",
            "epoch: 1, iteratation 1022, loss: 2.2354657649993896\n",
            "epoch: 1, iteratation 1023, loss: 2.2452588081359863\n",
            "epoch: 1, iteratation 1024, loss: 2.2938594818115234\n",
            "epoch: 1, iteratation 1025, loss: 2.417553424835205\n",
            "epoch: 1, iteratation 1026, loss: 2.341036319732666\n",
            "epoch: 1, iteratation 1027, loss: 2.210390567779541\n",
            "epoch: 1, iteratation 1028, loss: 2.4010398387908936\n",
            "epoch: 1, iteratation 1029, loss: 2.0997509956359863\n",
            "epoch: 1, iteratation 1030, loss: 2.2799739837646484\n",
            "epoch: 1, iteratation 1031, loss: 2.4322762489318848\n",
            "epoch: 1, iteratation 1032, loss: 2.3677563667297363\n",
            "epoch: 1, iteratation 1033, loss: 2.2711081504821777\n",
            "epoch: 1, iteratation 1034, loss: 2.270319938659668\n",
            "epoch: 1, iteratation 1035, loss: 2.2334694862365723\n",
            "epoch: 1, iteratation 1036, loss: 2.3079895973205566\n",
            "epoch: 1, iteratation 1037, loss: 2.1866366863250732\n",
            "epoch: 1, iteratation 1038, loss: 2.3298439979553223\n",
            "epoch: 1, iteratation 1039, loss: 2.1873233318328857\n",
            "epoch: 1, iteratation 1040, loss: 2.1704375743865967\n",
            "epoch: 1, iteratation 1041, loss: 2.244840383529663\n",
            "epoch: 1, iteratation 1042, loss: 2.0985145568847656\n",
            "epoch: 1, iteratation 1043, loss: 2.1978349685668945\n",
            "epoch: 1, iteratation 1044, loss: 2.2376997470855713\n",
            "epoch: 1, iteratation 1045, loss: 2.2581255435943604\n",
            "epoch: 1, iteratation 1046, loss: 2.1089859008789062\n",
            "epoch: 1, iteratation 1047, loss: 2.259333610534668\n",
            "epoch: 1, iteratation 1048, loss: 2.341099262237549\n",
            "epoch: 1, iteratation 1049, loss: 2.144382953643799\n",
            "epoch: 1, iteratation 1050, loss: 2.2716352939605713\n",
            "epoch: 1, iteratation 1051, loss: 2.0979256629943848\n",
            "epoch: 1, iteratation 1052, loss: 2.3298192024230957\n",
            "epoch: 1, iteratation 1053, loss: 2.1443982124328613\n",
            "epoch: 1, iteratation 1054, loss: 2.181236982345581\n",
            "epoch: 1, iteratation 1055, loss: 2.234832286834717\n",
            "epoch: 1, iteratation 1056, loss: 2.176713705062866\n",
            "epoch: 1, iteratation 1057, loss: 2.301100015640259\n",
            "epoch: 1, iteratation 1058, loss: 2.111358165740967\n",
            "epoch: 1, iteratation 1059, loss: 1.9987704753875732\n",
            "epoch: 1, iteratation 1060, loss: 2.1048378944396973\n",
            "epoch: 1, iteratation 1061, loss: 2.4126858711242676\n",
            "epoch: 1, iteratation 1062, loss: 2.382694721221924\n",
            "epoch: 1, iteratation 1063, loss: 2.125012159347534\n",
            "epoch: 1, iteratation 1064, loss: 2.1096034049987793\n",
            "epoch: 1, iteratation 1065, loss: 2.376465320587158\n",
            "epoch: 1, iteratation 1066, loss: 2.2573657035827637\n",
            "epoch: 1, iteratation 1067, loss: 2.1636672019958496\n",
            "epoch: 1, iteratation 1068, loss: 2.2650704383850098\n",
            "epoch: 1, iteratation 1069, loss: 2.214855909347534\n",
            "epoch: 1, iteratation 1070, loss: 2.2347970008850098\n",
            "epoch: 1, iteratation 1071, loss: 2.15165376663208\n",
            "epoch: 1, iteratation 1072, loss: 2.1183180809020996\n",
            "epoch: 1, iteratation 1073, loss: 2.146148204803467\n",
            "epoch: 1, iteratation 1074, loss: 2.038785934448242\n",
            "epoch: 1, iteratation 1075, loss: 2.207746982574463\n",
            "epoch: 1, iteratation 1076, loss: 2.0822839736938477\n",
            "epoch: 1, iteratation 1077, loss: 2.1515398025512695\n",
            "epoch: 1, iteratation 1078, loss: 2.132660388946533\n",
            "epoch: 1, iteratation 1079, loss: 2.0844054222106934\n",
            "epoch: 1, iteratation 1080, loss: 2.1117911338806152\n",
            "epoch: 1, iteratation 1081, loss: 2.2708802223205566\n",
            "epoch: 1, iteratation 1082, loss: 2.206965446472168\n",
            "epoch: 1, iteratation 1083, loss: 2.283327102661133\n",
            "epoch: 1, iteratation 1084, loss: 2.132889986038208\n",
            "epoch: 1, iteratation 1085, loss: 2.1495814323425293\n",
            "epoch: 1, iteratation 1086, loss: 2.0763401985168457\n",
            "epoch: 1, iteratation 1087, loss: 2.175809383392334\n",
            "epoch: 1, iteratation 1088, loss: 2.0747389793395996\n",
            "epoch: 1, iteratation 1089, loss: 2.103372573852539\n",
            "epoch: 1, iteratation 1090, loss: 2.152907371520996\n",
            "epoch: 1, iteratation 1091, loss: 2.0585148334503174\n",
            "epoch: 1, iteratation 1092, loss: 2.3033254146575928\n",
            "epoch: 1, iteratation 1093, loss: 2.3283872604370117\n",
            "epoch: 1, iteratation 1094, loss: 2.2151360511779785\n",
            "epoch: 1, iteratation 1095, loss: 2.088331937789917\n",
            "epoch: 1, iteratation 1096, loss: 2.0106382369995117\n",
            "epoch: 1, iteratation 1097, loss: 2.204599380493164\n",
            "epoch: 1, iteratation 1098, loss: 2.0381383895874023\n",
            "epoch: 1, iteratation 1099, loss: 2.136406660079956\n",
            "epoch: 1, iteratation 1100, loss: 2.2735610008239746\n",
            "epoch: 1, iteratation 1101, loss: 2.251674175262451\n",
            "epoch: 1, iteratation 1102, loss: 2.092653751373291\n",
            "epoch: 1, iteratation 1103, loss: 2.205172061920166\n",
            "epoch: 1, iteratation 1104, loss: 2.099663496017456\n",
            "epoch: 1, iteratation 1105, loss: 2.247121572494507\n",
            "epoch: 1, iteratation 1106, loss: 2.1981732845306396\n",
            "epoch: 1, iteratation 1107, loss: 2.279228687286377\n",
            "epoch: 1, iteratation 1108, loss: 2.232255458831787\n",
            "epoch: 1, iteratation 1109, loss: 2.118947744369507\n",
            "epoch: 1, iteratation 1110, loss: 2.091438055038452\n",
            "epoch: 1, iteratation 1111, loss: 2.1843810081481934\n",
            "epoch: 1, iteratation 1112, loss: 2.23417329788208\n",
            "epoch: 1, iteratation 1113, loss: 2.101598024368286\n",
            "epoch: 1, iteratation 1114, loss: 2.256234645843506\n",
            "epoch: 1, iteratation 1115, loss: 2.2222201824188232\n",
            "epoch: 1, iteratation 1116, loss: 2.0634613037109375\n",
            "epoch: 1, iteratation 1117, loss: 2.0402915477752686\n",
            "epoch: 1, iteratation 1118, loss: 2.1459901332855225\n",
            "epoch: 1, iteratation 1119, loss: 2.114819049835205\n",
            "epoch: 1, iteratation 1120, loss: 2.1963627338409424\n",
            "epoch: 1, iteratation 1121, loss: 2.170919418334961\n",
            "epoch: 1, iteratation 1122, loss: 2.0791642665863037\n",
            "epoch: 1, iteratation 1123, loss: 2.071409225463867\n",
            "epoch: 1, iteratation 1124, loss: 2.115112781524658\n",
            "epoch: 1, iteratation 1125, loss: 2.3154733180999756\n",
            "epoch: 1, iteratation 1126, loss: 2.144047260284424\n",
            "epoch: 1, iteratation 1127, loss: 2.132335662841797\n",
            "epoch: 1, iteratation 1128, loss: 2.069709062576294\n",
            "epoch: 1, iteratation 1129, loss: 2.619513511657715\n",
            "epoch: 1, iteratation 1130, loss: 2.2310986518859863\n",
            "epoch: 1, iteratation 1131, loss: 2.1616830825805664\n",
            "epoch: 1, iteratation 1132, loss: 2.0333364009857178\n",
            "epoch: 1, iteratation 1133, loss: 2.2057721614837646\n",
            "epoch: 1, iteratation 1134, loss: 2.0486080646514893\n",
            "epoch: 1, iteratation 1135, loss: 2.1862409114837646\n",
            "epoch: 1, iteratation 1136, loss: 2.1456780433654785\n",
            "epoch: 1, iteratation 1137, loss: 2.2191367149353027\n",
            "epoch: 1, iteratation 1138, loss: 2.1102182865142822\n",
            "epoch: 1, iteratation 1139, loss: 2.060638904571533\n",
            "epoch: 1, iteratation 1140, loss: 2.1034488677978516\n",
            "epoch: 1, iteratation 1141, loss: 2.1728692054748535\n",
            "epoch: 1, iteratation 1142, loss: 2.2952184677124023\n",
            "epoch: 1, iteratation 1143, loss: 2.084794521331787\n",
            "epoch: 1, iteratation 1144, loss: 2.2731924057006836\n",
            "epoch: 1, iteratation 1145, loss: 2.163764238357544\n",
            "epoch: 1, iteratation 1146, loss: 2.087059736251831\n",
            "epoch: 1, iteratation 1147, loss: 2.107090950012207\n",
            "epoch: 1, iteratation 1148, loss: 2.1496951580047607\n",
            "epoch: 1, iteratation 1149, loss: 2.090664863586426\n",
            "epoch: 1, iteratation 1150, loss: 2.1036384105682373\n",
            "epoch: 1, iteratation 1151, loss: 2.1468868255615234\n",
            "epoch: 1, iteratation 1152, loss: 2.0669143199920654\n",
            "epoch: 1, iteratation 1153, loss: 2.1220757961273193\n",
            "epoch: 1, iteratation 1154, loss: 2.06695556640625\n",
            "epoch: 1, iteratation 1155, loss: 2.130047559738159\n",
            "epoch: 1, iteratation 1156, loss: 2.1872568130493164\n",
            "epoch: 1, iteratation 1157, loss: 2.1447737216949463\n",
            "epoch: 1, iteratation 1158, loss: 2.216704845428467\n",
            "epoch: 1, iteratation 1159, loss: 2.0914721488952637\n",
            "epoch: 1, iteratation 1160, loss: 2.2495551109313965\n",
            "epoch: 1, iteratation 1161, loss: 2.372607707977295\n",
            "epoch: 1, iteratation 1162, loss: 2.1701772212982178\n",
            "epoch: 1, iteratation 1163, loss: 2.249328374862671\n",
            "epoch: 1, iteratation 1164, loss: 2.123196601867676\n",
            "epoch: 1, iteratation 1165, loss: 2.190830707550049\n",
            "epoch: 1, iteratation 1166, loss: 2.2619900703430176\n",
            "epoch: 1, iteratation 1167, loss: 2.121070623397827\n",
            "epoch: 1, iteratation 1168, loss: 2.134544849395752\n",
            "epoch: 1, iteratation 1169, loss: 2.003988027572632\n",
            "epoch: 1, iteratation 1170, loss: 2.0822577476501465\n",
            "epoch: 1, iteratation 1171, loss: 2.1507198810577393\n",
            "epoch: 1, iteratation 1172, loss: 2.2408149242401123\n",
            "epoch: 1, iteratation 1173, loss: 2.2561452388763428\n",
            "epoch: 1, iteratation 1174, loss: 2.0979225635528564\n",
            "epoch: 1, iteratation 1175, loss: 2.0272703170776367\n",
            "epoch: 1, iteratation 1176, loss: 2.210753917694092\n",
            "epoch: 1, iteratation 1177, loss: 2.2326512336730957\n",
            "epoch: 1, iteratation 1178, loss: 2.151435375213623\n",
            "epoch: 1, iteratation 1179, loss: 2.0911011695861816\n",
            "epoch: 1, iteratation 1180, loss: 2.00994873046875\n",
            "epoch: 1, iteratation 1181, loss: 2.1973578929901123\n",
            "epoch: 1, iteratation 1182, loss: 2.1311709880828857\n",
            "epoch: 1, iteratation 1183, loss: 2.2156386375427246\n",
            "epoch: 1, iteratation 1184, loss: 2.1386566162109375\n",
            "epoch: 1, iteratation 1185, loss: 2.0988965034484863\n",
            "epoch: 1, iteratation 1186, loss: 2.1326732635498047\n",
            "epoch: 1, iteratation 1187, loss: 2.231349468231201\n",
            "epoch: 1, iteratation 1188, loss: 2.143092155456543\n",
            "epoch: 1, iteratation 1189, loss: 2.033029317855835\n",
            "epoch: 1, iteratation 1190, loss: 2.1870224475860596\n",
            "epoch: 1, iteratation 1191, loss: 2.082369327545166\n",
            "epoch: 1, iteratation 1192, loss: 2.064931631088257\n",
            "epoch: 1, iteratation 1193, loss: 2.055756092071533\n",
            "epoch: 1, iteratation 1194, loss: 2.180499315261841\n",
            "epoch: 1, iteratation 1195, loss: 2.066592216491699\n",
            "epoch: 1, iteratation 1196, loss: 2.0621566772460938\n",
            "epoch: 1, iteratation 1197, loss: 1.9399656057357788\n",
            "epoch: 1, iteratation 1198, loss: 2.1012396812438965\n",
            "epoch: 1, iteratation 1199, loss: 2.0386714935302734\n",
            "epoch: 1, iteratation 1200, loss: 2.2564857006073\n",
            "epoch: 1, iteratation 1201, loss: 2.058748722076416\n",
            "epoch: 1, iteratation 1202, loss: 2.084622383117676\n",
            "epoch: 1, iteratation 1203, loss: 2.043205976486206\n",
            "epoch: 1, iteratation 1204, loss: 2.1904311180114746\n",
            "epoch: 1, iteratation 1205, loss: 1.9890702962875366\n",
            "epoch: 1, iteratation 1206, loss: 2.147555112838745\n",
            "epoch: 1, iteratation 1207, loss: 2.2173385620117188\n",
            "epoch: 1, iteratation 1208, loss: 2.032163143157959\n",
            "epoch: 1, iteratation 1209, loss: 2.0763721466064453\n",
            "epoch: 1, iteratation 1210, loss: 2.1441876888275146\n",
            "epoch: 1, iteratation 1211, loss: 2.122056484222412\n",
            "epoch: 1, iteratation 1212, loss: 2.1381874084472656\n",
            "epoch: 1, iteratation 1213, loss: 2.1345386505126953\n",
            "epoch: 1, iteratation 1214, loss: 2.0073018074035645\n",
            "epoch: 1, iteratation 1215, loss: 2.0492284297943115\n",
            "epoch: 1, iteratation 1216, loss: 1.9950134754180908\n",
            "epoch: 1, iteratation 1217, loss: 2.178722381591797\n",
            "epoch: 1, iteratation 1218, loss: 2.011349678039551\n",
            "epoch: 1, iteratation 1219, loss: 2.0650975704193115\n",
            "epoch: 1, iteratation 1220, loss: 2.0023789405822754\n",
            "epoch: 1, iteratation 1221, loss: 2.004579544067383\n",
            "epoch: 1, iteratation 1222, loss: 2.2766969203948975\n",
            "epoch: 1, iteratation 1223, loss: 2.1821985244750977\n",
            "epoch: 1, iteratation 1224, loss: 2.029935359954834\n",
            "epoch: 1, iteratation 1225, loss: 1.9202994108200073\n",
            "epoch: 1, iteratation 1226, loss: 1.9902927875518799\n",
            "epoch: 1, iteratation 1227, loss: 1.9566419124603271\n",
            "epoch: 1, iteratation 1228, loss: 2.01617169380188\n",
            "epoch: 1, iteratation 1229, loss: 1.9420175552368164\n",
            "epoch: 1, iteratation 1230, loss: 1.9861927032470703\n",
            "epoch: 1, iteratation 1231, loss: 2.169728994369507\n",
            "epoch: 1, iteratation 1232, loss: 2.0239503383636475\n",
            "epoch: 1, iteratation 1233, loss: 2.220745086669922\n",
            "epoch: 1, iteratation 1234, loss: 2.056582450866699\n",
            "epoch: 1, iteratation 1235, loss: 1.984917402267456\n",
            "epoch: 1, iteratation 1236, loss: 1.951735019683838\n",
            "epoch: 1, iteratation 1237, loss: 2.311365842819214\n",
            "epoch: 1, iteratation 1238, loss: 2.5396671295166016\n",
            "epoch: 1, iteratation 1239, loss: 2.154473304748535\n",
            "epoch: 1, iteratation 1240, loss: 2.0061614513397217\n",
            "epoch: 1, iteratation 1241, loss: 2.2574777603149414\n",
            "epoch: 1, iteratation 1242, loss: 1.9401010274887085\n",
            "epoch: 1, iteratation 1243, loss: 2.0229711532592773\n",
            "epoch: 1, iteratation 1244, loss: 2.0553805828094482\n",
            "epoch: 1, iteratation 1245, loss: 1.9867427349090576\n",
            "epoch: 1, iteratation 1246, loss: 1.9686511754989624\n",
            "epoch: 1, iteratation 1247, loss: 2.125663995742798\n",
            "epoch: 1, iteratation 1248, loss: 1.974225401878357\n",
            "epoch: 1, iteratation 1249, loss: 2.090162992477417\n",
            "epoch: 1, iteratation 1250, loss: 1.939406394958496\n",
            "epoch: 1, iteratation 1251, loss: 1.9531821012496948\n",
            "epoch: 1, iteratation 1252, loss: 1.995231032371521\n",
            "epoch: 1, iteratation 1253, loss: 2.1197564601898193\n",
            "epoch: 1, iteratation 1254, loss: 1.905845046043396\n",
            "epoch: 1, iteratation 1255, loss: 2.0285730361938477\n",
            "epoch: 1, iteratation 1256, loss: 1.953312635421753\n",
            "epoch: 1, iteratation 1257, loss: 2.0832695960998535\n",
            "epoch: 1, iteratation 1258, loss: 2.0934906005859375\n",
            "epoch: 1, iteratation 1259, loss: 2.128629684448242\n",
            "epoch: 1, iteratation 1260, loss: 1.9458421468734741\n",
            "epoch: 1, iteratation 1261, loss: 2.0487608909606934\n",
            "epoch: 1, iteratation 1262, loss: 1.9698227643966675\n",
            "epoch: 1, iteratation 1263, loss: 2.1909568309783936\n",
            "epoch: 1, iteratation 1264, loss: 2.0626723766326904\n",
            "epoch: 1, iteratation 1265, loss: 2.2342307567596436\n",
            "epoch: 1, iteratation 1266, loss: 2.1865715980529785\n",
            "epoch: 1, iteratation 1267, loss: 2.0804920196533203\n",
            "epoch: 1, iteratation 1268, loss: 1.8965901136398315\n",
            "epoch: 1, iteratation 1269, loss: 1.9960908889770508\n",
            "epoch: 1, iteratation 1270, loss: 2.018730878829956\n",
            "epoch: 1, iteratation 1271, loss: 2.0164806842803955\n",
            "epoch: 1, iteratation 1272, loss: 2.1496264934539795\n",
            "epoch: 1, iteratation 1273, loss: 2.0235419273376465\n",
            "epoch: 1, iteratation 1274, loss: 1.978704810142517\n",
            "epoch: 1, iteratation 1275, loss: 2.1398978233337402\n",
            "epoch: 1, iteratation 1276, loss: 2.0104286670684814\n",
            "epoch: 1, iteratation 1277, loss: 2.206430196762085\n",
            "epoch: 1, iteratation 1278, loss: 2.0060012340545654\n",
            "epoch: 1, iteratation 1279, loss: 2.5478620529174805\n",
            "epoch: 1, iteratation 1280, loss: 1.925959587097168\n",
            "epoch: 1, iteratation 1281, loss: 1.856424331665039\n",
            "epoch: 1, iteratation 1282, loss: 2.0170552730560303\n",
            "epoch: 1, iteratation 1283, loss: 2.024460554122925\n",
            "epoch: 1, iteratation 1284, loss: 2.2239081859588623\n",
            "epoch: 1, iteratation 1285, loss: 1.8926191329956055\n",
            "epoch: 1, iteratation 1286, loss: 2.049755573272705\n",
            "epoch: 1, iteratation 1287, loss: 1.9795410633087158\n",
            "epoch: 1, iteratation 1288, loss: 2.0527162551879883\n",
            "epoch: 1, iteratation 1289, loss: 2.1211090087890625\n",
            "epoch: 1, iteratation 1290, loss: 2.0163445472717285\n",
            "epoch: 1, iteratation 1291, loss: 2.047046661376953\n",
            "epoch: 1, iteratation 1292, loss: 2.077324151992798\n",
            "epoch: 1, iteratation 1293, loss: 2.0826783180236816\n",
            "epoch: 1, iteratation 1294, loss: 1.924475073814392\n",
            "epoch: 1, iteratation 1295, loss: 1.9382281303405762\n",
            "epoch: 1, iteratation 1296, loss: 2.108767509460449\n",
            "epoch: 1, iteratation 1297, loss: 1.8863309621810913\n",
            "epoch: 1, iteratation 1298, loss: 1.8791730403900146\n",
            "epoch: 1, iteratation 1299, loss: 1.9325757026672363\n",
            "epoch: 1, iteratation 1300, loss: 1.906691551208496\n",
            "epoch: 1, iteratation 1301, loss: 2.085200786590576\n",
            "epoch: 1, iteratation 1302, loss: 2.118577480316162\n",
            "epoch: 1, iteratation 1303, loss: 2.006716728210449\n",
            "epoch: 1, iteratation 1304, loss: 2.0232009887695312\n",
            "epoch: 1, iteratation 1305, loss: 1.8577865362167358\n",
            "epoch: 1, iteratation 1306, loss: 2.0575687885284424\n",
            "epoch: 1, iteratation 1307, loss: 1.940283179283142\n",
            "epoch: 1, iteratation 1308, loss: 2.1602187156677246\n",
            "epoch: 1, iteratation 1309, loss: 2.0544564723968506\n",
            "epoch: 1, iteratation 1310, loss: 2.0843911170959473\n",
            "epoch: 1, iteratation 1311, loss: 1.9949907064437866\n",
            "epoch: 1, iteratation 1312, loss: 2.027729034423828\n",
            "epoch: 1, iteratation 1313, loss: 1.9658091068267822\n",
            "epoch: 1, iteratation 1314, loss: 2.105696439743042\n",
            "epoch: 1, iteratation 1315, loss: 2.0597498416900635\n",
            "epoch: 1, iteratation 1316, loss: 1.975550889968872\n",
            "epoch: 1, iteratation 1317, loss: 1.9082436561584473\n",
            "epoch: 1, iteratation 1318, loss: 1.9656022787094116\n",
            "epoch: 1, iteratation 1319, loss: 2.0189433097839355\n",
            "epoch: 1, iteratation 1320, loss: 2.14176082611084\n",
            "epoch: 1, iteratation 1321, loss: 2.1469080448150635\n",
            "epoch: 1, iteratation 1322, loss: 2.1797640323638916\n",
            "epoch: 1, iteratation 1323, loss: 1.963529348373413\n",
            "epoch: 1, iteratation 1324, loss: 1.88534677028656\n",
            "epoch: 1, iteratation 1325, loss: 2.0150814056396484\n",
            "epoch: 1, iteratation 1326, loss: 1.9978593587875366\n",
            "epoch: 1, iteratation 1327, loss: 2.001293420791626\n",
            "epoch: 1, iteratation 1328, loss: 2.0049643516540527\n",
            "epoch: 1, iteratation 1329, loss: 2.014496326446533\n",
            "epoch: 1, iteratation 1330, loss: 1.9055631160736084\n",
            "epoch: 1, iteratation 1331, loss: 2.1355395317077637\n",
            "epoch: 1, iteratation 1332, loss: 1.881217360496521\n",
            "epoch: 1, iteratation 1333, loss: 2.0556225776672363\n",
            "epoch: 1, iteratation 1334, loss: 2.101896047592163\n",
            "epoch: 1, iteratation 1335, loss: 1.8693469762802124\n",
            "epoch: 1, iteratation 1336, loss: 1.8868625164031982\n",
            "epoch: 1, iteratation 1337, loss: 2.003899335861206\n",
            "epoch: 1, iteratation 1338, loss: 1.9272799491882324\n",
            "epoch: 1, iteratation 1339, loss: 1.9383695125579834\n",
            "epoch: 1, iteratation 1340, loss: 2.1313741207122803\n",
            "epoch: 1, iteratation 1341, loss: 1.9732526540756226\n",
            "epoch: 1, iteratation 1342, loss: 1.8670915365219116\n",
            "epoch: 1, iteratation 1343, loss: 1.8637275695800781\n",
            "epoch: 1, iteratation 1344, loss: 1.9403839111328125\n",
            "epoch: 1, iteratation 1345, loss: 1.9360547065734863\n",
            "epoch: 1, iteratation 1346, loss: 2.163757801055908\n",
            "epoch: 1, iteratation 1347, loss: 1.8126716613769531\n",
            "epoch: 1, iteratation 1348, loss: 2.031675100326538\n",
            "epoch: 1, iteratation 1349, loss: 1.9506272077560425\n",
            "epoch: 1, iteratation 1350, loss: 1.8562984466552734\n",
            "epoch: 1, iteratation 1351, loss: 1.9370646476745605\n",
            "epoch: 1, iteratation 1352, loss: 1.9418971538543701\n",
            "epoch: 1, iteratation 1353, loss: 1.835980772972107\n",
            "epoch: 1, iteratation 1354, loss: 2.0935020446777344\n",
            "epoch: 1, iteratation 1355, loss: 1.9897006750106812\n",
            "epoch: 1, iteratation 1356, loss: 1.8350532054901123\n",
            "epoch: 1, iteratation 1357, loss: 1.9727219343185425\n",
            "epoch: 1, iteratation 1358, loss: 1.9521691799163818\n",
            "epoch: 1, iteratation 1359, loss: 1.9006948471069336\n",
            "epoch: 1, iteratation 1360, loss: 1.8436307907104492\n",
            "epoch: 1, iteratation 1361, loss: 1.947427749633789\n",
            "epoch: 1, iteratation 1362, loss: 1.7330312728881836\n",
            "epoch: 1, iteratation 1363, loss: 1.7475030422210693\n",
            "epoch: 1, iteratation 1364, loss: 1.8937791585922241\n",
            "epoch: 1, iteratation 1365, loss: 1.8569021224975586\n",
            "epoch: 1, iteratation 1366, loss: 1.8432705402374268\n",
            "epoch: 1, iteratation 1367, loss: 1.9553766250610352\n",
            "epoch: 1, iteratation 1368, loss: 2.0072779655456543\n",
            "epoch: 1, iteratation 1369, loss: 1.9974563121795654\n",
            "epoch: 1, iteratation 1370, loss: 2.500558853149414\n",
            "epoch: 1, iteratation 1371, loss: 2.22391414642334\n",
            "epoch: 1, iteratation 1372, loss: 2.001248836517334\n",
            "epoch: 1, iteratation 1373, loss: 1.8359427452087402\n",
            "epoch: 1, iteratation 1374, loss: 1.9425122737884521\n",
            "epoch: 1, iteratation 1375, loss: 2.214132308959961\n",
            "epoch: 1, iteratation 1376, loss: 1.992911696434021\n",
            "epoch: 1, iteratation 1377, loss: 1.9649567604064941\n",
            "epoch: 1, iteratation 1378, loss: 1.837493896484375\n",
            "epoch: 1, iteratation 1379, loss: 2.2569892406463623\n",
            "epoch: 1, iteratation 1380, loss: 1.9353177547454834\n",
            "epoch: 1, iteratation 1381, loss: 2.031022548675537\n",
            "epoch: 1, iteratation 1382, loss: 1.8974689245224\n",
            "epoch: 1, iteratation 1383, loss: 1.929814100265503\n",
            "epoch: 1, iteratation 1384, loss: 1.9554857015609741\n",
            "epoch: 1, iteratation 1385, loss: 1.7637860774993896\n",
            "epoch: 1, iteratation 1386, loss: 2.0158286094665527\n",
            "epoch: 1, iteratation 1387, loss: 1.9300754070281982\n",
            "epoch: 1, iteratation 1388, loss: 1.9526221752166748\n",
            "epoch: 1, iteratation 1389, loss: 1.946218490600586\n",
            "epoch: 1, iteratation 1390, loss: 1.8764104843139648\n",
            "epoch: 1, iteratation 1391, loss: 1.9516432285308838\n",
            "epoch: 1, iteratation 1392, loss: 1.9718730449676514\n",
            "epoch: 1, iteratation 1393, loss: 1.9503796100616455\n",
            "epoch: 1, iteratation 1394, loss: 1.9007506370544434\n",
            "epoch: 1, iteratation 1395, loss: 1.859606146812439\n",
            "epoch: 1, iteratation 1396, loss: 1.8971580266952515\n",
            "epoch: 1, iteratation 1397, loss: 1.9576044082641602\n",
            "epoch: 1, iteratation 1398, loss: 1.9565889835357666\n",
            "epoch: 1, iteratation 1399, loss: 2.035015821456909\n",
            "epoch: 1, iteratation 1400, loss: 1.8734045028686523\n",
            "epoch: 1, iteratation 1401, loss: 2.010868549346924\n",
            "epoch: 1, iteratation 1402, loss: 1.9985554218292236\n",
            "epoch: 1, iteratation 1403, loss: 1.9101150035858154\n",
            "epoch: 1, iteratation 1404, loss: 1.9537830352783203\n",
            "epoch: 1, iteratation 1405, loss: 1.957077980041504\n",
            "epoch: 1, iteratation 1406, loss: 2.082557439804077\n",
            "epoch: 1, iteratation 1407, loss: 1.7920002937316895\n",
            "epoch: 1, iteratation 1408, loss: 1.872305154800415\n",
            "epoch: 1, iteratation 1409, loss: 2.094111442565918\n",
            "epoch: 1, iteratation 1410, loss: 2.107008695602417\n",
            "epoch: 1, iteratation 1411, loss: 2.0366668701171875\n",
            "epoch: 1, iteratation 1412, loss: 1.8571933507919312\n",
            "epoch: 1, iteratation 1413, loss: 2.0061097145080566\n",
            "epoch: 1, iteratation 1414, loss: 1.8048744201660156\n",
            "epoch: 1, iteratation 1415, loss: 2.0578174591064453\n",
            "epoch: 1, iteratation 1416, loss: 2.0074269771575928\n",
            "epoch: 1, iteratation 1417, loss: 1.9023470878601074\n",
            "epoch: 1, iteratation 1418, loss: 1.857168197631836\n",
            "epoch: 1, iteratation 1419, loss: 1.772258996963501\n",
            "epoch: 1, iteratation 1420, loss: 1.9161841869354248\n",
            "epoch: 1, iteratation 1421, loss: 1.9389963150024414\n",
            "epoch: 1, iteratation 1422, loss: 1.8736413717269897\n",
            "epoch: 1, iteratation 1423, loss: 1.7758259773254395\n",
            "epoch: 1, iteratation 1424, loss: 1.7362561225891113\n",
            "epoch: 1, iteratation 1425, loss: 1.915160894393921\n",
            "epoch: 1, iteratation 1426, loss: 1.859241247177124\n",
            "epoch: 1, iteratation 1427, loss: 1.7800109386444092\n",
            "epoch: 1, iteratation 1428, loss: 1.9286813735961914\n",
            "epoch: 1, iteratation 1429, loss: 1.9855278730392456\n",
            "epoch: 1, iteratation 1430, loss: 1.7838914394378662\n",
            "epoch: 1, iteratation 1431, loss: 2.0118772983551025\n",
            "epoch: 1, iteratation 1432, loss: 1.836382269859314\n",
            "epoch: 1, iteratation 1433, loss: 1.787200927734375\n",
            "epoch: 1, iteratation 1434, loss: 1.8085006475448608\n",
            "epoch: 1, iteratation 1435, loss: 1.7373994588851929\n",
            "epoch: 1, iteratation 1436, loss: 1.8848562240600586\n",
            "epoch: 1, iteratation 1437, loss: 1.8074066638946533\n",
            "epoch: 1, iteratation 1438, loss: 1.767625331878662\n",
            "epoch: 1, iteratation 1439, loss: 1.7398383617401123\n",
            "epoch: 1, iteratation 1440, loss: 1.9315160512924194\n",
            "epoch: 1, iteratation 1441, loss: 1.896722674369812\n",
            "epoch: 1, iteratation 1442, loss: 1.9948899745941162\n",
            "epoch: 1, iteratation 1443, loss: 1.9036672115325928\n",
            "epoch: 1, iteratation 1444, loss: 1.7554157972335815\n",
            "epoch: 1, iteratation 1445, loss: 1.884730577468872\n",
            "epoch: 1, iteratation 1446, loss: 1.7439610958099365\n",
            "epoch: 1, iteratation 1447, loss: 1.8158273696899414\n",
            "epoch: 1, iteratation 1448, loss: 1.7533786296844482\n",
            "epoch: 1, iteratation 1449, loss: 1.7464511394500732\n",
            "epoch: 1, iteratation 1450, loss: 1.794734001159668\n",
            "epoch: 1, iteratation 1451, loss: 1.9368876218795776\n",
            "epoch: 1, iteratation 1452, loss: 1.8375333547592163\n",
            "epoch: 1, iteratation 1453, loss: 1.9244601726531982\n",
            "epoch: 1, iteratation 1454, loss: 2.2287280559539795\n",
            "epoch: 1, iteratation 1455, loss: 1.8946728706359863\n",
            "epoch: 1, iteratation 1456, loss: 1.825613260269165\n",
            "epoch: 1, iteratation 1457, loss: 1.8787736892700195\n",
            "epoch: 1, iteratation 1458, loss: 2.0435242652893066\n",
            "epoch: 1, iteratation 1459, loss: 1.9091905355453491\n",
            "epoch: 1, iteratation 1460, loss: 1.8807575702667236\n",
            "epoch: 1, iteratation 1461, loss: 1.9379193782806396\n",
            "epoch: 1, iteratation 1462, loss: 1.8726716041564941\n",
            "epoch: 1, iteratation 1463, loss: 2.1012234687805176\n",
            "epoch: 1, iteratation 1464, loss: 2.125976085662842\n",
            "epoch: 1, iteratation 1465, loss: 1.8013174533843994\n",
            "epoch: 1, iteratation 1466, loss: 1.807819128036499\n",
            "epoch: 1, iteratation 1467, loss: 1.8549764156341553\n",
            "epoch: 1, iteratation 1468, loss: 1.8476871252059937\n",
            "epoch: 1, iteratation 1469, loss: 1.8167216777801514\n",
            "epoch: 1, iteratation 1470, loss: 1.8582637310028076\n",
            "epoch: 1, iteratation 1471, loss: 1.9970896244049072\n",
            "epoch: 1, iteratation 1472, loss: 1.799301028251648\n",
            "epoch: 1, iteratation 1473, loss: 1.807692527770996\n",
            "epoch: 1, iteratation 1474, loss: 1.9155890941619873\n",
            "epoch: 1, iteratation 1475, loss: 1.797094702720642\n",
            "epoch: 1, iteratation 1476, loss: 1.7672252655029297\n",
            "epoch: 1, iteratation 1477, loss: 1.8631961345672607\n",
            "epoch: 1, iteratation 1478, loss: 1.8840949535369873\n",
            "epoch: 1, iteratation 1479, loss: 1.9749479293823242\n",
            "epoch: 1, iteratation 1480, loss: 1.8381389379501343\n",
            "epoch: 1, iteratation 1481, loss: 1.897744059562683\n",
            "epoch: 1, iteratation 1482, loss: 1.8653711080551147\n",
            "epoch: 1, iteratation 1483, loss: 1.8526633977890015\n",
            "epoch: 1, iteratation 1484, loss: 1.8832592964172363\n",
            "epoch: 1, iteratation 1485, loss: 1.8202199935913086\n",
            "epoch: 1, iteratation 1486, loss: 1.7933104038238525\n",
            "epoch: 1, iteratation 1487, loss: 1.8000469207763672\n",
            "epoch: 1, iteratation 1488, loss: 1.9037284851074219\n",
            "epoch: 1, iteratation 1489, loss: 1.7505607604980469\n",
            "epoch: 1, iteratation 1490, loss: 1.6088907718658447\n",
            "epoch: 1, iteratation 1491, loss: 1.7511155605316162\n",
            "epoch: 1, iteratation 1492, loss: 1.973205327987671\n",
            "epoch: 1, iteratation 1493, loss: 2.0970497131347656\n",
            "epoch: 1, iteratation 1494, loss: 1.796421766281128\n",
            "epoch: 1, iteratation 1495, loss: 1.891892671585083\n",
            "epoch: 1, iteratation 1496, loss: 1.7592287063598633\n",
            "epoch: 1, iteratation 1497, loss: 1.9269096851348877\n",
            "epoch: 1, iteratation 1498, loss: 1.8666443824768066\n",
            "epoch: 1, iteratation 1499, loss: 1.8759522438049316\n",
            "epoch: 1, iteratation 1500, loss: 1.9230728149414062\n",
            "epoch: 1, iteratation 1501, loss: 1.9143245220184326\n",
            "epoch: 1, iteratation 1502, loss: 1.8398430347442627\n",
            "epoch: 1, iteratation 1503, loss: 1.9142251014709473\n",
            "epoch: 1, iteratation 1504, loss: 1.8046605587005615\n",
            "epoch: 1, iteratation 1505, loss: 1.7224032878875732\n",
            "epoch: 1, iteratation 1506, loss: 1.9512742757797241\n",
            "epoch: 1, iteratation 1507, loss: 1.8363240957260132\n",
            "epoch: 1, iteratation 1508, loss: 1.8583974838256836\n",
            "epoch: 1, iteratation 1509, loss: 2.041736364364624\n",
            "epoch: 1, iteratation 1510, loss: 2.1831252574920654\n",
            "epoch: 1, iteratation 1511, loss: 1.999696135520935\n",
            "epoch: 1, iteratation 1512, loss: 1.8370919227600098\n",
            "epoch: 1, iteratation 1513, loss: 1.7948956489562988\n",
            "epoch: 1, iteratation 1514, loss: 1.8262271881103516\n",
            "epoch: 1, iteratation 1515, loss: 1.866771936416626\n",
            "epoch: 1, iteratation 1516, loss: 1.6947004795074463\n",
            "epoch: 1, iteratation 1517, loss: 1.8981153964996338\n",
            "epoch: 1, iteratation 1518, loss: 1.7117059230804443\n",
            "epoch: 1, iteratation 1519, loss: 1.891249656677246\n",
            "epoch: 1, iteratation 1520, loss: 1.7186483144760132\n",
            "epoch: 1, iteratation 1521, loss: 1.706740379333496\n",
            "epoch: 1, iteratation 1522, loss: 1.8803308010101318\n",
            "epoch: 1, iteratation 1523, loss: 1.9501526355743408\n",
            "epoch: 1, iteratation 1524, loss: 2.034658432006836\n",
            "epoch: 1, iteratation 1525, loss: 2.093358039855957\n",
            "epoch: 1, iteratation 1526, loss: 1.972289800643921\n",
            "epoch: 1, iteratation 1527, loss: 1.7637243270874023\n",
            "epoch: 1, iteratation 1528, loss: 1.9422844648361206\n",
            "epoch: 1, iteratation 1529, loss: 1.8037004470825195\n",
            "epoch: 1, iteratation 1530, loss: 1.861070990562439\n",
            "epoch: 1, iteratation 1531, loss: 1.8146963119506836\n",
            "epoch: 1, iteratation 1532, loss: 1.952540397644043\n",
            "epoch: 1, iteratation 1533, loss: 2.059765577316284\n",
            "epoch: 1, iteratation 1534, loss: 1.7846143245697021\n",
            "epoch: 1, iteratation 1535, loss: 2.160447835922241\n",
            "epoch: 1, iteratation 1536, loss: 1.836307406425476\n",
            "epoch: 1, iteratation 1537, loss: 1.6605037450790405\n",
            "epoch: 1, iteratation 1538, loss: 1.9527572393417358\n",
            "epoch: 1, iteratation 1539, loss: 2.0935897827148438\n",
            "epoch: 1, iteratation 1540, loss: 1.8213748931884766\n",
            "epoch: 1, iteratation 1541, loss: 1.8821582794189453\n",
            "epoch: 1, iteratation 1542, loss: 1.8875248432159424\n",
            "epoch: 1, iteratation 1543, loss: 1.9005831480026245\n",
            "epoch: 1, iteratation 1544, loss: 2.1864778995513916\n",
            "epoch: 1, iteratation 1545, loss: 1.668599009513855\n",
            "epoch: 1, iteratation 1546, loss: 1.7981910705566406\n",
            "epoch: 1, iteratation 1547, loss: 1.857680320739746\n",
            "epoch: 1, iteratation 1548, loss: 1.9345386028289795\n",
            "epoch: 1, iteratation 1549, loss: 1.999301791191101\n",
            "epoch: 1, iteratation 1550, loss: 1.7545411586761475\n",
            "epoch: 1, iteratation 1551, loss: 1.9211468696594238\n",
            "epoch: 1, iteratation 1552, loss: 2.0732359886169434\n",
            "epoch: 1, iteratation 1553, loss: 1.8675785064697266\n",
            "epoch: 1, iteratation 1554, loss: 1.8051551580429077\n",
            "epoch: 1, iteratation 1555, loss: 1.8132318258285522\n",
            "epoch: 1, iteratation 1556, loss: 1.7543444633483887\n",
            "epoch: 1, iteratation 1557, loss: 1.8353049755096436\n",
            "epoch: 1, iteratation 1558, loss: 1.9788148403167725\n",
            "epoch: 1, iteratation 1559, loss: 1.8398869037628174\n",
            "epoch: 1, iteratation 1560, loss: 1.9383119344711304\n",
            "epoch: 1, iteratation 1561, loss: 1.8449581861495972\n",
            "epoch: 1, iteratation 1562, loss: 1.7475225925445557\n",
            "epoch: 1, iteratation 1563, loss: 1.9242992401123047\n",
            "epoch: 1, iteratation 1564, loss: 1.83224618434906\n",
            "epoch: 1, iteratation 1565, loss: 1.6169236898422241\n",
            "epoch: 1, iteratation 1566, loss: 1.6752851009368896\n",
            "epoch: 1, iteratation 1567, loss: 1.7931445837020874\n",
            "epoch: 1, iteratation 1568, loss: 1.7860488891601562\n",
            "epoch: 1, iteratation 1569, loss: 1.8617124557495117\n",
            "epoch: 1, iteratation 1570, loss: 1.8450959920883179\n",
            "epoch: 1, iteratation 1571, loss: 1.7605775594711304\n",
            "epoch: 1, iteratation 1572, loss: 1.8168468475341797\n",
            "epoch: 1, iteratation 1573, loss: 1.6668390035629272\n",
            "epoch: 1, iteratation 1574, loss: 1.7975449562072754\n",
            "epoch: 1, iteratation 1575, loss: 1.8862435817718506\n",
            "epoch: 1, iteratation 1576, loss: 1.6999152898788452\n",
            "epoch: 1, iteratation 1577, loss: 2.0423851013183594\n",
            "epoch: 1, iteratation 1578, loss: 1.7742211818695068\n",
            "epoch: 1, iteratation 1579, loss: 1.6591362953186035\n",
            "epoch: 1, iteratation 1580, loss: 1.7664365768432617\n",
            "epoch: 1, iteratation 1581, loss: 1.6928577423095703\n",
            "epoch: 1, iteratation 1582, loss: 1.6826999187469482\n",
            "epoch: 1, iteratation 1583, loss: 1.866300344467163\n",
            "epoch: 1, iteratation 1584, loss: 2.0385212898254395\n",
            "epoch: 1, iteratation 1585, loss: 1.963274359703064\n",
            "epoch: 1, iteratation 1586, loss: 1.7773010730743408\n",
            "epoch: 1, iteratation 1587, loss: 1.721215009689331\n",
            "epoch: 1, iteratation 1588, loss: 1.8601055145263672\n",
            "epoch: 1, iteratation 1589, loss: 1.8455591201782227\n",
            "epoch: 1, iteratation 1590, loss: 1.9827717542648315\n",
            "epoch: 1, iteratation 1591, loss: 1.8746923208236694\n",
            "epoch: 1, iteratation 1592, loss: 1.7612245082855225\n",
            "epoch: 1, iteratation 1593, loss: 1.8641576766967773\n",
            "epoch: 1, iteratation 1594, loss: 1.9069684743881226\n",
            "epoch: 1, iteratation 1595, loss: 1.9948095083236694\n",
            "epoch: 1, iteratation 1596, loss: 1.8643312454223633\n",
            "epoch: 1, iteratation 1597, loss: 1.8287935256958008\n",
            "epoch: 1, iteratation 1598, loss: 1.9628636837005615\n",
            "epoch: 1, iteratation 1599, loss: 1.81516432762146\n",
            "epoch: 1, iteratation 1600, loss: 1.948563814163208\n",
            "epoch: 1, iteratation 1601, loss: 1.7011431455612183\n",
            "epoch: 1, iteratation 1602, loss: 1.7813434600830078\n",
            "epoch: 1, iteratation 1603, loss: 1.701372504234314\n",
            "epoch: 1, iteratation 1604, loss: 1.8183698654174805\n",
            "epoch: 1, iteratation 1605, loss: 1.9522665739059448\n",
            "epoch: 1, iteratation 1606, loss: 1.8734118938446045\n",
            "epoch: 1, iteratation 1607, loss: 1.7179460525512695\n",
            "epoch: 1, iteratation 1608, loss: 1.8716280460357666\n",
            "epoch: 1, iteratation 1609, loss: 1.7566050291061401\n",
            "epoch: 1, iteratation 1610, loss: 1.83915376663208\n",
            "epoch: 1, iteratation 1611, loss: 1.7255538702011108\n",
            "epoch: 1, iteratation 1612, loss: 1.9695013761520386\n",
            "epoch: 1, iteratation 1613, loss: 1.8292722702026367\n",
            "epoch: 1, iteratation 1614, loss: 1.6760896444320679\n",
            "epoch: 1, iteratation 1615, loss: 1.6407709121704102\n",
            "epoch: 1, iteratation 1616, loss: 1.9345042705535889\n",
            "epoch: 1, iteratation 1617, loss: 1.7793302536010742\n",
            "epoch: 1, iteratation 1618, loss: 1.8109557628631592\n",
            "epoch: 1, iteratation 1619, loss: 1.7770851850509644\n",
            "epoch: 1, iteratation 1620, loss: 1.7127397060394287\n",
            "epoch: 1, iteratation 1621, loss: 1.834107756614685\n",
            "epoch: 1, iteratation 1622, loss: 1.8690803050994873\n",
            "epoch: 1, iteratation 1623, loss: 1.6425433158874512\n",
            "epoch: 1, iteratation 1624, loss: 1.6641048192977905\n",
            "epoch: 1, iteratation 1625, loss: 1.6980171203613281\n",
            "epoch: 1, iteratation 1626, loss: 1.7376670837402344\n",
            "epoch: 1, iteratation 1627, loss: 1.5799115896224976\n",
            "epoch: 1, iteratation 1628, loss: 1.7666791677474976\n",
            "epoch: 1, iteratation 1629, loss: 1.791797399520874\n",
            "epoch: 1, iteratation 1630, loss: 1.7066850662231445\n",
            "epoch: 1, iteratation 1631, loss: 1.8341765403747559\n",
            "epoch: 1, iteratation 1632, loss: 1.8565486669540405\n",
            "epoch: 1, iteratation 1633, loss: 1.875373363494873\n",
            "epoch: 1, iteratation 1634, loss: 1.8180675506591797\n",
            "epoch: 1, iteratation 1635, loss: 1.707100749015808\n",
            "epoch: 1, iteratation 1636, loss: 1.7831496000289917\n",
            "epoch: 1, iteratation 1637, loss: 1.746954321861267\n",
            "epoch: 1, iteratation 1638, loss: 1.8734691143035889\n",
            "epoch: 1, iteratation 1639, loss: 1.9331128597259521\n",
            "epoch: 1, iteratation 1640, loss: 1.6507929563522339\n",
            "epoch: 1, iteratation 1641, loss: 1.716705083847046\n",
            "epoch: 1, iteratation 1642, loss: 1.7201541662216187\n",
            "epoch: 1, iteratation 1643, loss: 1.775843620300293\n",
            "epoch: 1, iteratation 1644, loss: 1.6641173362731934\n",
            "epoch: 1, iteratation 1645, loss: 1.752471923828125\n",
            "epoch: 1, iteratation 1646, loss: 1.7399080991744995\n",
            "epoch: 1, iteratation 1647, loss: 1.7680425643920898\n",
            "epoch: 1, iteratation 1648, loss: 1.8013299703598022\n",
            "epoch: 1, iteratation 1649, loss: 1.825371503829956\n",
            "epoch: 1, iteratation 1650, loss: 1.6761674880981445\n",
            "epoch: 1, iteratation 1651, loss: 1.8907899856567383\n",
            "epoch: 1, iteratation 1652, loss: 1.661125898361206\n",
            "epoch: 1, iteratation 1653, loss: 1.5928218364715576\n",
            "epoch: 1, iteratation 1654, loss: 1.8371086120605469\n",
            "epoch: 1, iteratation 1655, loss: 2.0323801040649414\n",
            "epoch: 1, iteratation 1656, loss: 1.8450055122375488\n",
            "epoch: 1, iteratation 1657, loss: 2.1688737869262695\n",
            "epoch: 1, iteratation 1658, loss: 1.7588326930999756\n",
            "epoch: 1, iteratation 1659, loss: 1.7584199905395508\n",
            "epoch: 1, iteratation 1660, loss: 1.9467096328735352\n",
            "epoch: 1, iteratation 1661, loss: 1.7522211074829102\n",
            "epoch: 1, iteratation 1662, loss: 1.7979352474212646\n",
            "epoch: 1, iteratation 1663, loss: 1.717246413230896\n",
            "epoch: 1, iteratation 1664, loss: 1.826066017150879\n",
            "epoch: 1, iteratation 1665, loss: 1.7684805393218994\n",
            "epoch: 1, iteratation 1666, loss: 2.0005180835723877\n",
            "epoch: 1, iteratation 1667, loss: 1.6863559484481812\n",
            "epoch: 1, iteratation 1668, loss: 1.7038283348083496\n",
            "epoch: 1, iteratation 1669, loss: 1.7461451292037964\n",
            "epoch: 1, iteratation 1670, loss: 1.7765854597091675\n",
            "epoch: 1, iteratation 1671, loss: 1.9642895460128784\n",
            "epoch: 1, iteratation 1672, loss: 1.7413148880004883\n",
            "epoch: 1, iteratation 1673, loss: 1.6189680099487305\n",
            "epoch: 1, iteratation 1674, loss: 1.7071352005004883\n",
            "epoch: 1, iteratation 1675, loss: 1.7798898220062256\n",
            "epoch: 1, iteratation 1676, loss: 1.8532977104187012\n",
            "epoch: 1, iteratation 1677, loss: 1.9514813423156738\n",
            "epoch: 1, iteratation 1678, loss: 1.815184473991394\n",
            "epoch: 1, iteratation 1679, loss: 1.7211660146713257\n",
            "epoch: 1, iteratation 1680, loss: 1.7565252780914307\n",
            "epoch: 1, iteratation 1681, loss: 1.7687675952911377\n",
            "epoch: 1, iteratation 1682, loss: 1.7980159521102905\n",
            "epoch: 1, iteratation 1683, loss: 1.9948396682739258\n",
            "epoch: 1, iteratation 1684, loss: 1.731844186782837\n",
            "epoch: 1, iteratation 1685, loss: 1.6492799520492554\n",
            "epoch: 1, iteratation 1686, loss: 1.7805025577545166\n",
            "epoch: 1, iteratation 1687, loss: 1.7538799047470093\n",
            "epoch: 1, iteratation 1688, loss: 1.8267492055892944\n",
            "epoch: 1, iteratation 1689, loss: 1.6875003576278687\n",
            "epoch: 1, iteratation 1690, loss: 1.6542928218841553\n",
            "epoch: 1, iteratation 1691, loss: 1.7365193367004395\n",
            "epoch: 1, iteratation 1692, loss: 1.652814269065857\n",
            "epoch: 1, iteratation 1693, loss: 1.905627965927124\n",
            "epoch: 1, iteratation 1694, loss: 2.0036306381225586\n",
            "epoch: 1, iteratation 1695, loss: 1.5689384937286377\n",
            "epoch: 1, iteratation 1696, loss: 1.6852439641952515\n",
            "epoch: 1, iteratation 1697, loss: 1.7243961095809937\n",
            "epoch: 1, iteratation 1698, loss: 1.708098292350769\n",
            "epoch: 1, iteratation 1699, loss: 1.7472460269927979\n",
            "epoch: 1, iteratation 1700, loss: 1.6872190237045288\n",
            "epoch: 1, iteratation 1701, loss: 1.719542384147644\n",
            "epoch: 1, iteratation 1702, loss: 1.5789531469345093\n",
            "epoch: 1, iteratation 1703, loss: 1.5947251319885254\n",
            "epoch: 1, iteratation 1704, loss: 1.9362452030181885\n",
            "epoch: 1, iteratation 1705, loss: 1.7484955787658691\n",
            "epoch: 1, iteratation 1706, loss: 1.7972248792648315\n",
            "epoch: 1, iteratation 1707, loss: 1.6221046447753906\n",
            "epoch: 1, iteratation 1708, loss: 1.5864986181259155\n",
            "epoch: 1, iteratation 1709, loss: 1.6665191650390625\n",
            "epoch: 1, iteratation 1710, loss: 1.9456241130828857\n",
            "epoch: 1, iteratation 1711, loss: 1.7432541847229004\n",
            "epoch: 1, iteratation 1712, loss: 1.6988427639007568\n",
            "epoch: 1, iteratation 1713, loss: 1.645798683166504\n",
            "epoch: 1, iteratation 1714, loss: 1.5909641981124878\n",
            "epoch: 1, iteratation 1715, loss: 1.6320862770080566\n",
            "epoch: 1, iteratation 1716, loss: 1.8611555099487305\n",
            "epoch: 1, iteratation 1717, loss: 2.0382919311523438\n",
            "epoch: 1, iteratation 1718, loss: 1.7601569890975952\n",
            "epoch: 1, iteratation 1719, loss: 1.7383098602294922\n",
            "epoch: 1, iteratation 1720, loss: 1.664560079574585\n",
            "epoch: 1, iteratation 1721, loss: 1.740058183670044\n",
            "epoch: 1, iteratation 1722, loss: 1.8024696111679077\n",
            "epoch: 1, iteratation 1723, loss: 1.772505760192871\n",
            "epoch: 1, iteratation 1724, loss: 1.784346342086792\n",
            "epoch: 1, iteratation 1725, loss: 1.8497226238250732\n",
            "epoch: 1, iteratation 1726, loss: 1.7073984146118164\n",
            "epoch: 1, iteratation 1727, loss: 1.7126328945159912\n",
            "epoch: 1, iteratation 1728, loss: 1.7147479057312012\n",
            "epoch: 1, iteratation 1729, loss: 1.993523120880127\n",
            "epoch: 1, iteratation 1730, loss: 1.7129029035568237\n",
            "epoch: 1, iteratation 1731, loss: 1.6773219108581543\n",
            "epoch: 1, iteratation 1732, loss: 1.7195613384246826\n",
            "epoch: 1, iteratation 1733, loss: 1.8345011472702026\n",
            "epoch: 1, iteratation 1734, loss: 1.6817643642425537\n",
            "epoch: 1, iteratation 1735, loss: 1.6378930807113647\n",
            "epoch: 1, iteratation 1736, loss: 1.6222761869430542\n",
            "epoch: 1, iteratation 1737, loss: 1.7512092590332031\n",
            "epoch: 1, iteratation 1738, loss: 1.7095904350280762\n",
            "epoch: 1, iteratation 1739, loss: 1.8765767812728882\n",
            "epoch: 1, iteratation 1740, loss: 1.9710382223129272\n",
            "epoch: 1, iteratation 1741, loss: 1.9563121795654297\n",
            "epoch: 1, iteratation 1742, loss: 1.6632630825042725\n",
            "epoch: 1, iteratation 1743, loss: 1.9345331192016602\n",
            "epoch: 1, iteratation 1744, loss: 1.7589006423950195\n",
            "epoch: 1, iteratation 1745, loss: 1.787839412689209\n",
            "epoch: 1, iteratation 1746, loss: 1.780475378036499\n",
            "epoch: 1, iteratation 1747, loss: 1.8209689855575562\n",
            "epoch: 1, iteratation 1748, loss: 1.7846473455429077\n",
            "epoch: 1, iteratation 1749, loss: 1.67034912109375\n",
            "epoch: 1, iteratation 1750, loss: 1.7971129417419434\n",
            "epoch: 1, iteratation 1751, loss: 1.9085501432418823\n",
            "epoch: 1, iteratation 1752, loss: 1.709368109703064\n",
            "epoch: 1, iteratation 1753, loss: 2.028204917907715\n",
            "epoch: 1, iteratation 1754, loss: 1.7636516094207764\n",
            "epoch: 1, iteratation 1755, loss: 1.8517217636108398\n",
            "epoch: 1, iteratation 1756, loss: 1.85050368309021\n",
            "epoch: 1, iteratation 1757, loss: 1.6156549453735352\n",
            "epoch: 1, iteratation 1758, loss: 1.8356341123580933\n",
            "epoch: 1, iteratation 1759, loss: 1.6950401067733765\n",
            "epoch: 1, iteratation 1760, loss: 1.7531275749206543\n",
            "epoch: 1, iteratation 1761, loss: 1.5975637435913086\n",
            "epoch: 1, iteratation 1762, loss: 2.1800241470336914\n",
            "epoch: 1, iteratation 1763, loss: 1.78127121925354\n",
            "epoch: 1, iteratation 1764, loss: 1.8102359771728516\n",
            "epoch: 1, iteratation 1765, loss: 1.787419080734253\n",
            "epoch: 1, iteratation 1766, loss: 1.727553367614746\n",
            "epoch: 1, iteratation 1767, loss: 1.679133415222168\n",
            "epoch: 1, iteratation 1768, loss: 1.707135558128357\n",
            "epoch: 1, iteratation 1769, loss: 1.7320451736450195\n",
            "epoch: 1, iteratation 1770, loss: 1.8815431594848633\n",
            "epoch: 1, iteratation 1771, loss: 1.8537076711654663\n",
            "epoch: 1, iteratation 1772, loss: 1.6683642864227295\n",
            "epoch: 1, iteratation 1773, loss: 1.7045953273773193\n",
            "epoch: 1, iteratation 1774, loss: 1.7139214277267456\n",
            "epoch: 1, iteratation 1775, loss: 1.7103602886199951\n",
            "epoch: 1, iteratation 1776, loss: 1.7570199966430664\n",
            "epoch: 1, iteratation 1777, loss: 1.7694289684295654\n",
            "epoch: 1, iteratation 1778, loss: 1.6003268957138062\n",
            "epoch: 1, iteratation 1779, loss: 1.9371860027313232\n",
            "epoch: 1, iteratation 1780, loss: 1.633470892906189\n",
            "epoch: 1, iteratation 1781, loss: 1.6796271800994873\n",
            "epoch: 1, iteratation 1782, loss: 1.6635208129882812\n",
            "epoch: 1, iteratation 1783, loss: 1.7402656078338623\n",
            "epoch: 1, iteratation 1784, loss: 1.8212130069732666\n",
            "epoch: 1, iteratation 1785, loss: 1.8623583316802979\n",
            "epoch: 1, iteratation 1786, loss: 1.6277246475219727\n",
            "epoch: 1, iteratation 1787, loss: 1.90884530544281\n",
            "epoch: 1, iteratation 1788, loss: 1.6714146137237549\n",
            "epoch: 1, iteratation 1789, loss: 1.6963634490966797\n",
            "epoch: 1, iteratation 1790, loss: 1.6668118238449097\n",
            "epoch: 1, iteratation 1791, loss: 1.8203704357147217\n",
            "epoch: 1, iteratation 1792, loss: 1.697832465171814\n",
            "epoch: 1, iteratation 1793, loss: 1.7277663946151733\n",
            "epoch: 1, iteratation 1794, loss: 1.7124700546264648\n",
            "epoch: 1, iteratation 1795, loss: 2.035581111907959\n",
            "epoch: 1, iteratation 1796, loss: 1.7885611057281494\n",
            "epoch: 1, iteratation 1797, loss: 1.616616129875183\n",
            "epoch: 1, iteratation 1798, loss: 1.749647855758667\n",
            "epoch: 1, iteratation 1799, loss: 1.6848552227020264\n",
            "epoch: 1, iteratation 1800, loss: 1.7665660381317139\n",
            "epoch: 1, iteratation 1801, loss: 1.589948058128357\n",
            "epoch: 1, iteratation 1802, loss: 1.6717326641082764\n",
            "epoch: 1, iteratation 1803, loss: 1.6156082153320312\n",
            "epoch: 1, iteratation 1804, loss: 1.7225918769836426\n",
            "epoch: 1, iteratation 1805, loss: 1.632434606552124\n",
            "epoch: 1, iteratation 1806, loss: 1.8293333053588867\n",
            "epoch: 1, iteratation 1807, loss: 1.8074328899383545\n",
            "epoch: 1, iteratation 1808, loss: 1.7258734703063965\n",
            "epoch: 1, iteratation 1809, loss: 1.615944743156433\n",
            "epoch: 1, iteratation 1810, loss: 1.8281817436218262\n",
            "epoch: 1, iteratation 1811, loss: 1.714601993560791\n",
            "epoch: 1, iteratation 1812, loss: 1.5949066877365112\n",
            "epoch: 1, iteratation 1813, loss: 1.7476990222930908\n",
            "epoch: 1, iteratation 1814, loss: 1.7034647464752197\n",
            "epoch: 1, iteratation 1815, loss: 1.7434778213500977\n",
            "epoch: 1, iteratation 1816, loss: 1.8146567344665527\n",
            "epoch: 1, iteratation 1817, loss: 1.679072618484497\n",
            "epoch: 1, iteratation 1818, loss: 1.8951871395111084\n",
            "epoch: 1, iteratation 1819, loss: 1.6319589614868164\n",
            "epoch: 1, iteratation 1820, loss: 1.5504406690597534\n",
            "epoch: 1, iteratation 1821, loss: 1.6854503154754639\n",
            "epoch: 1, iteratation 1822, loss: 1.6570667028427124\n",
            "epoch: 1, iteratation 1823, loss: 1.7075893878936768\n",
            "epoch: 1, iteratation 1824, loss: 1.6269423961639404\n",
            "epoch: 1, iteratation 1825, loss: 1.6869176626205444\n",
            "epoch: 1, iteratation 1826, loss: 1.8294031620025635\n",
            "epoch: 1, iteratation 1827, loss: 1.8463761806488037\n",
            "epoch: 1, iteratation 1828, loss: 1.6225335597991943\n",
            "epoch: 1, iteratation 1829, loss: 1.7313179969787598\n",
            "epoch: 1, iteratation 1830, loss: 1.6974958181381226\n",
            "epoch: 1, iteratation 1831, loss: 1.5953688621520996\n",
            "epoch: 1, iteratation 1832, loss: 1.6059650182724\n",
            "epoch: 1, iteratation 1833, loss: 1.7154757976531982\n",
            "epoch: 1, iteratation 1834, loss: 1.7790025472640991\n",
            "epoch: 1, iteratation 1835, loss: 1.696190595626831\n",
            "epoch: 1, iteratation 1836, loss: 1.6177926063537598\n",
            "epoch: 1, iteratation 1837, loss: 1.636859655380249\n",
            "epoch: 1, iteratation 1838, loss: 1.7773406505584717\n",
            "epoch: 1, iteratation 1839, loss: 1.5455268621444702\n",
            "epoch: 1, iteratation 1840, loss: 1.9771283864974976\n",
            "epoch: 1, iteratation 1841, loss: 1.5154922008514404\n",
            "epoch: 1, iteratation 1842, loss: 1.6308420896530151\n",
            "epoch: 1, iteratation 1843, loss: 2.0102992057800293\n",
            "epoch: 1, iteratation 1844, loss: 1.7256711721420288\n",
            "epoch: 1, iteratation 1845, loss: 1.6558432579040527\n",
            "epoch: 1, iteratation 1846, loss: 1.635830283164978\n",
            "epoch: 1, iteratation 1847, loss: 1.5987939834594727\n",
            "epoch: 1, iteratation 1848, loss: 1.6822199821472168\n",
            "epoch: 1, iteratation 1849, loss: 1.7285516262054443\n",
            "epoch: 1, iteratation 1850, loss: 1.6216745376586914\n",
            "epoch: 1, iteratation 1851, loss: 1.7370508909225464\n",
            "epoch: 1, iteratation 1852, loss: 1.5602905750274658\n",
            "epoch: 1, iteratation 1853, loss: 1.6753724813461304\n",
            "epoch: 1, iteratation 1854, loss: 1.9881439208984375\n",
            "epoch: 1, iteratation 1855, loss: 1.703416347503662\n",
            "epoch: 1, iteratation 1856, loss: 1.7474822998046875\n",
            "epoch: 1, iteratation 1857, loss: 1.7354106903076172\n",
            "epoch: 1, iteratation 1858, loss: 1.4909800291061401\n",
            "epoch: 1, iteratation 1859, loss: 1.765340805053711\n",
            "epoch: 1, iteratation 1860, loss: 1.6332640647888184\n",
            "epoch: 1, iteratation 1861, loss: 1.726507544517517\n",
            "epoch: 1, iteratation 1862, loss: 1.6598833799362183\n",
            "epoch: 1, iteratation 1863, loss: 1.8653595447540283\n",
            "epoch: 1, iteratation 1864, loss: 1.8505587577819824\n",
            "epoch: 1, iteratation 1865, loss: 1.683525800704956\n",
            "epoch: 1, iteratation 1866, loss: 1.5627598762512207\n",
            "epoch: 1, iteratation 1867, loss: 1.632604956626892\n",
            "epoch: 1, iteratation 1868, loss: 1.676378607749939\n",
            "epoch: 1, iteratation 1869, loss: 1.6627442836761475\n",
            "epoch: 1, iteratation 1870, loss: 1.498265266418457\n",
            "epoch: 1, iteratation 1871, loss: 1.5992177724838257\n",
            "epoch: 1, iteratation 1872, loss: 1.7335599660873413\n",
            "epoch: 1, iteratation 1873, loss: 1.863943338394165\n",
            "epoch: 1, iteratation 1874, loss: 1.9216442108154297\n",
            "epoch: 1, iteratation 1875, loss: 1.6598689556121826\n",
            "epoch: 1, iteratation 1876, loss: 1.7911803722381592\n",
            "epoch: 1, iteratation 1877, loss: 1.7379564046859741\n",
            "epoch: 1, iteratation 1878, loss: 1.6491225957870483\n",
            "epoch: 1, iteratation 1879, loss: 1.8194057941436768\n",
            "epoch: 1, iteratation 1880, loss: 1.6270928382873535\n",
            "epoch: 1, iteratation 1881, loss: 1.529167890548706\n",
            "epoch: 1, iteratation 1882, loss: 1.9281080961227417\n",
            "epoch: 1, iteratation 1883, loss: 1.671337604522705\n",
            "epoch: 1, iteratation 1884, loss: 1.6270259618759155\n",
            "epoch: 1, iteratation 1885, loss: 1.7430989742279053\n",
            "epoch: 1, iteratation 1886, loss: 1.6224870681762695\n",
            "epoch: 1, iteratation 1887, loss: 1.5493946075439453\n",
            "epoch: 1, iteratation 1888, loss: 1.7962030172348022\n",
            "epoch: 1, iteratation 1889, loss: 1.819406270980835\n",
            "epoch: 1, iteratation 1890, loss: 1.571642279624939\n",
            "epoch: 1, iteratation 1891, loss: 1.5937985181808472\n",
            "epoch: 1, iteratation 1892, loss: 1.7348769903182983\n",
            "epoch: 1, iteratation 1893, loss: 1.7942843437194824\n",
            "epoch: 1, iteratation 1894, loss: 1.6972101926803589\n",
            "epoch: 1, iteratation 1895, loss: 1.6262731552124023\n",
            "epoch: 1, iteratation 1896, loss: 1.6639971733093262\n",
            "epoch: 1, iteratation 1897, loss: 1.591957449913025\n",
            "epoch: 1, iteratation 1898, loss: 1.635632038116455\n",
            "epoch: 1, iteratation 1899, loss: 1.737932562828064\n",
            "epoch: 1, iteratation 1900, loss: 1.705942153930664\n",
            "epoch: 1, iteratation 1901, loss: 1.7022528648376465\n",
            "epoch: 1, iteratation 1902, loss: 1.742971420288086\n",
            "epoch: 1, iteratation 1903, loss: 1.6754262447357178\n",
            "epoch: 1, iteratation 1904, loss: 1.6462621688842773\n",
            "epoch: 1, iteratation 1905, loss: 1.661844253540039\n",
            "epoch: 1, iteratation 1906, loss: 1.5411057472229004\n",
            "epoch: 1, iteratation 1907, loss: 1.6474390029907227\n",
            "epoch: 1, iteratation 1908, loss: 1.6547707319259644\n",
            "epoch: 1, iteratation 1909, loss: 1.534501075744629\n",
            "epoch: 1, iteratation 1910, loss: 1.6507762670516968\n",
            "epoch: 1, iteratation 1911, loss: 1.7122218608856201\n",
            "epoch: 1, iteratation 1912, loss: 1.7463858127593994\n",
            "epoch: 1, iteratation 1913, loss: 1.8714563846588135\n",
            "epoch: 1, iteratation 1914, loss: 1.6100547313690186\n",
            "epoch: 1, iteratation 1915, loss: 1.5325411558151245\n",
            "epoch: 1, iteratation 1916, loss: 1.6461164951324463\n",
            "epoch: 1, iteratation 1917, loss: 1.703740119934082\n",
            "epoch: 1, iteratation 1918, loss: 2.0350422859191895\n",
            "epoch: 1, iteratation 1919, loss: 2.0285329818725586\n",
            "epoch: 1, iteratation 1920, loss: 1.9448503255844116\n",
            "epoch: 1, iteratation 1921, loss: 1.9906187057495117\n",
            "epoch: 1, iteratation 1922, loss: 1.5449626445770264\n",
            "epoch: 1, iteratation 1923, loss: 1.7062976360321045\n",
            "epoch: 1, iteratation 1924, loss: 1.8482770919799805\n",
            "epoch: 1, iteratation 1925, loss: 1.704291820526123\n",
            "epoch: 1, iteratation 1926, loss: 1.8660380840301514\n",
            "epoch: 1, iteratation 1927, loss: 1.6283185482025146\n",
            "epoch: 1, iteratation 1928, loss: 1.577336311340332\n",
            "epoch: 1, iteratation 1929, loss: 1.5921869277954102\n",
            "epoch: 1, iteratation 1930, loss: 1.7021090984344482\n",
            "epoch: 1, iteratation 1931, loss: 1.588165283203125\n",
            "epoch: 1, iteratation 1932, loss: 1.5522968769073486\n",
            "epoch: 1, iteratation 1933, loss: 1.7977460622787476\n",
            "epoch: 1, iteratation 1934, loss: 1.740741491317749\n",
            "epoch: 1, iteratation 1935, loss: 1.6217273473739624\n",
            "epoch: 1, iteratation 1936, loss: 1.6102855205535889\n",
            "epoch: 1, iteratation 1937, loss: 1.4874613285064697\n",
            "epoch: 1, iteratation 1938, loss: 1.5781707763671875\n",
            "epoch: 1, iteratation 1939, loss: 1.8361320495605469\n",
            "epoch: 1, iteratation 1940, loss: 1.8434538841247559\n",
            "epoch: 1, iteratation 1941, loss: 1.632865309715271\n",
            "epoch: 1, iteratation 1942, loss: 1.7948541641235352\n",
            "epoch: 1, iteratation 1943, loss: 1.6099634170532227\n",
            "epoch: 1, iteratation 1944, loss: 1.6268147230148315\n",
            "epoch: 1, iteratation 1945, loss: 1.6787526607513428\n",
            "epoch: 1, iteratation 1946, loss: 1.7617356777191162\n",
            "epoch: 1, iteratation 1947, loss: 1.5968081951141357\n",
            "epoch: 1, iteratation 1948, loss: 1.6681220531463623\n",
            "epoch: 1, iteratation 1949, loss: 1.7974342107772827\n",
            "epoch: 1, iteratation 1950, loss: 1.6215760707855225\n",
            "epoch: 1, iteratation 1951, loss: 1.7623108625411987\n",
            "epoch: 1, iteratation 1952, loss: 1.7094502449035645\n",
            "epoch: 1, iteratation 1953, loss: 1.808159351348877\n",
            "epoch: 1, iteratation 1954, loss: 1.611366629600525\n",
            "epoch: 1, iteratation 1955, loss: 1.5827445983886719\n",
            "epoch: 1, iteratation 1956, loss: 1.8381624221801758\n",
            "epoch: 1, iteratation 1957, loss: 1.6129601001739502\n",
            "epoch: 1, iteratation 1958, loss: 1.5527477264404297\n",
            "epoch: 1, iteratation 1959, loss: 1.703428030014038\n",
            "epoch: 1, iteratation 1960, loss: 1.9328216314315796\n",
            "epoch: 1, iteratation 1961, loss: 1.5684640407562256\n",
            "epoch: 1, iteratation 1962, loss: 1.7837717533111572\n",
            "epoch: 1, iteratation 1963, loss: 1.5580475330352783\n",
            "epoch: 1, iteratation 1964, loss: 1.5726388692855835\n",
            "epoch: 1, iteratation 1965, loss: 1.699173927307129\n",
            "epoch: 1, iteratation 1966, loss: 1.5869464874267578\n",
            "epoch: 1, iteratation 1967, loss: 1.6644420623779297\n",
            "epoch: 1, iteratation 1968, loss: 1.5992854833602905\n",
            "epoch: 1, iteratation 1969, loss: 1.5951560735702515\n",
            "epoch: 1, iteratation 1970, loss: 1.6703205108642578\n",
            "epoch: 1, iteratation 1971, loss: 1.6797937154769897\n",
            "epoch: 1, iteratation 1972, loss: 1.5800952911376953\n",
            "epoch: 1, iteratation 1973, loss: 1.6639089584350586\n",
            "epoch: 1, iteratation 1974, loss: 1.6183338165283203\n",
            "epoch: 1, iteratation 1975, loss: 1.4554990530014038\n",
            "epoch: 1, iteratation 1976, loss: 1.9231064319610596\n",
            "epoch: 1, iteratation 1977, loss: 1.6287801265716553\n",
            "epoch: 1, iteratation 1978, loss: 1.7081602811813354\n",
            "epoch: 1, iteratation 1979, loss: 1.4977312088012695\n",
            "epoch: 1, iteratation 1980, loss: 1.5830647945404053\n",
            "epoch: 1, iteratation 1981, loss: 1.6091126203536987\n",
            "epoch: 1, iteratation 1982, loss: 1.559277892112732\n",
            "epoch: 1, iteratation 1983, loss: 1.6411702632904053\n",
            "epoch: 1, iteratation 1984, loss: 1.5190715789794922\n",
            "epoch: 1, iteratation 1985, loss: 1.6352174282073975\n",
            "epoch: 1, iteratation 1986, loss: 1.6426094770431519\n",
            "epoch: 1, iteratation 1987, loss: 1.6423306465148926\n",
            "epoch: 1, iteratation 1988, loss: 1.5371254682540894\n",
            "epoch: 1, iteratation 1989, loss: 1.6085879802703857\n",
            "epoch: 1, iteratation 1990, loss: 1.5321763753890991\n",
            "epoch: 1, iteratation 1991, loss: 1.607345461845398\n",
            "epoch: 1, iteratation 1992, loss: 1.529456615447998\n",
            "epoch: 1, iteratation 1993, loss: 1.6075999736785889\n",
            "epoch: 1, iteratation 1994, loss: 1.5957636833190918\n",
            "epoch: 1, iteratation 1995, loss: 1.7623939514160156\n",
            "epoch: 1, iteratation 1996, loss: 1.5826499462127686\n",
            "epoch: 1, iteratation 1997, loss: 1.5608772039413452\n",
            "epoch: 1, iteratation 1998, loss: 1.5741958618164062\n",
            "epoch: 1, iteratation 1999, loss: 1.6437363624572754\n",
            "epoch: 1, iteratation 2000, loss: 1.5909020900726318\n",
            "epoch: 1, iteratation 2001, loss: 1.4849803447723389\n",
            "epoch: 1, iteratation 2002, loss: 1.5895717144012451\n",
            "epoch: 1, iteratation 2003, loss: 1.591679334640503\n",
            "epoch: 1, iteratation 2004, loss: 1.4342477321624756\n",
            "epoch: 1, iteratation 2005, loss: 1.6098334789276123\n",
            "epoch: 1, iteratation 2006, loss: 1.5667705535888672\n",
            "epoch: 1, iteratation 2007, loss: 1.6387856006622314\n",
            "epoch: 1, iteratation 2008, loss: 1.9331376552581787\n",
            "epoch: 1, iteratation 2009, loss: 1.6532243490219116\n",
            "epoch: 1, iteratation 2010, loss: 1.5980104207992554\n",
            "epoch: 1, iteratation 2011, loss: 1.6538207530975342\n",
            "epoch: 1, iteratation 2012, loss: 1.8329819440841675\n",
            "epoch: 1, iteratation 2013, loss: 1.6850416660308838\n",
            "epoch: 1, iteratation 2014, loss: 1.61685311794281\n",
            "epoch: 1, iteratation 2015, loss: 1.5709035396575928\n",
            "epoch: 1, iteratation 2016, loss: 1.6325767040252686\n",
            "epoch: 1, iteratation 2017, loss: 1.537062644958496\n",
            "epoch: 1, iteratation 2018, loss: 1.5782321691513062\n",
            "epoch: 1, iteratation 2019, loss: 1.7291946411132812\n",
            "epoch: 1, iteratation 2020, loss: 1.7095708847045898\n",
            "epoch: 1, iteratation 2021, loss: 1.6386406421661377\n",
            "epoch: 1, iteratation 2022, loss: 1.984442114830017\n",
            "epoch: 1, iteratation 2023, loss: 1.5436723232269287\n",
            "epoch: 1, iteratation 2024, loss: 1.613300085067749\n",
            "epoch: 1, iteratation 2025, loss: 1.6637557744979858\n",
            "epoch: 1, iteratation 2026, loss: 1.6017749309539795\n",
            "epoch: 1, iteratation 2027, loss: 1.7572212219238281\n",
            "epoch: 1, iteratation 2028, loss: 1.6792523860931396\n",
            "epoch: 1, iteratation 2029, loss: 1.6382287740707397\n",
            "epoch: 1, iteratation 2030, loss: 1.6493957042694092\n",
            "epoch: 1, iteratation 2031, loss: 1.4900429248809814\n",
            "epoch: 1, iteratation 2032, loss: 1.560542106628418\n",
            "epoch: 1, iteratation 2033, loss: 1.5443074703216553\n",
            "epoch: 1, iteratation 2034, loss: 1.900722861289978\n",
            "epoch: 1, iteratation 2035, loss: 1.618507742881775\n",
            "epoch: 1, iteratation 2036, loss: 1.622418761253357\n",
            "epoch: 1, iteratation 2037, loss: 1.743379831314087\n",
            "epoch: 1, iteratation 2038, loss: 1.7013239860534668\n",
            "epoch: 1, iteratation 2039, loss: 1.5829565525054932\n",
            "epoch: 1, iteratation 2040, loss: 1.7372263669967651\n",
            "epoch: 1, iteratation 2041, loss: 1.5967357158660889\n",
            "epoch: 1, iteratation 2042, loss: 1.5077013969421387\n",
            "epoch: 1, iteratation 2043, loss: 1.8722724914550781\n",
            "epoch: 1, iteratation 2044, loss: 1.9272193908691406\n",
            "epoch: 1, iteratation 2045, loss: 1.6513392925262451\n",
            "epoch: 1, iteratation 2046, loss: 1.5162900686264038\n",
            "epoch: 1, iteratation 2047, loss: 1.628119945526123\n",
            "epoch: 1, iteratation 2048, loss: 1.5416040420532227\n",
            "epoch: 1, iteratation 2049, loss: 1.513563632965088\n",
            "epoch: 1, iteratation 2050, loss: 1.6824471950531006\n",
            "epoch: 1, iteratation 2051, loss: 1.772526502609253\n",
            "epoch: 1, iteratation 2052, loss: 1.7739009857177734\n",
            "epoch: 1, iteratation 2053, loss: 1.678553581237793\n",
            "epoch: 1, iteratation 2054, loss: 1.6488778591156006\n",
            "epoch: 1, iteratation 2055, loss: 1.633520483970642\n",
            "epoch: 1, iteratation 2056, loss: 1.543302297592163\n",
            "epoch: 1, iteratation 2057, loss: 1.5510318279266357\n",
            "epoch: 1, iteratation 2058, loss: 1.6601343154907227\n",
            "epoch: 1, iteratation 2059, loss: 1.5626144409179688\n",
            "epoch: 1, iteratation 2060, loss: 1.54096257686615\n",
            "epoch: 1, iteratation 2061, loss: 1.5829899311065674\n",
            "epoch: 1, iteratation 2062, loss: 1.7729575634002686\n",
            "epoch: 1, iteratation 2063, loss: 1.6520851850509644\n",
            "epoch: 1, iteratation 2064, loss: 1.69639253616333\n",
            "epoch: 1, iteratation 2065, loss: 1.6964945793151855\n",
            "epoch: 1, iteratation 2066, loss: 1.4868669509887695\n",
            "epoch: 1, iteratation 2067, loss: 1.5745195150375366\n",
            "epoch: 1, iteratation 2068, loss: 1.8309688568115234\n",
            "epoch: 1, iteratation 2069, loss: 1.6421239376068115\n",
            "epoch: 1, iteratation 2070, loss: 1.6053847074508667\n",
            "epoch: 1, iteratation 2071, loss: 1.5395725965499878\n",
            "epoch: 1, iteratation 2072, loss: 1.570871114730835\n",
            "epoch: 1, iteratation 2073, loss: 1.676647424697876\n",
            "epoch: 1, iteratation 2074, loss: 1.5583146810531616\n",
            "epoch: 1, iteratation 2075, loss: 1.5650490522384644\n",
            "epoch: 1, iteratation 2076, loss: 1.8144903182983398\n",
            "epoch: 1, iteratation 2077, loss: 1.4658302068710327\n",
            "epoch: 1, iteratation 2078, loss: 1.696211814880371\n",
            "epoch: 1, iteratation 2079, loss: 1.6411840915679932\n",
            "epoch: 1, iteratation 2080, loss: 1.543626308441162\n",
            "epoch: 1, iteratation 2081, loss: 1.690403938293457\n",
            "epoch: 1, iteratation 2082, loss: 1.6110930442810059\n",
            "epoch: 1, iteratation 2083, loss: 1.6680517196655273\n",
            "epoch: 1, iteratation 2084, loss: 1.4975898265838623\n",
            "epoch: 1, iteratation 2085, loss: 1.6582024097442627\n",
            "epoch: 1, iteratation 2086, loss: 1.698011875152588\n",
            "epoch: 1, iteratation 2087, loss: 1.6848111152648926\n",
            "epoch: 1, iteratation 2088, loss: 1.6234824657440186\n",
            "epoch: 1, iteratation 2089, loss: 1.5894778966903687\n",
            "epoch: 1, iteratation 2090, loss: 1.5616214275360107\n",
            "epoch: 1, iteratation 2091, loss: 1.5982745885849\n",
            "epoch: 1, iteratation 2092, loss: 1.555177927017212\n",
            "epoch: 1, iteratation 2093, loss: 1.4930999279022217\n",
            "epoch: 1, iteratation 2094, loss: 1.6589072942733765\n",
            "epoch: 1, iteratation 2095, loss: 1.69745671749115\n",
            "epoch: 1, iteratation 2096, loss: 1.4976385831832886\n",
            "epoch: 1, iteratation 2097, loss: 1.8257761001586914\n",
            "epoch: 1, iteratation 2098, loss: 1.6006743907928467\n",
            "epoch: 1, iteratation 2099, loss: 1.6864221096038818\n",
            "epoch: 1, iteratation 2100, loss: 1.6311490535736084\n",
            "epoch: 1, iteratation 2101, loss: 1.5647327899932861\n",
            "epoch: 1, iteratation 2102, loss: 1.6284358501434326\n",
            "epoch: 1, iteratation 2103, loss: 1.5383245944976807\n",
            "epoch: 1, iteratation 2104, loss: 1.5603766441345215\n",
            "epoch: 1, iteratation 2105, loss: 1.537484884262085\n",
            "epoch: 1, iteratation 2106, loss: 1.57627272605896\n",
            "epoch: 1, iteratation 2107, loss: 1.5305818319320679\n",
            "epoch: 1, iteratation 2108, loss: 1.4913966655731201\n",
            "epoch: 1, iteratation 2109, loss: 1.5359634160995483\n",
            "epoch: 1, iteratation 2110, loss: 1.5767816305160522\n",
            "epoch: 1, iteratation 2111, loss: 1.4710458517074585\n",
            "epoch: 1, iteratation 2112, loss: 1.5938048362731934\n",
            "epoch: 1, iteratation 2113, loss: 1.6977543830871582\n",
            "epoch: 1, iteratation 2114, loss: 1.800183653831482\n",
            "epoch: 1, iteratation 2115, loss: 1.683448076248169\n",
            "epoch: 1, iteratation 2116, loss: 1.4769208431243896\n",
            "epoch: 1, iteratation 2117, loss: 1.5124406814575195\n",
            "epoch: 1, iteratation 2118, loss: 1.599755048751831\n",
            "epoch: 1, iteratation 2119, loss: 1.5532039403915405\n",
            "epoch: 1, iteratation 2120, loss: 1.7217302322387695\n",
            "epoch: 1, iteratation 2121, loss: 1.5168745517730713\n",
            "epoch: 1, iteratation 2122, loss: 1.5341346263885498\n",
            "epoch: 1, iteratation 2123, loss: 1.6222562789916992\n",
            "epoch: 1, iteratation 2124, loss: 1.866544485092163\n",
            "epoch: 1, iteratation 2125, loss: 1.4893403053283691\n",
            "epoch: 1, iteratation 2126, loss: 1.5565717220306396\n",
            "epoch: 1, iteratation 2127, loss: 1.5542716979980469\n",
            "epoch: 1, iteratation 2128, loss: 1.6954468488693237\n",
            "epoch: 1, iteratation 2129, loss: 1.612041711807251\n",
            "epoch: 1, iteratation 2130, loss: 1.6365671157836914\n",
            "epoch: 1, iteratation 2131, loss: 1.6091493368148804\n",
            "epoch: 1, iteratation 2132, loss: 1.5956038236618042\n",
            "epoch: 1, iteratation 2133, loss: 1.5657339096069336\n",
            "epoch: 1, iteratation 2134, loss: 1.5567026138305664\n",
            "epoch: 1, iteratation 2135, loss: 1.5370042324066162\n",
            "epoch: 1, iteratation 2136, loss: 1.4881811141967773\n",
            "epoch: 1, iteratation 2137, loss: 1.471118688583374\n",
            "epoch: 1, iteratation 2138, loss: 1.5709342956542969\n",
            "epoch: 1, iteratation 2139, loss: 1.3955833911895752\n",
            "epoch: 1, iteratation 2140, loss: 1.6005477905273438\n",
            "epoch: 1, iteratation 2141, loss: 1.6997106075286865\n",
            "epoch: 1, iteratation 2142, loss: 1.6651767492294312\n",
            "epoch: 1, iteratation 2143, loss: 1.6442360877990723\n",
            "epoch: 1, iteratation 2144, loss: 1.5707687139511108\n",
            "epoch: 1, iteratation 2145, loss: 1.4794223308563232\n",
            "epoch: 1, iteratation 2146, loss: 1.418029546737671\n",
            "epoch: 1, iteratation 2147, loss: 1.539341688156128\n",
            "epoch: 1, iteratation 2148, loss: 1.5875637531280518\n",
            "epoch: 1, iteratation 2149, loss: 1.6171987056732178\n",
            "epoch: 1, iteratation 2150, loss: 1.7230110168457031\n",
            "epoch: 1, iteratation 2151, loss: 1.6435598134994507\n",
            "epoch: 1, iteratation 2152, loss: 1.4969384670257568\n",
            "epoch: 1, iteratation 2153, loss: 1.5823800563812256\n",
            "epoch: 1, iteratation 2154, loss: 1.5458974838256836\n",
            "epoch: 1, iteratation 2155, loss: 1.6592057943344116\n",
            "epoch: 1, iteratation 2156, loss: 1.702195644378662\n",
            "epoch: 1, iteratation 2157, loss: 1.5873135328292847\n",
            "epoch: 1, iteratation 2158, loss: 1.646887183189392\n",
            "epoch: 1, iteratation 2159, loss: 1.7380220890045166\n",
            "epoch: 1, iteratation 2160, loss: 1.4993846416473389\n",
            "epoch: 1, iteratation 2161, loss: 1.4915941953659058\n",
            "epoch: 1, iteratation 2162, loss: 1.5715599060058594\n",
            "epoch: 1, iteratation 2163, loss: 1.5562810897827148\n",
            "epoch: 1, iteratation 2164, loss: 1.6799901723861694\n",
            "epoch: 1, iteratation 2165, loss: 1.693005919456482\n",
            "epoch: 1, iteratation 2166, loss: 1.5461766719818115\n",
            "epoch: 1, iteratation 2167, loss: 1.724298357963562\n",
            "epoch: 1, iteratation 2168, loss: 1.8259494304656982\n",
            "epoch: 1, iteratation 2169, loss: 1.63828444480896\n",
            "epoch: 1, iteratation 2170, loss: 1.5627248287200928\n",
            "epoch: 1, iteratation 2171, loss: 1.4750239849090576\n",
            "epoch: 1, iteratation 2172, loss: 1.6609162092208862\n",
            "epoch: 1, iteratation 2173, loss: 1.6108596324920654\n",
            "epoch: 1, iteratation 2174, loss: 1.6387720108032227\n",
            "epoch: 1, iteratation 2175, loss: 1.5219085216522217\n",
            "epoch: 1, iteratation 2176, loss: 1.605243444442749\n",
            "epoch: 1, iteratation 2177, loss: 1.5344245433807373\n",
            "epoch: 1, iteratation 2178, loss: 1.7811754941940308\n",
            "epoch: 1, iteratation 2179, loss: 1.3894075155258179\n",
            "epoch: 1, iteratation 2180, loss: 1.491243839263916\n",
            "epoch: 1, iteratation 2181, loss: 1.721031665802002\n",
            "epoch: 1, iteratation 2182, loss: 1.6291049718856812\n",
            "epoch: 1, iteratation 2183, loss: 1.442621111869812\n",
            "epoch: 1, iteratation 2184, loss: 1.6362252235412598\n",
            "epoch: 1, iteratation 2185, loss: 1.608790397644043\n",
            "epoch: 1, iteratation 2186, loss: 1.6437091827392578\n",
            "epoch: 1, iteratation 2187, loss: 1.499150037765503\n",
            "epoch: 1, iteratation 2188, loss: 1.8424203395843506\n",
            "epoch: 1, iteratation 2189, loss: 1.5455358028411865\n",
            "epoch: 1, iteratation 2190, loss: 1.5238159894943237\n",
            "epoch: 1, iteratation 2191, loss: 1.5737022161483765\n",
            "epoch: 1, iteratation 2192, loss: 1.5929982662200928\n",
            "epoch: 1, iteratation 2193, loss: 1.6382458209991455\n",
            "epoch: 1, iteratation 2194, loss: 1.624495267868042\n",
            "epoch: 1, iteratation 2195, loss: 1.667792558670044\n",
            "epoch: 1, iteratation 2196, loss: 1.352308750152588\n",
            "epoch: 1, iteratation 2197, loss: 1.5229305028915405\n",
            "epoch: 1, iteratation 2198, loss: 1.5530836582183838\n",
            "epoch: 1, iteratation 2199, loss: 1.4329719543457031\n",
            "epoch: 1, iteratation 2200, loss: 1.5524883270263672\n",
            "epoch: 1, iteratation 2201, loss: 1.5562551021575928\n",
            "epoch: 1, iteratation 2202, loss: 1.6068686246871948\n",
            "epoch: 1, iteratation 2203, loss: 1.6678307056427002\n",
            "epoch: 1, iteratation 2204, loss: 1.6145555973052979\n",
            "epoch: 1, iteratation 2205, loss: 1.5705794095993042\n",
            "epoch: 1, iteratation 2206, loss: 1.8620116710662842\n",
            "epoch: 1, iteratation 2207, loss: 1.5245599746704102\n",
            "epoch: 1, iteratation 2208, loss: 1.6145994663238525\n",
            "epoch: 1, iteratation 2209, loss: 1.664414882659912\n",
            "epoch: 1, iteratation 2210, loss: 1.66645085811615\n",
            "epoch: 1, iteratation 2211, loss: 1.6239842176437378\n",
            "epoch: 1, iteratation 2212, loss: 1.5100927352905273\n",
            "epoch: 1, iteratation 2213, loss: 1.5086902379989624\n",
            "epoch: 1, iteratation 2214, loss: 1.3754929304122925\n",
            "epoch: 1, iteratation 2215, loss: 1.5527846813201904\n",
            "epoch: 1, iteratation 2216, loss: 1.4917576313018799\n",
            "epoch: 1, iteratation 2217, loss: 1.5423390865325928\n",
            "epoch: 1, iteratation 2218, loss: 1.4980571269989014\n",
            "epoch: 1, iteratation 2219, loss: 1.6303184032440186\n",
            "epoch: 1, iteratation 2220, loss: 1.5037721395492554\n",
            "epoch: 1, iteratation 2221, loss: 1.645943522453308\n",
            "epoch: 1, iteratation 2222, loss: 1.8023507595062256\n",
            "epoch: 1, iteratation 2223, loss: 1.6394709348678589\n",
            "epoch: 1, iteratation 2224, loss: 1.5310554504394531\n",
            "epoch: 1, iteratation 2225, loss: 1.5675950050354004\n",
            "epoch: 1, iteratation 2226, loss: 1.6136010885238647\n",
            "epoch: 1, iteratation 2227, loss: 1.536839246749878\n",
            "epoch: 1, iteratation 2228, loss: 1.4675815105438232\n",
            "epoch: 1, iteratation 2229, loss: 1.5273959636688232\n",
            "epoch: 1, iteratation 2230, loss: 1.7022451162338257\n",
            "epoch: 1, iteratation 2231, loss: 1.4525294303894043\n",
            "epoch: 1, iteratation 2232, loss: 1.5021113157272339\n",
            "epoch: 1, iteratation 2233, loss: 1.4281232357025146\n",
            "epoch: 1, iteratation 2234, loss: 1.3891396522521973\n",
            "epoch: 1, iteratation 2235, loss: 1.556688666343689\n",
            "epoch: 1, iteratation 2236, loss: 1.7506340742111206\n",
            "epoch: 1, iteratation 2237, loss: 1.5436887741088867\n",
            "epoch: 1, iteratation 2238, loss: 1.3979119062423706\n",
            "epoch: 1, iteratation 2239, loss: 1.4801442623138428\n",
            "epoch: 1, iteratation 2240, loss: 1.5356864929199219\n",
            "epoch: 1, iteratation 2241, loss: 1.5540828704833984\n",
            "epoch: 1, iteratation 2242, loss: 1.5150177478790283\n",
            "epoch: 1, iteratation 2243, loss: 1.6490237712860107\n",
            "epoch: 1, iteratation 2244, loss: 1.4345910549163818\n",
            "epoch: 1, iteratation 2245, loss: 1.471426010131836\n",
            "epoch: 1, iteratation 2246, loss: 1.633316993713379\n",
            "epoch: 1, iteratation 2247, loss: 1.431679129600525\n",
            "epoch: 1, iteratation 2248, loss: 1.9822973012924194\n",
            "epoch: 1, iteratation 2249, loss: 2.3406665325164795\n",
            "epoch: 1, iteratation 2250, loss: 2.350818395614624\n",
            "epoch: 1, iteratation 2251, loss: 2.3180654048919678\n",
            "epoch: 1, iteratation 2252, loss: 2.256155252456665\n",
            "epoch: 1, iteratation 2253, loss: 2.202394723892212\n",
            "epoch: 1, iteratation 2254, loss: 2.131132125854492\n",
            "epoch: 1, iteratation 2255, loss: 2.0046215057373047\n",
            "epoch: 1, iteratation 2256, loss: 1.9619412422180176\n",
            "epoch: 1, iteratation 2257, loss: 2.168768882751465\n",
            "epoch: 1, iteratation 2258, loss: 2.1310529708862305\n",
            "epoch: 1, iteratation 2259, loss: 2.0940213203430176\n",
            "epoch: 1, iteratation 2260, loss: 2.12477970123291\n",
            "epoch: 1, iteratation 2261, loss: 2.0875794887542725\n",
            "epoch: 1, iteratation 2262, loss: 1.9826067686080933\n",
            "epoch: 1, iteratation 2263, loss: 2.0277106761932373\n",
            "epoch: 1, iteratation 2264, loss: 1.9943393468856812\n",
            "epoch: 1, iteratation 2265, loss: 2.0154309272766113\n",
            "epoch: 1, iteratation 2266, loss: 1.9807586669921875\n",
            "epoch: 1, iteratation 2267, loss: 2.1593830585479736\n",
            "epoch: 1, iteratation 2268, loss: 1.9857162237167358\n",
            "epoch: 1, iteratation 2269, loss: 2.020482301712036\n",
            "epoch: 1, iteratation 2270, loss: 2.0497684478759766\n",
            "epoch: 1, iteratation 2271, loss: 2.005096912384033\n",
            "epoch: 1, iteratation 2272, loss: 1.9811077117919922\n",
            "epoch: 1, iteratation 2273, loss: 2.010775089263916\n",
            "epoch: 1, iteratation 2274, loss: 1.9450515508651733\n",
            "epoch: 1, iteratation 2275, loss: 1.9614207744598389\n",
            "epoch: 1, iteratation 2276, loss: 1.8481566905975342\n",
            "epoch: 1, iteratation 2277, loss: 1.9417331218719482\n",
            "epoch: 1, iteratation 2278, loss: 1.9507160186767578\n",
            "epoch: 1, iteratation 2279, loss: 2.0046191215515137\n",
            "epoch: 1, iteratation 2280, loss: 2.0317211151123047\n",
            "epoch: 1, iteratation 2281, loss: 1.94253671169281\n",
            "epoch: 1, iteratation 2282, loss: 1.8921951055526733\n",
            "epoch: 1, iteratation 2283, loss: 1.9358563423156738\n",
            "epoch: 1, iteratation 2284, loss: 1.8996562957763672\n",
            "epoch: 1, iteratation 2285, loss: 1.9400227069854736\n",
            "epoch: 1, iteratation 2286, loss: 1.8943122625350952\n",
            "epoch: 1, iteratation 2287, loss: 1.8585710525512695\n",
            "epoch: 1, iteratation 2288, loss: 1.8492646217346191\n",
            "epoch: 1, iteratation 2289, loss: 1.951843023300171\n",
            "epoch: 1, iteratation 2290, loss: 1.8167445659637451\n",
            "epoch: 1, iteratation 2291, loss: 2.0278966426849365\n",
            "epoch: 1, iteratation 2292, loss: 1.8792651891708374\n",
            "epoch: 1, iteratation 2293, loss: 1.8456748723983765\n",
            "epoch: 1, iteratation 2294, loss: 1.862787127494812\n",
            "epoch: 1, iteratation 2295, loss: 1.9356811046600342\n",
            "epoch: 1, iteratation 2296, loss: 1.8530139923095703\n",
            "epoch: 1, iteratation 2297, loss: 1.8575743436813354\n",
            "epoch: 1, iteratation 2298, loss: 1.8999600410461426\n",
            "epoch: 1, iteratation 2299, loss: 1.877435564994812\n",
            "epoch: 1, iteratation 2300, loss: 1.950540542602539\n",
            "epoch: 1, iteratation 2301, loss: 1.9784005880355835\n",
            "epoch: 1, iteratation 2302, loss: 1.9504916667938232\n",
            "epoch: 1, iteratation 2303, loss: 1.942557692527771\n",
            "epoch: 1, iteratation 2304, loss: 1.8743743896484375\n",
            "epoch: 1, iteratation 2305, loss: 1.8305516242980957\n",
            "epoch: 1, iteratation 2306, loss: 1.895979642868042\n",
            "epoch: 1, iteratation 2307, loss: 1.8055814504623413\n",
            "epoch: 1, iteratation 2308, loss: 1.900570273399353\n",
            "epoch: 1, iteratation 2309, loss: 1.7859253883361816\n",
            "epoch: 1, iteratation 2310, loss: 1.8767857551574707\n",
            "epoch: 1, iteratation 2311, loss: 1.8222920894622803\n",
            "epoch: 1, iteratation 2312, loss: 1.7788736820220947\n",
            "epoch: 1, iteratation 2313, loss: 1.892352819442749\n",
            "epoch: 1, iteratation 2314, loss: 1.8201236724853516\n",
            "epoch: 1, iteratation 2315, loss: 1.82987642288208\n",
            "epoch: 1, iteratation 2316, loss: 1.7496387958526611\n",
            "epoch: 1, iteratation 2317, loss: 1.7890031337738037\n",
            "epoch: 1, iteratation 2318, loss: 1.7914679050445557\n",
            "epoch: 1, iteratation 2319, loss: 2.2357935905456543\n",
            "epoch: 1, iteratation 2320, loss: 1.8150184154510498\n",
            "epoch: 1, iteratation 2321, loss: 1.801717758178711\n",
            "epoch: 1, iteratation 2322, loss: 1.8235739469528198\n",
            "epoch: 1, iteratation 2323, loss: 1.8757641315460205\n",
            "epoch: 1, iteratation 2324, loss: 1.7791194915771484\n",
            "epoch: 1, iteratation 2325, loss: 1.734809398651123\n",
            "epoch: 1, iteratation 2326, loss: 1.6496700048446655\n",
            "epoch: 1, iteratation 2327, loss: 1.9113038778305054\n",
            "epoch: 1, iteratation 2328, loss: 1.7970266342163086\n",
            "epoch: 1, iteratation 2329, loss: 1.8058507442474365\n",
            "epoch: 1, iteratation 2330, loss: 1.8961241245269775\n",
            "epoch: 1, iteratation 2331, loss: 1.716657042503357\n",
            "epoch: 1, iteratation 2332, loss: 1.7685410976409912\n",
            "epoch: 1, iteratation 2333, loss: 1.856175184249878\n",
            "epoch: 1, iteratation 2334, loss: 1.8302948474884033\n",
            "epoch: 1, iteratation 2335, loss: 2.035783052444458\n",
            "epoch: 1, iteratation 2336, loss: 1.860550880432129\n",
            "epoch: 1, iteratation 2337, loss: 1.8504422903060913\n",
            "epoch: 1, iteratation 2338, loss: 1.8050031661987305\n",
            "epoch: 1, iteratation 2339, loss: 1.831870436668396\n",
            "epoch: 1, iteratation 2340, loss: 1.8681925535202026\n",
            "epoch: 1, iteratation 2341, loss: 1.8242168426513672\n",
            "epoch: 1, iteratation 2342, loss: 1.7601490020751953\n",
            "epoch: 1, iteratation 2343, loss: 1.8016383647918701\n",
            "epoch: 1, iteratation 2344, loss: 1.878901720046997\n",
            "epoch: 1, iteratation 2345, loss: 1.7221829891204834\n",
            "epoch: 1, iteratation 2346, loss: 1.7638435363769531\n",
            "epoch: 1, iteratation 2347, loss: 1.7309751510620117\n",
            "epoch: 1, iteratation 2348, loss: 1.8812100887298584\n",
            "epoch: 1, iteratation 2349, loss: 1.9502251148223877\n",
            "epoch: 1, iteratation 2350, loss: 1.776504397392273\n",
            "epoch: 1, iteratation 2351, loss: 1.8620953559875488\n",
            "epoch: 1, iteratation 2352, loss: 1.763728380203247\n",
            "epoch: 1, iteratation 2353, loss: 1.805426001548767\n",
            "epoch: 1, iteratation 2354, loss: 1.9283361434936523\n",
            "epoch: 1, iteratation 2355, loss: 1.844840407371521\n",
            "epoch: 1, iteratation 2356, loss: 1.7455568313598633\n",
            "epoch: 1, iteratation 2357, loss: 1.8217101097106934\n",
            "epoch: 1, iteratation 2358, loss: 1.7223412990570068\n",
            "epoch: 1, iteratation 2359, loss: 1.782613754272461\n",
            "epoch: 1, iteratation 2360, loss: 1.7696336507797241\n",
            "epoch: 1, iteratation 2361, loss: 1.7042303085327148\n",
            "epoch: 1, iteratation 2362, loss: 1.8674240112304688\n",
            "epoch: 1, iteratation 2363, loss: 1.7901480197906494\n",
            "epoch: 1, iteratation 2364, loss: 1.8214091062545776\n",
            "epoch: 1, iteratation 2365, loss: 1.754042148590088\n",
            "epoch: 1, iteratation 2366, loss: 1.7464507818222046\n",
            "epoch: 1, iteratation 2367, loss: 1.6677874326705933\n",
            "epoch: 1, iteratation 2368, loss: 1.7514142990112305\n",
            "epoch: 1, iteratation 2369, loss: 1.7514691352844238\n",
            "epoch: 1, iteratation 2370, loss: 1.9975519180297852\n",
            "epoch: 1, iteratation 2371, loss: 1.903739333152771\n",
            "epoch: 1, iteratation 2372, loss: 1.8552792072296143\n",
            "epoch: 1, iteratation 2373, loss: 1.6561241149902344\n",
            "epoch: 1, iteratation 2374, loss: 1.7615118026733398\n",
            "epoch: 1, iteratation 2375, loss: 1.8413937091827393\n",
            "epoch: 1, iteratation 2376, loss: 1.7592287063598633\n",
            "epoch: 1, iteratation 2377, loss: 1.721540927886963\n",
            "epoch: 1, iteratation 2378, loss: 1.7855498790740967\n",
            "epoch: 1, iteratation 2379, loss: 1.701171636581421\n",
            "epoch: 1, iteratation 2380, loss: 1.864316701889038\n",
            "epoch: 1, iteratation 2381, loss: 1.7263301610946655\n",
            "epoch: 1, iteratation 2382, loss: 1.6116126775741577\n",
            "epoch: 1, iteratation 2383, loss: 1.8267548084259033\n",
            "epoch: 1, iteratation 2384, loss: 1.8007439374923706\n",
            "epoch: 1, iteratation 2385, loss: 1.6671260595321655\n",
            "epoch: 1, iteratation 2386, loss: 1.7426989078521729\n",
            "epoch: 1, iteratation 2387, loss: 1.726778268814087\n",
            "epoch: 1, iteratation 2388, loss: 1.9190043210983276\n",
            "epoch: 1, iteratation 2389, loss: 1.7138020992279053\n",
            "epoch: 1, iteratation 2390, loss: 1.7666902542114258\n",
            "epoch: 1, iteratation 2391, loss: 1.6443160772323608\n",
            "epoch: 1, iteratation 2392, loss: 1.70956552028656\n",
            "epoch: 1, iteratation 2393, loss: 1.6173299551010132\n",
            "epoch: 1, iteratation 2394, loss: 1.646935224533081\n",
            "epoch: 1, iteratation 2395, loss: 1.6649930477142334\n",
            "epoch: 1, iteratation 2396, loss: 1.7658936977386475\n",
            "epoch: 1, iteratation 2397, loss: 1.8065317869186401\n",
            "epoch: 1, iteratation 2398, loss: 1.746817946434021\n",
            "epoch: 1, iteratation 2399, loss: 1.8571434020996094\n",
            "epoch: 1, iteratation 2400, loss: 1.7360734939575195\n",
            "epoch: 1, iteratation 2401, loss: 1.6533451080322266\n",
            "epoch: 1, iteratation 2402, loss: 1.6349761486053467\n",
            "epoch: 1, iteratation 2403, loss: 1.8183015584945679\n",
            "epoch: 1, iteratation 2404, loss: 1.7088931798934937\n",
            "epoch: 1, iteratation 2405, loss: 1.736650824546814\n",
            "epoch: 1, iteratation 2406, loss: 1.6886682510375977\n",
            "epoch: 1, iteratation 2407, loss: 1.6038379669189453\n",
            "epoch: 1, iteratation 2408, loss: 1.5809601545333862\n",
            "epoch: 1, iteratation 2409, loss: 1.6487205028533936\n",
            "epoch: 1, iteratation 2410, loss: 1.6621513366699219\n",
            "epoch: 1, iteratation 2411, loss: 1.7204434871673584\n",
            "epoch: 1, iteratation 2412, loss: 1.6627650260925293\n",
            "epoch: 1, iteratation 2413, loss: 1.7649486064910889\n",
            "epoch: 1, iteratation 2414, loss: 1.7853026390075684\n",
            "epoch: 1, iteratation 2415, loss: 1.6441590785980225\n",
            "epoch: 1, iteratation 2416, loss: 1.7228124141693115\n",
            "epoch: 1, iteratation 2417, loss: 1.5799936056137085\n",
            "epoch: 1, iteratation 2418, loss: 1.6099271774291992\n",
            "epoch: 1, iteratation 2419, loss: 1.585542917251587\n",
            "epoch: 1, iteratation 2420, loss: 1.5314288139343262\n",
            "epoch: 1, iteratation 2421, loss: 1.69375741481781\n",
            "epoch: 1, iteratation 2422, loss: 1.7061078548431396\n",
            "epoch: 1, iteratation 2423, loss: 1.7799118757247925\n",
            "epoch: 1, iteratation 2424, loss: 1.7739570140838623\n",
            "epoch: 1, iteratation 2425, loss: 1.6760268211364746\n",
            "epoch: 1, iteratation 2426, loss: 1.6910394430160522\n",
            "epoch: 1, iteratation 2427, loss: 1.7078989744186401\n",
            "epoch: 1, iteratation 2428, loss: 1.5937120914459229\n",
            "epoch: 1, iteratation 2429, loss: 1.7945032119750977\n",
            "epoch: 1, iteratation 2430, loss: 1.735174536705017\n",
            "epoch: 1, iteratation 2431, loss: 1.7543976306915283\n",
            "epoch: 1, iteratation 2432, loss: 1.699297308921814\n",
            "epoch: 1, iteratation 2433, loss: 1.6609538793563843\n",
            "epoch: 1, iteratation 2434, loss: 1.7064905166625977\n",
            "epoch: 1, iteratation 2435, loss: 1.678191900253296\n",
            "epoch: 1, iteratation 2436, loss: 1.5434455871582031\n",
            "epoch: 1, iteratation 2437, loss: 1.6691246032714844\n",
            "epoch: 1, iteratation 2438, loss: 1.611169695854187\n",
            "epoch: 1, iteratation 2439, loss: 1.687456488609314\n",
            "epoch: 1, iteratation 2440, loss: 1.8201158046722412\n",
            "epoch: 1, iteratation 2441, loss: 1.584323763847351\n",
            "epoch: 1, iteratation 2442, loss: 1.6737630367279053\n",
            "epoch: 1, iteratation 2443, loss: 2.000246524810791\n",
            "epoch: 1, iteratation 2444, loss: 1.8832224607467651\n",
            "epoch: 1, iteratation 2445, loss: 1.5881012678146362\n",
            "epoch: 1, iteratation 2446, loss: 1.6495771408081055\n",
            "epoch: 1, iteratation 2447, loss: 1.6707019805908203\n",
            "epoch: 1, iteratation 2448, loss: 1.6674015522003174\n",
            "epoch: 1, iteratation 2449, loss: 2.0178475379943848\n",
            "epoch: 1, iteratation 2450, loss: 1.9305903911590576\n",
            "epoch: 1, iteratation 2451, loss: 1.697103500366211\n",
            "epoch: 1, iteratation 2452, loss: 1.681699275970459\n",
            "epoch: 1, iteratation 2453, loss: 1.6050466299057007\n",
            "epoch: 1, iteratation 2454, loss: 1.7411693334579468\n",
            "epoch: 1, iteratation 2455, loss: 1.7427257299423218\n",
            "epoch: 1, iteratation 2456, loss: 1.6457910537719727\n",
            "epoch: 1, iteratation 2457, loss: 1.6989474296569824\n",
            "epoch: 1, iteratation 2458, loss: 1.7605550289154053\n",
            "epoch: 1, iteratation 2459, loss: 1.9530009031295776\n",
            "epoch: 1, iteratation 2460, loss: 1.7386120557785034\n",
            "epoch: 1, iteratation 2461, loss: 1.6081428527832031\n",
            "epoch: 1, iteratation 2462, loss: 1.6475005149841309\n",
            "epoch: 1, iteratation 2463, loss: 1.6277673244476318\n",
            "epoch: 1, iteratation 2464, loss: 1.7840125560760498\n",
            "epoch: 1, iteratation 2465, loss: 1.6823023557662964\n",
            "epoch: 1, iteratation 2466, loss: 1.7664201259613037\n",
            "epoch: 1, iteratation 2467, loss: 1.7407071590423584\n",
            "epoch: 1, iteratation 2468, loss: 1.600721836090088\n",
            "epoch: 1, iteratation 2469, loss: 1.6121826171875\n",
            "epoch: 1, iteratation 2470, loss: 1.670548439025879\n",
            "epoch: 1, iteratation 2471, loss: 1.6450920104980469\n",
            "epoch: 1, iteratation 2472, loss: 1.6798675060272217\n",
            "epoch: 1, iteratation 2473, loss: 1.835261344909668\n",
            "epoch: 1, iteratation 2474, loss: 1.6299594640731812\n",
            "epoch: 1, iteratation 2475, loss: 1.618734359741211\n",
            "epoch: 1, iteratation 2476, loss: 1.5825674533843994\n",
            "epoch: 1, iteratation 2477, loss: 1.6539376974105835\n",
            "epoch: 1, iteratation 2478, loss: 1.578750491142273\n",
            "epoch: 1, iteratation 2479, loss: 1.7253960371017456\n",
            "epoch: 1, iteratation 2480, loss: 1.6344125270843506\n",
            "epoch: 1, iteratation 2481, loss: 1.7358684539794922\n",
            "epoch: 1, iteratation 2482, loss: 1.6604688167572021\n",
            "epoch: 1, iteratation 2483, loss: 1.7052688598632812\n",
            "epoch: 1, iteratation 2484, loss: 1.6253759860992432\n",
            "epoch: 1, iteratation 2485, loss: 1.761687994003296\n",
            "epoch: 1, iteratation 2486, loss: 1.752152442932129\n",
            "epoch: 1, iteratation 2487, loss: 1.5831353664398193\n",
            "epoch: 1, iteratation 2488, loss: 1.639040231704712\n",
            "epoch: 1, iteratation 2489, loss: 1.6349294185638428\n",
            "epoch: 1, iteratation 2490, loss: 1.7511271238327026\n",
            "epoch: 1, iteratation 2491, loss: 1.6196403503417969\n",
            "epoch: 1, iteratation 2492, loss: 1.7081035375595093\n",
            "epoch: 1, iteratation 2493, loss: 1.6478147506713867\n",
            "epoch: 1, iteratation 2494, loss: 1.6118829250335693\n",
            "epoch: 1, iteratation 2495, loss: 1.6082370281219482\n",
            "epoch: 1, iteratation 2496, loss: 1.6995481252670288\n",
            "epoch: 1, iteratation 2497, loss: 1.6772279739379883\n",
            "epoch: 1, iteratation 2498, loss: 1.617002248764038\n",
            "epoch: 1, iteratation 2499, loss: 1.858168601989746\n",
            "epoch: 1, iteratation 2500, loss: 1.6252654790878296\n",
            "epoch: 1, iteratation 2501, loss: 1.566554069519043\n",
            "epoch: 1, iteratation 2502, loss: 1.7511438131332397\n",
            "epoch: 1, iteratation 2503, loss: 1.7335718870162964\n",
            "epoch: 1, iteratation 2504, loss: 1.784491777420044\n",
            "epoch: 1, iteratation 2505, loss: 1.6327497959136963\n",
            "epoch: 1, iteratation 2506, loss: 1.6972869634628296\n",
            "epoch: 1, iteratation 2507, loss: 1.5917294025421143\n",
            "epoch: 1, iteratation 2508, loss: 1.6702146530151367\n",
            "epoch: 1, iteratation 2509, loss: 1.7284972667694092\n",
            "epoch: 1, iteratation 2510, loss: 1.703407645225525\n",
            "epoch: 1, iteratation 2511, loss: 1.6714069843292236\n",
            "epoch: 1, iteratation 2512, loss: 1.7295622825622559\n",
            "epoch: 1, iteratation 2513, loss: 1.6863107681274414\n",
            "epoch: 1, iteratation 2514, loss: 1.847142219543457\n",
            "epoch: 1, iteratation 2515, loss: 1.9818675518035889\n",
            "epoch: 1, iteratation 2516, loss: 1.8922507762908936\n",
            "epoch: 1, iteratation 2517, loss: 1.6777324676513672\n",
            "epoch: 1, iteratation 2518, loss: 1.6261167526245117\n",
            "epoch: 1, iteratation 2519, loss: 1.7388453483581543\n",
            "epoch: 1, iteratation 2520, loss: 1.6320655345916748\n",
            "epoch: 1, iteratation 2521, loss: 1.653019666671753\n",
            "epoch: 1, iteratation 2522, loss: 1.6361629962921143\n",
            "epoch: 1, iteratation 2523, loss: 1.715677261352539\n",
            "epoch: 1, iteratation 2524, loss: 1.8697826862335205\n",
            "epoch: 1, iteratation 2525, loss: 1.820221185684204\n",
            "epoch: 1, iteratation 2526, loss: 1.5529807806015015\n",
            "epoch: 1, iteratation 2527, loss: 1.700602412223816\n",
            "epoch: 1, iteratation 2528, loss: 1.6544030904769897\n",
            "epoch: 1, iteratation 2529, loss: 1.6747815608978271\n",
            "epoch: 1, iteratation 2530, loss: 1.6353271007537842\n",
            "epoch: 1, iteratation 2531, loss: 1.5040382146835327\n",
            "epoch: 1, iteratation 2532, loss: 1.6121673583984375\n",
            "epoch: 1, iteratation 2533, loss: 1.6632026433944702\n",
            "epoch: 1, iteratation 2534, loss: 1.7108354568481445\n",
            "epoch: 1, iteratation 2535, loss: 1.6453254222869873\n",
            "epoch: 1, iteratation 2536, loss: 1.609001874923706\n",
            "epoch: 1, iteratation 2537, loss: 1.571420431137085\n",
            "epoch: 1, iteratation 2538, loss: 1.5841069221496582\n",
            "epoch: 1, iteratation 2539, loss: 1.6015453338623047\n",
            "epoch: 1, iteratation 2540, loss: 1.6963609457015991\n",
            "epoch: 1, iteratation 2541, loss: 1.5972168445587158\n",
            "epoch: 1, iteratation 2542, loss: 1.6733262538909912\n",
            "epoch: 1, iteratation 2543, loss: 1.7081964015960693\n",
            "epoch: 1, iteratation 2544, loss: 1.6126054525375366\n",
            "epoch: 1, iteratation 2545, loss: 1.6218888759613037\n",
            "epoch: 1, iteratation 2546, loss: 1.7033557891845703\n",
            "epoch: 1, iteratation 2547, loss: 1.5908851623535156\n",
            "epoch: 1, iteratation 2548, loss: 1.6721148490905762\n",
            "epoch: 1, iteratation 2549, loss: 1.7231173515319824\n",
            "epoch: 1, iteratation 2550, loss: 1.616330862045288\n",
            "epoch: 1, iteratation 2551, loss: 1.5851249694824219\n",
            "epoch: 1, iteratation 2552, loss: 1.5886304378509521\n",
            "epoch: 1, iteratation 2553, loss: 1.656630039215088\n",
            "epoch: 1, iteratation 2554, loss: 1.6993978023529053\n",
            "epoch: 1, iteratation 2555, loss: 1.7989883422851562\n",
            "epoch: 1, iteratation 2556, loss: 1.7955892086029053\n",
            "epoch: 1, iteratation 2557, loss: 1.5095577239990234\n",
            "epoch: 1, iteratation 2558, loss: 1.7662605047225952\n",
            "epoch: 1, iteratation 2559, loss: 1.5679845809936523\n",
            "epoch: 1, iteratation 2560, loss: 1.6199281215667725\n",
            "epoch: 1, iteratation 2561, loss: 1.5809693336486816\n",
            "epoch: 1, iteratation 2562, loss: 1.6498775482177734\n",
            "epoch: 1, iteratation 2563, loss: 1.6934854984283447\n",
            "epoch: 1, iteratation 2564, loss: 1.746370553970337\n",
            "epoch: 1, iteratation 2565, loss: 1.578940749168396\n",
            "epoch: 1, iteratation 2566, loss: 1.5684155225753784\n",
            "epoch: 1, iteratation 2567, loss: 1.7554700374603271\n",
            "epoch: 1, iteratation 2568, loss: 1.5937598943710327\n",
            "epoch: 1, iteratation 2569, loss: 1.7355659008026123\n",
            "epoch: 1, iteratation 2570, loss: 1.6203420162200928\n",
            "epoch: 1, iteratation 2571, loss: 1.5523327589035034\n",
            "epoch: 1, iteratation 2572, loss: 1.6720359325408936\n",
            "epoch: 1, iteratation 2573, loss: 1.73164963722229\n",
            "epoch: 1, iteratation 2574, loss: 1.5746803283691406\n",
            "epoch: 1, iteratation 2575, loss: 1.7142194509506226\n",
            "epoch: 1, iteratation 2576, loss: 1.5172971487045288\n",
            "epoch: 1, iteratation 2577, loss: 1.6814491748809814\n",
            "epoch: 1, iteratation 2578, loss: 1.6790708303451538\n",
            "epoch: 1, iteratation 2579, loss: 1.7414004802703857\n",
            "epoch: 1, iteratation 2580, loss: 1.652256965637207\n",
            "epoch: 1, iteratation 2581, loss: 1.6513395309448242\n",
            "epoch: 1, iteratation 2582, loss: 1.6160249710083008\n",
            "epoch: 1, iteratation 2583, loss: 1.7182672023773193\n",
            "epoch: 1, iteratation 2584, loss: 1.6797406673431396\n",
            "epoch: 1, iteratation 2585, loss: 1.755305528640747\n",
            "epoch: 1, iteratation 2586, loss: 1.5979609489440918\n",
            "epoch: 1, iteratation 2587, loss: 1.7036855220794678\n",
            "epoch: 1, iteratation 2588, loss: 1.6087782382965088\n",
            "epoch: 1, iteratation 2589, loss: 1.5810325145721436\n",
            "epoch: 1, iteratation 2590, loss: 1.662778377532959\n",
            "epoch: 1, iteratation 2591, loss: 1.7136706113815308\n",
            "epoch: 1, iteratation 2592, loss: 1.6703577041625977\n",
            "epoch: 1, iteratation 2593, loss: 1.5321311950683594\n",
            "epoch: 1, iteratation 2594, loss: 1.5321557521820068\n",
            "epoch: 1, iteratation 2595, loss: 1.6360442638397217\n",
            "epoch: 1, iteratation 2596, loss: 1.5086320638656616\n",
            "epoch: 1, iteratation 2597, loss: 1.5582736730575562\n",
            "epoch: 1, iteratation 2598, loss: 1.4877570867538452\n",
            "epoch: 1, iteratation 2599, loss: 1.6724357604980469\n",
            "epoch: 1, iteratation 2600, loss: 1.7503035068511963\n",
            "epoch: 1, iteratation 2601, loss: 1.5056979656219482\n",
            "epoch: 1, iteratation 2602, loss: 1.5184354782104492\n",
            "epoch: 1, iteratation 2603, loss: 1.6460117101669312\n",
            "epoch: 1, iteratation 2604, loss: 1.7091870307922363\n",
            "epoch: 1, iteratation 2605, loss: 1.831036925315857\n",
            "epoch: 1, iteratation 2606, loss: 1.5190776586532593\n",
            "epoch: 1, iteratation 2607, loss: 1.6246330738067627\n",
            "epoch: 1, iteratation 2608, loss: 1.5855865478515625\n",
            "epoch: 1, iteratation 2609, loss: 1.5371167659759521\n",
            "epoch: 1, iteratation 2610, loss: 1.560661792755127\n",
            "epoch: 1, iteratation 2611, loss: 1.6253957748413086\n",
            "epoch: 1, iteratation 2612, loss: 1.8062026500701904\n",
            "epoch: 1, iteratation 2613, loss: 1.5662254095077515\n",
            "epoch: 1, iteratation 2614, loss: 1.7391715049743652\n",
            "epoch: 1, iteratation 2615, loss: 1.6457128524780273\n",
            "epoch: 1, iteratation 2616, loss: 1.4786827564239502\n",
            "epoch: 1, iteratation 2617, loss: 1.4476779699325562\n",
            "epoch: 1, iteratation 2618, loss: 1.5172361135482788\n",
            "epoch: 1, iteratation 2619, loss: 1.493496298789978\n",
            "epoch: 1, iteratation 2620, loss: 1.5928308963775635\n",
            "epoch: 1, iteratation 2621, loss: 1.6861522197723389\n",
            "epoch: 1, iteratation 2622, loss: 1.4333661794662476\n",
            "epoch: 1, iteratation 2623, loss: 1.6445624828338623\n",
            "epoch: 1, iteratation 2624, loss: 1.6576616764068604\n",
            "epoch: 1, iteratation 2625, loss: 1.6659209728240967\n",
            "epoch: 1, iteratation 2626, loss: 1.536940574645996\n",
            "epoch: 1, iteratation 2627, loss: 1.4995849132537842\n",
            "epoch: 1, iteratation 2628, loss: 1.6482579708099365\n",
            "epoch: 1, iteratation 2629, loss: 1.5598173141479492\n",
            "epoch: 1, iteratation 2630, loss: 1.6856153011322021\n",
            "epoch: 1, iteratation 2631, loss: 1.6178821325302124\n",
            "epoch: 1, iteratation 2632, loss: 1.7793326377868652\n",
            "epoch: 1, iteratation 2633, loss: 1.635472059249878\n",
            "epoch: 1, iteratation 2634, loss: 1.5748800039291382\n",
            "epoch: 1, iteratation 2635, loss: 1.524632215499878\n",
            "epoch: 1, iteratation 2636, loss: 1.477691650390625\n",
            "epoch: 1, iteratation 2637, loss: 1.5631685256958008\n",
            "epoch: 1, iteratation 2638, loss: 1.5240542888641357\n",
            "epoch: 1, iteratation 2639, loss: 1.490295171737671\n",
            "epoch: 1, iteratation 2640, loss: 1.4307785034179688\n",
            "epoch: 1, iteratation 2641, loss: 1.5779684782028198\n",
            "epoch: 1, iteratation 2642, loss: 1.7594187259674072\n",
            "epoch: 1, iteratation 2643, loss: 1.5566596984863281\n",
            "epoch: 1, iteratation 2644, loss: 1.5338047742843628\n",
            "epoch: 1, iteratation 2645, loss: 1.5820274353027344\n",
            "epoch: 1, iteratation 2646, loss: 1.501143455505371\n",
            "epoch: 1, iteratation 2647, loss: 1.567218542098999\n",
            "epoch: 1, iteratation 2648, loss: 1.6490750312805176\n",
            "epoch: 1, iteratation 2649, loss: 1.6337604522705078\n",
            "epoch: 1, iteratation 2650, loss: 1.352670669555664\n",
            "epoch: 1, iteratation 2651, loss: 1.3766487836837769\n",
            "epoch: 1, iteratation 2652, loss: 1.670163869857788\n",
            "epoch: 1, iteratation 2653, loss: 1.5473130941390991\n",
            "epoch: 1, iteratation 2654, loss: 1.7538989782333374\n",
            "epoch: 1, iteratation 2655, loss: 1.4851360321044922\n",
            "epoch: 1, iteratation 2656, loss: 1.5672725439071655\n",
            "epoch: 1, iteratation 2657, loss: 1.4661495685577393\n",
            "epoch: 1, iteratation 2658, loss: 1.4861592054367065\n",
            "epoch: 1, iteratation 2659, loss: 1.6104415655136108\n",
            "epoch: 1, iteratation 2660, loss: 1.657570242881775\n",
            "epoch: 1, iteratation 2661, loss: 1.5010446310043335\n",
            "epoch: 1, iteratation 2662, loss: 1.594215750694275\n",
            "epoch: 1, iteratation 2663, loss: 1.4292380809783936\n",
            "epoch: 1, iteratation 2664, loss: 1.8666833639144897\n",
            "epoch: 1, iteratation 2665, loss: 1.784414529800415\n",
            "epoch: 1, iteratation 2666, loss: 1.638533353805542\n",
            "epoch: 1, iteratation 2667, loss: 1.6546907424926758\n",
            "epoch: 1, iteratation 2668, loss: 1.6656699180603027\n",
            "epoch: 1, iteratation 2669, loss: 1.6791003942489624\n",
            "epoch: 1, iteratation 2670, loss: 1.6021020412445068\n",
            "epoch: 1, iteratation 2671, loss: 1.6202723979949951\n",
            "epoch: 1, iteratation 2672, loss: 1.5433833599090576\n",
            "epoch: 1, iteratation 2673, loss: 1.6596472263336182\n",
            "epoch: 1, iteratation 2674, loss: 1.4526245594024658\n",
            "epoch: 1, iteratation 2675, loss: 1.5159022808074951\n",
            "epoch: 1, iteratation 2676, loss: 1.598573088645935\n",
            "epoch: 1, iteratation 2677, loss: 1.5409371852874756\n",
            "epoch: 1, iteratation 2678, loss: 1.6181089878082275\n",
            "epoch: 1, iteratation 2679, loss: 1.5861642360687256\n",
            "epoch: 1, iteratation 2680, loss: 1.6226904392242432\n",
            "epoch: 1, iteratation 2681, loss: 1.726090669631958\n",
            "epoch: 1, iteratation 2682, loss: 1.6740121841430664\n",
            "epoch: 1, iteratation 2683, loss: 1.5807770490646362\n",
            "epoch: 1, iteratation 2684, loss: 1.5799341201782227\n",
            "epoch: 1, iteratation 2685, loss: 1.701648473739624\n",
            "epoch: 1, iteratation 2686, loss: 1.6855548620224\n",
            "epoch: 1, iteratation 2687, loss: 1.5193098783493042\n",
            "epoch: 1, iteratation 2688, loss: 1.547830581665039\n",
            "epoch: 1, iteratation 2689, loss: 1.6512153148651123\n",
            "epoch: 1, iteratation 2690, loss: 1.5592646598815918\n",
            "epoch: 1, iteratation 2691, loss: 1.5150493383407593\n",
            "epoch: 1, iteratation 2692, loss: 1.7567660808563232\n",
            "epoch: 1, iteratation 2693, loss: 1.5972617864608765\n",
            "epoch: 1, iteratation 2694, loss: 1.690761923789978\n",
            "epoch: 1, iteratation 2695, loss: 1.6972697973251343\n",
            "epoch: 1, iteratation 2696, loss: 1.4660921096801758\n",
            "epoch: 1, iteratation 2697, loss: 1.7559013366699219\n",
            "epoch: 1, iteratation 2698, loss: 1.6970213651657104\n",
            "epoch: 1, iteratation 2699, loss: 1.5572093725204468\n",
            "epoch: 1, iteratation 2700, loss: 1.5112087726593018\n",
            "epoch: 1, iteratation 2701, loss: 1.692775011062622\n",
            "epoch: 1, iteratation 2702, loss: 1.7435497045516968\n",
            "epoch: 1, iteratation 2703, loss: 1.649550199508667\n",
            "epoch: 1, iteratation 2704, loss: 1.6498701572418213\n",
            "epoch: 1, iteratation 2705, loss: 1.7000069618225098\n",
            "epoch: 1, iteratation 2706, loss: 1.4514806270599365\n",
            "epoch: 1, iteratation 2707, loss: 1.5429795980453491\n",
            "epoch: 1, iteratation 2708, loss: 1.5478482246398926\n",
            "epoch: 1, iteratation 2709, loss: 1.470966100692749\n",
            "epoch: 1, iteratation 2710, loss: 1.6030505895614624\n",
            "epoch: 1, iteratation 2711, loss: 1.422212839126587\n",
            "epoch: 1, iteratation 2712, loss: 1.4421671628952026\n",
            "epoch: 1, iteratation 2713, loss: 1.534881591796875\n",
            "epoch: 1, iteratation 2714, loss: 1.5928516387939453\n",
            "epoch: 1, iteratation 2715, loss: 1.5988763570785522\n",
            "epoch: 1, iteratation 2716, loss: 1.680211067199707\n",
            "epoch: 1, iteratation 2717, loss: 1.5443875789642334\n",
            "epoch: 1, iteratation 2718, loss: 1.5874032974243164\n",
            "epoch: 1, iteratation 2719, loss: 1.6061710119247437\n",
            "epoch: 1, iteratation 2720, loss: 1.5653762817382812\n",
            "epoch: 1, iteratation 2721, loss: 1.4743762016296387\n",
            "epoch: 1, iteratation 2722, loss: 1.4468711614608765\n",
            "epoch: 1, iteratation 2723, loss: 1.558211088180542\n",
            "epoch: 1, iteratation 2724, loss: 1.6650316715240479\n",
            "epoch: 1, iteratation 2725, loss: 1.630480170249939\n",
            "epoch: 1, iteratation 2726, loss: 1.4825782775878906\n",
            "epoch: 1, iteratation 2727, loss: 1.556738257408142\n",
            "epoch: 1, iteratation 2728, loss: 1.71536386013031\n",
            "epoch: 1, iteratation 2729, loss: 1.5220680236816406\n",
            "epoch: 1, iteratation 2730, loss: 1.6434777975082397\n",
            "epoch: 1, iteratation 2731, loss: 1.5493693351745605\n",
            "epoch: 1, iteratation 2732, loss: 1.552919626235962\n",
            "epoch: 1, iteratation 2733, loss: 1.4899991750717163\n",
            "epoch: 1, iteratation 2734, loss: 1.4829648733139038\n",
            "epoch: 1, iteratation 2735, loss: 1.4622600078582764\n",
            "epoch: 1, iteratation 2736, loss: 1.6124944686889648\n",
            "epoch: 1, iteratation 2737, loss: 1.513415813446045\n",
            "epoch: 1, iteratation 2738, loss: 1.5876784324645996\n",
            "epoch: 1, iteratation 2739, loss: 1.5413830280303955\n",
            "epoch: 1, iteratation 2740, loss: 1.491502046585083\n",
            "epoch: 1, iteratation 2741, loss: 1.5564484596252441\n",
            "epoch: 1, iteratation 2742, loss: 1.4627692699432373\n",
            "epoch: 1, iteratation 2743, loss: 1.6203629970550537\n",
            "epoch: 1, iteratation 2744, loss: 1.5004422664642334\n",
            "epoch: 1, iteratation 2745, loss: 1.583909273147583\n",
            "epoch: 1, iteratation 2746, loss: 1.7113282680511475\n",
            "epoch: 1, iteratation 2747, loss: 1.6028879880905151\n",
            "epoch: 1, iteratation 2748, loss: 1.6052205562591553\n",
            "epoch: 1, iteratation 2749, loss: 1.5815792083740234\n",
            "epoch: 1, iteratation 2750, loss: 1.5564401149749756\n",
            "epoch: 1, iteratation 2751, loss: 1.5555146932601929\n",
            "epoch: 1, iteratation 2752, loss: 1.5070304870605469\n",
            "epoch: 1, iteratation 2753, loss: 1.48029363155365\n",
            "epoch: 1, iteratation 2754, loss: 1.5427157878875732\n",
            "epoch: 1, iteratation 2755, loss: 1.4443912506103516\n",
            "epoch: 1, iteratation 2756, loss: 1.543835997581482\n",
            "epoch: 1, iteratation 2757, loss: 1.5246033668518066\n",
            "epoch: 1, iteratation 2758, loss: 1.6254291534423828\n",
            "epoch: 1, iteratation 2759, loss: 1.4059906005859375\n",
            "epoch: 1, iteratation 2760, loss: 1.538856863975525\n",
            "epoch: 1, iteratation 2761, loss: 1.778609037399292\n",
            "epoch: 1, iteratation 2762, loss: 1.723395824432373\n",
            "epoch: 1, iteratation 2763, loss: 1.4337351322174072\n",
            "epoch: 1, iteratation 2764, loss: 1.5395524501800537\n",
            "epoch: 1, iteratation 2765, loss: 1.590641736984253\n",
            "epoch: 1, iteratation 2766, loss: 1.7150801420211792\n",
            "epoch: 1, iteratation 2767, loss: 1.524040699005127\n",
            "epoch: 1, iteratation 2768, loss: 1.5412540435791016\n",
            "epoch: 1, iteratation 2769, loss: 1.4634981155395508\n",
            "epoch: 1, iteratation 2770, loss: 1.5512794256210327\n",
            "epoch: 1, iteratation 2771, loss: 1.5961203575134277\n",
            "epoch: 1, iteratation 2772, loss: 1.4723443984985352\n",
            "epoch: 1, iteratation 2773, loss: 1.504305362701416\n",
            "epoch: 1, iteratation 2774, loss: 1.4830220937728882\n",
            "epoch: 1, iteratation 2775, loss: 1.6533831357955933\n",
            "epoch: 1, iteratation 2776, loss: 1.652707576751709\n",
            "epoch: 1, iteratation 2777, loss: 1.4665801525115967\n",
            "epoch: 1, iteratation 2778, loss: 1.427159309387207\n",
            "epoch: 1, iteratation 2779, loss: 1.559665560722351\n",
            "epoch: 1, iteratation 2780, loss: 1.5196490287780762\n",
            "epoch: 1, iteratation 2781, loss: 1.766406774520874\n",
            "epoch: 1, iteratation 2782, loss: 1.560852289199829\n",
            "epoch: 1, iteratation 2783, loss: 1.4567699432373047\n",
            "epoch: 1, iteratation 2784, loss: 1.693368673324585\n",
            "epoch: 1, iteratation 2785, loss: 1.6443557739257812\n",
            "epoch: 1, iteratation 2786, loss: 1.4374908208847046\n",
            "epoch: 1, iteratation 2787, loss: 1.3804621696472168\n",
            "epoch: 1, iteratation 2788, loss: 1.580678939819336\n",
            "epoch: 1, iteratation 2789, loss: 1.7497403621673584\n",
            "epoch: 1, iteratation 2790, loss: 1.8165229558944702\n",
            "epoch: 1, iteratation 2791, loss: 1.453578233718872\n",
            "epoch: 1, iteratation 2792, loss: 1.688359022140503\n",
            "epoch: 1, iteratation 2793, loss: 1.5434154272079468\n",
            "epoch: 1, iteratation 2794, loss: 1.8685836791992188\n",
            "epoch: 1, iteratation 2795, loss: 1.5423663854599\n",
            "epoch: 1, iteratation 2796, loss: 1.6846399307250977\n",
            "epoch: 1, iteratation 2797, loss: 1.6227645874023438\n",
            "epoch: 1, iteratation 2798, loss: 1.7455934286117554\n",
            "epoch: 1, iteratation 2799, loss: 1.538260817527771\n",
            "epoch: 1, iteratation 2800, loss: 1.5604276657104492\n",
            "epoch: 1, iteratation 2801, loss: 1.4321669340133667\n",
            "epoch: 1, iteratation 2802, loss: 1.658822774887085\n",
            "epoch: 1, iteratation 2803, loss: 1.6748199462890625\n",
            "epoch: 1, iteratation 2804, loss: 1.6192902326583862\n",
            "epoch: 1, iteratation 2805, loss: 1.5352427959442139\n",
            "epoch: 1, iteratation 2806, loss: 1.6174993515014648\n",
            "epoch: 1, iteratation 2807, loss: 1.5737403631210327\n",
            "epoch: 1, iteratation 2808, loss: 1.5122827291488647\n",
            "epoch: 1, iteratation 2809, loss: 1.4885082244873047\n",
            "epoch: 1, iteratation 2810, loss: 1.5443800687789917\n",
            "epoch: 1, iteratation 2811, loss: 1.6751474142074585\n",
            "epoch: 1, iteratation 2812, loss: 1.616333246231079\n",
            "epoch: 1, iteratation 2813, loss: 1.4981249570846558\n",
            "epoch: 1, iteratation 2814, loss: 1.5279626846313477\n",
            "epoch: 1, iteratation 2815, loss: 1.4243144989013672\n",
            "epoch: 1, iteratation 2816, loss: 1.608605146408081\n",
            "epoch: 1, iteratation 2817, loss: 1.5223751068115234\n",
            "epoch: 1, iteratation 2818, loss: 1.5954251289367676\n",
            "epoch: 1, iteratation 2819, loss: 1.5577834844589233\n",
            "epoch: 1, iteratation 2820, loss: 1.5167406797409058\n",
            "epoch: 1, iteratation 2821, loss: 1.5210447311401367\n",
            "epoch: 1, iteratation 2822, loss: 1.5351014137268066\n",
            "epoch: 1, iteratation 2823, loss: 1.4963922500610352\n",
            "epoch: 1, iteratation 2824, loss: 1.7247838973999023\n",
            "epoch: 1, iteratation 2825, loss: 1.7075283527374268\n",
            "epoch: 1, iteratation 2826, loss: 1.5851795673370361\n",
            "epoch: 1, iteratation 2827, loss: 1.5152124166488647\n",
            "epoch: 1, iteratation 2828, loss: 1.5048456192016602\n",
            "epoch: 1, iteratation 2829, loss: 1.536190390586853\n",
            "epoch: 1, iteratation 2830, loss: 1.550992727279663\n",
            "epoch: 1, iteratation 2831, loss: 1.8536972999572754\n",
            "epoch: 1, iteratation 2832, loss: 1.5025317668914795\n",
            "epoch: 1, iteratation 2833, loss: 1.5446375608444214\n",
            "epoch: 1, iteratation 2834, loss: 1.650705099105835\n",
            "epoch: 1, iteratation 2835, loss: 1.6711444854736328\n",
            "epoch: 1, iteratation 2836, loss: 1.4736708402633667\n",
            "epoch: 1, iteratation 2837, loss: 1.571632742881775\n",
            "epoch: 1, iteratation 2838, loss: 1.7386913299560547\n",
            "epoch: 1, iteratation 2839, loss: 1.5921519994735718\n",
            "epoch: 1, iteratation 2840, loss: 1.4708926677703857\n",
            "epoch: 1, iteratation 2841, loss: 1.4816526174545288\n",
            "epoch: 1, iteratation 2842, loss: 1.527301549911499\n",
            "epoch: 1, iteratation 2843, loss: 1.6740443706512451\n",
            "epoch: 1, iteratation 2844, loss: 1.404134750366211\n",
            "epoch: 1, iteratation 2845, loss: 1.5479592084884644\n",
            "epoch: 1, iteratation 2846, loss: 1.5558183193206787\n",
            "epoch: 1, iteratation 2847, loss: 1.472928762435913\n",
            "epoch: 1, iteratation 2848, loss: 1.5394484996795654\n",
            "epoch: 1, iteratation 2849, loss: 1.5617116689682007\n",
            "epoch: 1, iteratation 2850, loss: 1.4315640926361084\n",
            "epoch: 1, iteratation 2851, loss: 1.3408206701278687\n",
            "epoch: 1, iteratation 2852, loss: 1.4108575582504272\n",
            "epoch: 1, iteratation 2853, loss: 1.622964859008789\n",
            "epoch: 1, iteratation 2854, loss: 1.8336408138275146\n",
            "epoch: 1, iteratation 2855, loss: 1.472537875175476\n",
            "epoch: 1, iteratation 2856, loss: 1.389979362487793\n",
            "epoch: 1, iteratation 2857, loss: 1.5744870901107788\n",
            "epoch: 1, iteratation 2858, loss: 1.6361114978790283\n",
            "epoch: 1, iteratation 2859, loss: 1.38624906539917\n",
            "epoch: 1, iteratation 2860, loss: 1.5685571432113647\n",
            "epoch: 1, iteratation 2861, loss: 1.5469446182250977\n",
            "epoch: 1, iteratation 2862, loss: 1.4736955165863037\n",
            "epoch: 1, iteratation 2863, loss: 1.6153593063354492\n",
            "epoch: 1, iteratation 2864, loss: 1.496665358543396\n",
            "epoch: 1, iteratation 2865, loss: 1.589084506034851\n",
            "epoch: 1, iteratation 2866, loss: 1.5416487455368042\n",
            "epoch: 1, iteratation 2867, loss: 1.5696786642074585\n",
            "epoch: 1, iteratation 2868, loss: 1.504197597503662\n",
            "epoch: 1, iteratation 2869, loss: 1.6083314418792725\n",
            "epoch: 1, iteratation 2870, loss: 1.3573246002197266\n",
            "epoch: 1, iteratation 2871, loss: 1.3927524089813232\n",
            "epoch: 1, iteratation 2872, loss: 1.5914802551269531\n",
            "epoch: 1, iteratation 2873, loss: 1.4568555355072021\n",
            "epoch: 1, iteratation 2874, loss: 1.5424375534057617\n",
            "epoch: 1, iteratation 2875, loss: 1.4503892660140991\n",
            "epoch: 1, iteratation 2876, loss: 1.5209407806396484\n",
            "epoch: 1, iteratation 2877, loss: 1.543578863143921\n",
            "epoch: 1, iteratation 2878, loss: 1.6459369659423828\n",
            "epoch: 1, iteratation 2879, loss: 1.4675538539886475\n",
            "epoch: 1, iteratation 2880, loss: 1.5613477230072021\n",
            "epoch: 1, iteratation 2881, loss: 1.7444175481796265\n",
            "epoch: 1, iteratation 2882, loss: 1.706311583518982\n",
            "epoch: 1, iteratation 2883, loss: 1.5452067852020264\n",
            "epoch: 1, iteratation 2884, loss: 1.5015987157821655\n",
            "epoch: 1, iteratation 2885, loss: 1.6035709381103516\n",
            "epoch: 1, iteratation 2886, loss: 1.5057204961776733\n",
            "epoch: 1, iteratation 2887, loss: 1.6421312093734741\n",
            "epoch: 1, iteratation 2888, loss: 1.4552596807479858\n",
            "epoch: 1, iteratation 2889, loss: 1.3694159984588623\n",
            "epoch: 1, iteratation 2890, loss: 1.472687005996704\n",
            "epoch: 1, iteratation 2891, loss: 1.3565032482147217\n",
            "epoch: 1, iteratation 2892, loss: 1.7328641414642334\n",
            "epoch: 1, iteratation 2893, loss: 1.5725181102752686\n",
            "epoch: 1, iteratation 2894, loss: 1.4241244792938232\n",
            "epoch: 1, iteratation 2895, loss: 1.3916534185409546\n",
            "epoch: 1, iteratation 2896, loss: 1.4564107656478882\n",
            "epoch: 1, iteratation 2897, loss: 1.4529318809509277\n",
            "epoch: 1, iteratation 2898, loss: 1.5901774168014526\n",
            "epoch: 1, iteratation 2899, loss: 1.5818068981170654\n",
            "epoch: 1, iteratation 2900, loss: 1.4126965999603271\n",
            "epoch: 1, iteratation 2901, loss: 1.5620527267456055\n",
            "epoch: 1, iteratation 2902, loss: 1.5724046230316162\n",
            "epoch: 1, iteratation 2903, loss: 1.7440050840377808\n",
            "epoch: 1, iteratation 2904, loss: 1.6594350337982178\n",
            "epoch: 1, iteratation 2905, loss: 1.4023914337158203\n",
            "epoch: 1, iteratation 2906, loss: 1.4419331550598145\n",
            "epoch: 1, iteratation 2907, loss: 1.5174096822738647\n",
            "epoch: 1, iteratation 2908, loss: 1.4991534948349\n",
            "epoch: 1, iteratation 2909, loss: 1.4722546339035034\n",
            "epoch: 1, iteratation 2910, loss: 1.5349029302597046\n",
            "epoch: 1, iteratation 2911, loss: 1.711545705795288\n",
            "epoch: 1, iteratation 2912, loss: 1.5247607231140137\n",
            "epoch: 1, iteratation 2913, loss: 1.4111413955688477\n",
            "epoch: 1, iteratation 2914, loss: 1.5079889297485352\n",
            "epoch: 1, iteratation 2915, loss: 1.433612585067749\n",
            "epoch: 1, iteratation 2916, loss: 1.533658742904663\n",
            "epoch: 1, iteratation 2917, loss: 1.6597732305526733\n",
            "epoch: 1, iteratation 2918, loss: 1.5113424062728882\n",
            "epoch: 1, iteratation 2919, loss: 1.4517695903778076\n",
            "epoch: 1, iteratation 2920, loss: 1.5494908094406128\n",
            "epoch: 1, iteratation 2921, loss: 1.3790853023529053\n",
            "epoch: 1, iteratation 2922, loss: 1.5024398565292358\n",
            "epoch: 1, iteratation 2923, loss: 1.3552029132843018\n",
            "epoch: 1, iteratation 2924, loss: 1.5201581716537476\n",
            "epoch: 1, iteratation 2925, loss: 1.6187586784362793\n",
            "epoch: 1, iteratation 2926, loss: 1.645883321762085\n",
            "epoch: 1, iteratation 2927, loss: 1.437619686126709\n",
            "epoch: 1, iteratation 2928, loss: 1.4890167713165283\n",
            "epoch: 1, iteratation 2929, loss: 1.5768598318099976\n",
            "epoch: 1, iteratation 2930, loss: 1.5554288625717163\n",
            "epoch: 1, iteratation 2931, loss: 1.552000880241394\n",
            "epoch: 1, iteratation 2932, loss: 1.5876712799072266\n",
            "epoch: 1, iteratation 2933, loss: 1.576115608215332\n",
            "epoch: 1, iteratation 2934, loss: 1.4482768774032593\n",
            "epoch: 1, iteratation 2935, loss: 1.5316643714904785\n",
            "epoch: 1, iteratation 2936, loss: 1.5395959615707397\n",
            "epoch: 1, iteratation 2937, loss: 1.5971940755844116\n",
            "epoch: 1, iteratation 2938, loss: 1.371272087097168\n",
            "epoch: 1, iteratation 2939, loss: 1.4518589973449707\n",
            "epoch: 1, iteratation 2940, loss: 1.6232514381408691\n",
            "epoch: 1, iteratation 2941, loss: 1.4771091938018799\n",
            "epoch: 1, iteratation 2942, loss: 1.6215429306030273\n",
            "epoch: 1, iteratation 2943, loss: 1.6105470657348633\n",
            "epoch: 1, iteratation 2944, loss: 1.6312675476074219\n",
            "epoch: 1, iteratation 2945, loss: 1.407787561416626\n",
            "epoch: 1, iteratation 2946, loss: 1.6912660598754883\n",
            "epoch: 1, iteratation 2947, loss: 1.527716040611267\n",
            "epoch: 1, iteratation 2948, loss: 1.4246773719787598\n",
            "epoch: 1, iteratation 2949, loss: 1.6229743957519531\n",
            "epoch: 1, iteratation 2950, loss: 1.6777032613754272\n",
            "epoch: 1, iteratation 2951, loss: 1.5370591878890991\n",
            "epoch: 1, iteratation 2952, loss: 1.5258080959320068\n",
            "epoch: 1, iteratation 2953, loss: 1.51175856590271\n",
            "epoch: 1, iteratation 2954, loss: 1.4592182636260986\n",
            "epoch: 1, iteratation 2955, loss: 1.5428872108459473\n",
            "epoch: 1, iteratation 2956, loss: 1.5285289287567139\n",
            "epoch: 1, iteratation 2957, loss: 1.6241345405578613\n",
            "epoch: 1, iteratation 2958, loss: 1.6732826232910156\n",
            "epoch: 1, iteratation 2959, loss: 1.3917365074157715\n",
            "epoch: 1, iteratation 2960, loss: 1.6567811965942383\n",
            "epoch: 1, iteratation 2961, loss: 1.4962995052337646\n",
            "epoch: 1, iteratation 2962, loss: 1.4502557516098022\n",
            "epoch: 1, iteratation 2963, loss: 1.5042626857757568\n",
            "epoch: 1, iteratation 2964, loss: 1.5701768398284912\n",
            "epoch: 1, iteratation 2965, loss: 1.6489871740341187\n",
            "epoch: 1, iteratation 2966, loss: 1.668672800064087\n",
            "epoch: 1, iteratation 2967, loss: 1.607055425643921\n",
            "epoch: 1, iteratation 2968, loss: 1.4885244369506836\n",
            "epoch: 1, iteratation 2969, loss: 1.581396460533142\n",
            "epoch: 1, iteratation 2970, loss: 1.6864957809448242\n",
            "epoch: 1, iteratation 2971, loss: 1.5842103958129883\n",
            "epoch: 1, iteratation 2972, loss: 1.4313075542449951\n",
            "epoch: 1, iteratation 2973, loss: 1.4920852184295654\n",
            "epoch: 1, iteratation 2974, loss: 1.5634267330169678\n",
            "epoch: 1, iteratation 2975, loss: 1.6503366231918335\n",
            "epoch: 1, iteratation 2976, loss: 1.4350707530975342\n",
            "epoch: 1, iteratation 2977, loss: 1.5058796405792236\n",
            "epoch: 1, iteratation 2978, loss: 1.577294111251831\n",
            "epoch: 1, iteratation 2979, loss: 1.3625047206878662\n",
            "epoch: 1, iteratation 2980, loss: 1.4664199352264404\n",
            "epoch: 1, iteratation 2981, loss: 1.5486621856689453\n",
            "epoch: 1, iteratation 2982, loss: 1.4819819927215576\n",
            "epoch: 1, iteratation 2983, loss: 1.5496251583099365\n",
            "epoch: 1, iteratation 2984, loss: 1.516815185546875\n",
            "epoch: 1, iteratation 2985, loss: 1.3759149312973022\n",
            "epoch: 1, iteratation 2986, loss: 1.5119245052337646\n",
            "epoch: 1, iteratation 2987, loss: 1.5960230827331543\n",
            "epoch: 1, iteratation 2988, loss: 1.4698216915130615\n",
            "epoch: 1, iteratation 2989, loss: 1.676836371421814\n",
            "epoch: 1, iteratation 2990, loss: 1.377779483795166\n",
            "epoch: 1, iteratation 2991, loss: 1.3986523151397705\n",
            "epoch: 1, iteratation 2992, loss: 1.3106179237365723\n",
            "epoch: 1, iteratation 2993, loss: 1.6129395961761475\n",
            "epoch: 1, iteratation 2994, loss: 1.5030492544174194\n",
            "epoch: 1, iteratation 2995, loss: 1.4965918064117432\n",
            "epoch: 1, iteratation 2996, loss: 1.3127273321151733\n",
            "epoch: 1, iteratation 2997, loss: 1.783511996269226\n",
            "epoch: 1, iteratation 2998, loss: 1.404542326927185\n",
            "epoch: 1, iteratation 2999, loss: 1.4125640392303467\n",
            "epoch: 1, iteratation 3000, loss: 1.4670979976654053\n",
            "epoch: 1, iteratation 3001, loss: 1.4209197759628296\n",
            "epoch: 1, iteratation 3002, loss: 1.4759410619735718\n",
            "epoch: 1, iteratation 3003, loss: 1.4330449104309082\n",
            "epoch: 1, iteratation 3004, loss: 1.5384597778320312\n",
            "epoch: 1, iteratation 3005, loss: 1.4786550998687744\n",
            "epoch: 1, iteratation 3006, loss: 1.3143731355667114\n",
            "epoch: 1, iteratation 3007, loss: 1.4509077072143555\n",
            "epoch: 1, iteratation 3008, loss: 1.5336065292358398\n",
            "epoch: 1, iteratation 3009, loss: 1.5750749111175537\n",
            "epoch: 1, iteratation 3010, loss: 1.6274017095565796\n",
            "epoch: 1, iteratation 3011, loss: 1.4137166738510132\n",
            "epoch: 1, iteratation 3012, loss: 1.3456246852874756\n",
            "epoch: 1, iteratation 3013, loss: 1.3427280187606812\n",
            "epoch: 1, iteratation 3014, loss: 1.5274322032928467\n",
            "epoch: 1, iteratation 3015, loss: 1.3447761535644531\n",
            "epoch: 1, iteratation 3016, loss: 1.3896210193634033\n",
            "epoch: 1, iteratation 3017, loss: 1.3981752395629883\n",
            "epoch: 1, iteratation 3018, loss: 1.5037387609481812\n",
            "epoch: 1, iteratation 3019, loss: 1.504136085510254\n",
            "epoch: 1, iteratation 3020, loss: 1.3501628637313843\n",
            "epoch: 1, iteratation 3021, loss: 1.4387595653533936\n",
            "epoch: 1, iteratation 3022, loss: 1.515360713005066\n",
            "epoch: 1, iteratation 3023, loss: 1.526050329208374\n",
            "epoch: 1, iteratation 3024, loss: 1.3488634824752808\n",
            "epoch: 1, iteratation 3025, loss: 1.4130144119262695\n",
            "epoch: 1, iteratation 3026, loss: 1.4220216274261475\n",
            "epoch: 1, iteratation 3027, loss: 1.6503324508666992\n",
            "epoch: 1, iteratation 3028, loss: 1.4449909925460815\n",
            "epoch: 1, iteratation 3029, loss: 1.3863601684570312\n",
            "epoch: 1, iteratation 3030, loss: 1.3445676565170288\n",
            "epoch: 1, iteratation 3031, loss: 1.5702273845672607\n",
            "epoch: 1, iteratation 3032, loss: 1.4543030261993408\n",
            "epoch: 1, iteratation 3033, loss: 1.499929666519165\n",
            "epoch: 1, iteratation 3034, loss: 1.5220694541931152\n",
            "epoch: 1, iteratation 3035, loss: 1.550771713256836\n",
            "epoch: 1, iteratation 3036, loss: 1.4204061031341553\n",
            "epoch: 1, iteratation 3037, loss: 1.369720220565796\n",
            "epoch: 1, iteratation 3038, loss: 1.3296246528625488\n",
            "epoch: 1, iteratation 3039, loss: 1.4970897436141968\n",
            "epoch: 1, iteratation 3040, loss: 1.4680030345916748\n",
            "epoch: 1, iteratation 3041, loss: 1.4080960750579834\n",
            "epoch: 1, iteratation 3042, loss: 1.343437910079956\n",
            "epoch: 1, iteratation 3043, loss: 1.3638298511505127\n",
            "epoch: 1, iteratation 3044, loss: 1.5481771230697632\n",
            "epoch: 1, iteratation 3045, loss: 1.492323637008667\n",
            "epoch: 1, iteratation 3046, loss: 1.3667047023773193\n",
            "epoch: 1, iteratation 3047, loss: 1.4573930501937866\n",
            "epoch: 1, iteratation 3048, loss: 1.362727165222168\n",
            "epoch: 1, iteratation 3049, loss: 1.6710751056671143\n",
            "epoch: 1, iteratation 3050, loss: 1.5912466049194336\n",
            "epoch: 1, iteratation 3051, loss: 1.4313299655914307\n",
            "epoch: 1, iteratation 3052, loss: 1.4614181518554688\n",
            "epoch: 1, iteratation 3053, loss: 1.5653102397918701\n",
            "epoch: 1, iteratation 3054, loss: 1.5309679508209229\n",
            "epoch: 1, iteratation 3055, loss: 1.40873122215271\n",
            "epoch: 1, iteratation 3056, loss: 1.4737310409545898\n",
            "epoch: 1, iteratation 3057, loss: 1.4246773719787598\n",
            "epoch: 1, iteratation 3058, loss: 1.4961521625518799\n",
            "epoch: 1, iteratation 3059, loss: 1.4496406316757202\n",
            "epoch: 1, iteratation 3060, loss: 1.43174147605896\n",
            "epoch: 1, iteratation 3061, loss: 1.402048110961914\n",
            "epoch: 1, iteratation 3062, loss: 1.454321265220642\n",
            "epoch: 1, iteratation 3063, loss: 1.4516233205795288\n",
            "epoch: 1, iteratation 3064, loss: 1.444145679473877\n",
            "epoch: 1, iteratation 3065, loss: 1.379085898399353\n",
            "epoch: 1, iteratation 3066, loss: 1.5108445882797241\n",
            "epoch: 1, iteratation 3067, loss: 1.537667989730835\n",
            "epoch: 1, iteratation 3068, loss: 1.4471147060394287\n",
            "epoch: 1, iteratation 3069, loss: 1.4735840559005737\n",
            "epoch: 1, iteratation 3070, loss: 1.434410810470581\n",
            "epoch: 1, iteratation 3071, loss: 1.3415144681930542\n",
            "epoch: 1, iteratation 3072, loss: 1.4746555089950562\n",
            "epoch: 1, iteratation 3073, loss: 1.6951215267181396\n",
            "epoch: 1, iteratation 3074, loss: 1.5539569854736328\n",
            "epoch: 1, iteratation 3075, loss: 1.3937091827392578\n",
            "epoch: 1, iteratation 3076, loss: 1.5696309804916382\n",
            "epoch: 1, iteratation 3077, loss: 1.3681715726852417\n",
            "epoch: 1, iteratation 3078, loss: 1.578901767730713\n",
            "epoch: 1, iteratation 3079, loss: 1.3540252447128296\n",
            "epoch: 1, iteratation 3080, loss: 1.4503321647644043\n",
            "epoch: 1, iteratation 3081, loss: 1.5309150218963623\n",
            "epoch: 1, iteratation 3082, loss: 1.3966201543807983\n",
            "epoch: 1, iteratation 3083, loss: 1.46161687374115\n",
            "epoch: 1, iteratation 3084, loss: 1.3919105529785156\n",
            "epoch: 1, iteratation 3085, loss: 1.3729195594787598\n",
            "epoch: 1, iteratation 3086, loss: 1.4362385272979736\n",
            "epoch: 1, iteratation 3087, loss: 1.356742262840271\n",
            "epoch: 1, iteratation 3088, loss: 1.4056367874145508\n",
            "epoch: 1, iteratation 3089, loss: 1.4679934978485107\n",
            "epoch: 1, iteratation 3090, loss: 1.3923356533050537\n",
            "epoch: 1, iteratation 3091, loss: 1.4213354587554932\n",
            "epoch: 1, iteratation 3092, loss: 1.3996081352233887\n",
            "epoch: 1, iteratation 3093, loss: 1.3495352268218994\n",
            "epoch: 1, iteratation 3094, loss: 1.4538630247116089\n",
            "epoch: 1, iteratation 3095, loss: 1.4269959926605225\n",
            "epoch: 1, iteratation 3096, loss: 1.4778884649276733\n",
            "epoch: 1, iteratation 3097, loss: 1.3850988149642944\n",
            "epoch: 1, iteratation 3098, loss: 1.4725098609924316\n",
            "epoch: 1, iteratation 3099, loss: 1.6243951320648193\n",
            "epoch: 1, iteratation 3100, loss: 1.4931062459945679\n",
            "epoch: 1, iteratation 3101, loss: 1.5206780433654785\n",
            "epoch: 1, iteratation 3102, loss: 1.4216153621673584\n",
            "epoch: 1, iteratation 3103, loss: 1.4547199010849\n",
            "epoch: 1, iteratation 3104, loss: 1.5692819356918335\n",
            "epoch: 1, iteratation 3105, loss: 1.4755618572235107\n",
            "epoch: 1, iteratation 3106, loss: 1.5990018844604492\n",
            "epoch: 1, iteratation 3107, loss: 1.4962527751922607\n",
            "epoch: 1, iteratation 3108, loss: 1.3478749990463257\n",
            "epoch: 1, iteratation 3109, loss: 1.3920955657958984\n",
            "epoch: 1, iteratation 3110, loss: 1.5801379680633545\n",
            "epoch: 1, iteratation 3111, loss: 1.4701852798461914\n",
            "epoch: 1, iteratation 3112, loss: 1.4681795835494995\n",
            "epoch: 1, iteratation 3113, loss: 1.6126580238342285\n",
            "epoch: 1, iteratation 3114, loss: 1.3732385635375977\n",
            "epoch: 1, iteratation 3115, loss: 1.4612905979156494\n",
            "epoch: 1, iteratation 3116, loss: 1.5327608585357666\n",
            "epoch: 1, iteratation 3117, loss: 1.3990278244018555\n",
            "epoch: 1, iteratation 3118, loss: 1.3459861278533936\n",
            "epoch: 1, iteratation 3119, loss: 1.46186101436615\n",
            "epoch: 1, iteratation 3120, loss: 1.537459373474121\n",
            "epoch: 1, iteratation 3121, loss: 1.4235212802886963\n",
            "epoch: 1, iteratation 3122, loss: 1.4319032430648804\n",
            "epoch: 1, iteratation 3123, loss: 1.413485050201416\n",
            "epoch: 1, iteratation 3124, loss: 1.4731061458587646\n",
            "epoch: 1, iteratation 3125, loss: 1.681789755821228\n",
            "epoch: 1, iteratation 3126, loss: 1.6327497959136963\n",
            "epoch: 1, iteratation 3127, loss: 1.4805635213851929\n",
            "epoch: 1, iteratation 3128, loss: 1.4250491857528687\n",
            "epoch: 1, iteratation 3129, loss: 1.3542201519012451\n",
            "epoch: 1, iteratation 3130, loss: 1.504225730895996\n",
            "epoch: 1, iteratation 3131, loss: 1.7081631422042847\n",
            "epoch: 1, iteratation 3132, loss: 1.479852557182312\n",
            "epoch: 1, iteratation 3133, loss: 1.5908048152923584\n",
            "epoch: 1, iteratation 3134, loss: 1.3481191396713257\n",
            "epoch: 1, iteratation 3135, loss: 1.6542768478393555\n",
            "epoch: 1, iteratation 3136, loss: 1.4276065826416016\n",
            "epoch: 1, iteratation 3137, loss: 1.3142714500427246\n",
            "epoch: 1, iteratation 3138, loss: 1.4570684432983398\n",
            "epoch: 1, iteratation 3139, loss: 1.3965907096862793\n",
            "epoch: 1, iteratation 3140, loss: 1.5937421321868896\n",
            "epoch: 1, iteratation 3141, loss: 1.6718194484710693\n",
            "epoch: 1, iteratation 3142, loss: 1.444661021232605\n",
            "epoch: 1, iteratation 3143, loss: 1.4173787832260132\n",
            "epoch: 1, iteratation 3144, loss: 1.4370033740997314\n",
            "epoch: 1, iteratation 3145, loss: 1.5232661962509155\n",
            "epoch: 1, iteratation 3146, loss: 1.5556704998016357\n",
            "epoch: 1, iteratation 3147, loss: 1.6116046905517578\n",
            "epoch: 1, iteratation 3148, loss: 1.5395854711532593\n",
            "epoch: 1, iteratation 3149, loss: 1.547823190689087\n",
            "epoch: 1, iteratation 3150, loss: 1.5418671369552612\n",
            "epoch: 1, iteratation 3151, loss: 1.4063905477523804\n",
            "epoch: 1, iteratation 3152, loss: 1.4349216222763062\n",
            "epoch: 1, iteratation 3153, loss: 1.4142541885375977\n",
            "epoch: 1, iteratation 3154, loss: 1.5276734828948975\n",
            "epoch: 1, iteratation 3155, loss: 1.5416967868804932\n",
            "epoch: 1, iteratation 3156, loss: 1.3261692523956299\n",
            "epoch: 1, iteratation 3157, loss: 1.401617407798767\n",
            "epoch: 1, iteratation 3158, loss: 1.4274605512619019\n",
            "epoch: 1, iteratation 3159, loss: 1.5073297023773193\n",
            "epoch: 1, iteratation 3160, loss: 1.3665103912353516\n",
            "epoch: 1, iteratation 3161, loss: 1.4615777730941772\n",
            "epoch: 1, iteratation 3162, loss: 1.330595850944519\n",
            "epoch: 1, iteratation 3163, loss: 1.3788344860076904\n",
            "epoch: 1, iteratation 3164, loss: 1.3704228401184082\n",
            "epoch: 1, iteratation 3165, loss: 1.3996332883834839\n",
            "epoch: 1, iteratation 3166, loss: 1.5299623012542725\n",
            "epoch: 1, iteratation 3167, loss: 1.3988460302352905\n",
            "epoch: 1, iteratation 3168, loss: 1.4453010559082031\n",
            "epoch: 1, iteratation 3169, loss: 1.5249354839324951\n",
            "epoch: 1, iteratation 3170, loss: 1.3876899480819702\n",
            "epoch: 1, iteratation 3171, loss: 1.282499074935913\n",
            "epoch: 1, iteratation 3172, loss: 1.437056541442871\n",
            "epoch: 1, iteratation 3173, loss: 1.3494136333465576\n",
            "epoch: 1, iteratation 3174, loss: 1.3731683492660522\n",
            "epoch: 1, iteratation 3175, loss: 1.663832664489746\n",
            "epoch: 1, iteratation 3176, loss: 1.4398492574691772\n",
            "epoch: 1, iteratation 3177, loss: 1.3256967067718506\n",
            "epoch: 1, iteratation 3178, loss: 1.271296501159668\n",
            "epoch: 1, iteratation 3179, loss: 1.5092419385910034\n",
            "epoch: 1, iteratation 3180, loss: 1.5539405345916748\n",
            "epoch: 1, iteratation 3181, loss: 1.4029197692871094\n",
            "epoch: 1, iteratation 3182, loss: 1.4756572246551514\n",
            "epoch: 1, iteratation 3183, loss: 1.3855528831481934\n",
            "epoch: 1, iteratation 3184, loss: 1.6158474683761597\n",
            "epoch: 1, iteratation 3185, loss: 1.5447912216186523\n",
            "epoch: 1, iteratation 3186, loss: 1.6370818614959717\n",
            "epoch: 1, iteratation 3187, loss: 1.3884700536727905\n",
            "epoch: 1, iteratation 3188, loss: 1.5238497257232666\n",
            "epoch: 1, iteratation 3189, loss: 1.522836685180664\n",
            "epoch: 1, iteratation 3190, loss: 1.4743913412094116\n",
            "epoch: 1, iteratation 3191, loss: 1.4784343242645264\n",
            "epoch: 1, iteratation 3192, loss: 1.4269568920135498\n",
            "epoch: 1, iteratation 3193, loss: 1.5359435081481934\n",
            "epoch: 1, iteratation 3194, loss: 1.7475141286849976\n",
            "epoch: 1, iteratation 3195, loss: 1.5893058776855469\n",
            "epoch: 1, iteratation 3196, loss: 1.5763652324676514\n",
            "epoch: 1, iteratation 3197, loss: 1.4925082921981812\n",
            "epoch: 1, iteratation 3198, loss: 1.467904806137085\n",
            "epoch: 1, iteratation 3199, loss: 1.4362907409667969\n",
            "epoch: 1, iteratation 3200, loss: 1.49906587600708\n",
            "epoch: 1, iteratation 3201, loss: 1.4478319883346558\n",
            "epoch: 1, iteratation 3202, loss: 1.5528548955917358\n",
            "epoch: 1, iteratation 3203, loss: 1.4317859411239624\n",
            "epoch: 1, iteratation 3204, loss: 1.4862360954284668\n",
            "epoch: 1, iteratation 3205, loss: 1.5352600812911987\n",
            "epoch: 1, iteratation 3206, loss: 1.4398694038391113\n",
            "epoch: 1, iteratation 3207, loss: 1.4378166198730469\n",
            "epoch: 1, iteratation 3208, loss: 1.4375274181365967\n",
            "epoch: 1, iteratation 3209, loss: 1.4582147598266602\n",
            "epoch: 1, iteratation 3210, loss: 1.3577821254730225\n",
            "epoch: 1, iteratation 3211, loss: 1.4989919662475586\n",
            "epoch: 1, iteratation 3212, loss: 1.3792436122894287\n",
            "epoch: 1, iteratation 3213, loss: 1.36074960231781\n",
            "epoch: 1, iteratation 3214, loss: 1.2725770473480225\n",
            "epoch: 1, iteratation 3215, loss: 1.2693095207214355\n",
            "epoch: 1, iteratation 3216, loss: 1.4048004150390625\n",
            "epoch: 1, iteratation 3217, loss: 1.6076633930206299\n",
            "epoch: 1, iteratation 3218, loss: 1.6707080602645874\n",
            "epoch: 1, iteratation 3219, loss: 1.583505630493164\n",
            "epoch: 1, iteratation 3220, loss: 1.733764410018921\n",
            "epoch: 1, iteratation 3221, loss: 1.604540228843689\n",
            "epoch: 1, iteratation 3222, loss: 1.3810393810272217\n",
            "epoch: 1, iteratation 3223, loss: 1.3524415493011475\n",
            "epoch: 1, iteratation 3224, loss: 1.6969280242919922\n",
            "epoch: 1, iteratation 3225, loss: 1.7370493412017822\n",
            "epoch: 1, iteratation 3226, loss: 1.5246493816375732\n",
            "epoch: 1, iteratation 3227, loss: 1.6080869436264038\n",
            "epoch: 1, iteratation 3228, loss: 1.6895098686218262\n",
            "epoch: 1, iteratation 3229, loss: 1.700228214263916\n",
            "epoch: 1, iteratation 3230, loss: 1.8051223754882812\n",
            "epoch: 1, iteratation 3231, loss: 1.4376447200775146\n",
            "epoch: 1, iteratation 3232, loss: 1.5019056797027588\n",
            "epoch: 1, iteratation 3233, loss: 1.4151967763900757\n",
            "epoch: 1, iteratation 3234, loss: 1.348874568939209\n",
            "epoch: 1, iteratation 3235, loss: 1.543871283531189\n",
            "epoch: 1, iteratation 3236, loss: 1.7579444646835327\n",
            "epoch: 1, iteratation 3237, loss: 1.3921903371810913\n",
            "epoch: 1, iteratation 3238, loss: 1.3154572248458862\n",
            "epoch: 1, iteratation 3239, loss: 1.4270174503326416\n",
            "epoch: 1, iteratation 3240, loss: 1.4042795896530151\n",
            "epoch: 1, iteratation 3241, loss: 1.503098487854004\n",
            "epoch: 1, iteratation 3242, loss: 1.3441917896270752\n",
            "epoch: 1, iteratation 3243, loss: 1.296802043914795\n",
            "epoch: 1, iteratation 3244, loss: 1.4537246227264404\n",
            "epoch: 1, iteratation 3245, loss: 1.4921754598617554\n",
            "epoch: 1, iteratation 3246, loss: 1.303460955619812\n",
            "epoch: 1, iteratation 3247, loss: 1.3074841499328613\n",
            "epoch: 1, iteratation 3248, loss: 1.5428600311279297\n",
            "epoch: 1, iteratation 3249, loss: 1.283297061920166\n",
            "epoch: 1, iteratation 3250, loss: 1.2823396921157837\n",
            "epoch: 1, iteratation 3251, loss: 1.394017219543457\n",
            "epoch: 1, iteratation 3252, loss: 1.6438279151916504\n",
            "epoch: 1, iteratation 3253, loss: 1.583636999130249\n",
            "epoch: 1, iteratation 3254, loss: 1.4091805219650269\n",
            "epoch: 1, iteratation 3255, loss: 1.2752225399017334\n",
            "epoch: 1, iteratation 3256, loss: 1.3871287107467651\n",
            "epoch: 1, iteratation 3257, loss: 1.3260457515716553\n",
            "epoch: 1, iteratation 3258, loss: 1.5516414642333984\n",
            "epoch: 1, iteratation 3259, loss: 1.438798427581787\n",
            "epoch: 1, iteratation 3260, loss: 1.4687994718551636\n",
            "epoch: 1, iteratation 3261, loss: 1.4641469717025757\n",
            "epoch: 1, iteratation 3262, loss: 1.411578893661499\n",
            "epoch: 1, iteratation 3263, loss: 1.2944220304489136\n",
            "epoch: 1, iteratation 3264, loss: 1.3658781051635742\n",
            "epoch: 1, iteratation 3265, loss: 1.3699735403060913\n",
            "epoch: 1, iteratation 3266, loss: 1.417554259300232\n",
            "epoch: 1, iteratation 3267, loss: 1.4902057647705078\n",
            "epoch: 1, iteratation 3268, loss: 1.4984171390533447\n",
            "epoch: 1, iteratation 3269, loss: 1.4768937826156616\n",
            "epoch: 1, iteratation 3270, loss: 1.3191683292388916\n",
            "epoch: 1, iteratation 3271, loss: 1.3838505744934082\n",
            "epoch: 1, iteratation 3272, loss: 1.2871127128601074\n",
            "epoch: 1, iteratation 3273, loss: 1.305124044418335\n",
            "epoch: 1, iteratation 3274, loss: 1.548191785812378\n",
            "epoch: 1, iteratation 3275, loss: 1.5063838958740234\n",
            "epoch: 1, iteratation 3276, loss: 1.4046883583068848\n",
            "epoch: 1, iteratation 3277, loss: 1.5437850952148438\n",
            "epoch: 1, iteratation 3278, loss: 1.450434684753418\n",
            "epoch: 1, iteratation 3279, loss: 1.4036964178085327\n",
            "epoch: 1, iteratation 3280, loss: 1.4960107803344727\n",
            "epoch: 1, iteratation 3281, loss: 1.6367299556732178\n",
            "epoch: 1, iteratation 3282, loss: 1.2103195190429688\n",
            "epoch: 1, iteratation 3283, loss: 1.3077725172042847\n",
            "epoch: 1, iteratation 3284, loss: 1.287766933441162\n",
            "epoch: 1, iteratation 3285, loss: 1.4448617696762085\n",
            "epoch: 1, iteratation 3286, loss: 1.5122150182724\n",
            "epoch: 1, iteratation 3287, loss: 1.337517261505127\n",
            "epoch: 1, iteratation 3288, loss: 1.4268085956573486\n",
            "epoch: 1, iteratation 3289, loss: 1.4423553943634033\n",
            "epoch: 1, iteratation 3290, loss: 1.4671138525009155\n",
            "epoch: 1, iteratation 3291, loss: 1.3391525745391846\n",
            "epoch: 1, iteratation 3292, loss: 1.3193820714950562\n",
            "epoch: 1, iteratation 3293, loss: 1.3759993314743042\n",
            "epoch: 1, iteratation 3294, loss: 1.5735054016113281\n",
            "epoch: 1, iteratation 3295, loss: 1.4975042343139648\n",
            "epoch: 1, iteratation 3296, loss: 1.4017465114593506\n",
            "epoch: 1, iteratation 3297, loss: 1.3939406871795654\n",
            "epoch: 1, iteratation 3298, loss: 1.4133169651031494\n",
            "epoch: 1, iteratation 3299, loss: 1.4254579544067383\n",
            "epoch: 1, iteratation 3300, loss: 1.5150933265686035\n",
            "epoch: 1, iteratation 3301, loss: 1.5157451629638672\n",
            "epoch: 1, iteratation 3302, loss: 1.4523677825927734\n",
            "epoch: 1, iteratation 3303, loss: 1.4643278121948242\n",
            "epoch: 1, iteratation 3304, loss: 1.2798622846603394\n",
            "epoch: 1, iteratation 3305, loss: 1.486975073814392\n",
            "epoch: 1, iteratation 3306, loss: 1.4228112697601318\n",
            "epoch: 1, iteratation 3307, loss: 1.473330020904541\n",
            "epoch: 1, iteratation 3308, loss: 1.5024926662445068\n",
            "epoch: 1, iteratation 3309, loss: 1.366684913635254\n",
            "epoch: 1, iteratation 3310, loss: 1.644640326499939\n",
            "epoch: 1, iteratation 3311, loss: 1.558079719543457\n",
            "epoch: 1, iteratation 3312, loss: 1.4186489582061768\n",
            "epoch: 1, iteratation 3313, loss: 1.3578386306762695\n",
            "epoch: 1, iteratation 3314, loss: 1.7320144176483154\n",
            "epoch: 1, iteratation 3315, loss: 1.470367431640625\n",
            "epoch: 1, iteratation 3316, loss: 1.4680389165878296\n",
            "epoch: 1, iteratation 3317, loss: 1.3284275531768799\n",
            "epoch: 1, iteratation 3318, loss: 1.6144412755966187\n",
            "epoch: 1, iteratation 3319, loss: 1.480034589767456\n",
            "epoch: 1, iteratation 3320, loss: 1.343402624130249\n",
            "epoch: 1, iteratation 3321, loss: 1.441083312034607\n",
            "epoch: 1, iteratation 3322, loss: 1.2668312788009644\n",
            "epoch: 1, iteratation 3323, loss: 1.4580715894699097\n",
            "epoch: 1, iteratation 3324, loss: 1.3794646263122559\n",
            "epoch: 1, iteratation 3325, loss: 1.4465898275375366\n",
            "epoch: 1, iteratation 3326, loss: 1.8781464099884033\n",
            "epoch: 1, iteratation 3327, loss: 1.5394266843795776\n",
            "epoch: 1, iteratation 3328, loss: 1.6262056827545166\n",
            "epoch: 1, iteratation 3329, loss: 1.5254544019699097\n",
            "epoch: 1, iteratation 3330, loss: 1.4871810674667358\n",
            "epoch: 1, iteratation 3331, loss: 1.4619815349578857\n",
            "epoch: 1, iteratation 3332, loss: 1.3651444911956787\n",
            "epoch: 1, iteratation 3333, loss: 1.590566635131836\n",
            "epoch: 1, iteratation 3334, loss: 1.4100770950317383\n",
            "epoch: 1, iteratation 3335, loss: 1.3572580814361572\n",
            "epoch: 1, iteratation 3336, loss: 1.3857386112213135\n",
            "epoch: 1, iteratation 3337, loss: 1.4556710720062256\n",
            "epoch: 1, iteratation 3338, loss: 1.545222282409668\n",
            "epoch: 1, iteratation 3339, loss: 1.3241328001022339\n",
            "epoch: 1, iteratation 3340, loss: 1.4227298498153687\n",
            "epoch: 1, iteratation 3341, loss: 1.282184362411499\n",
            "epoch: 1, iteratation 3342, loss: 1.547742247581482\n",
            "epoch: 1, iteratation 3343, loss: 1.6434125900268555\n",
            "epoch: 1, iteratation 3344, loss: 1.6548250913619995\n",
            "epoch: 1, iteratation 3345, loss: 1.6240730285644531\n",
            "epoch: 1, iteratation 3346, loss: 1.575823187828064\n",
            "epoch: 1, iteratation 3347, loss: 1.5081781148910522\n",
            "epoch: 1, iteratation 3348, loss: 1.4449224472045898\n",
            "epoch: 1, iteratation 3349, loss: 1.6271347999572754\n",
            "epoch: 1, iteratation 3350, loss: 1.3825478553771973\n",
            "epoch: 1, iteratation 3351, loss: 1.5458929538726807\n",
            "epoch: 1, iteratation 3352, loss: 1.4364250898361206\n",
            "epoch: 1, iteratation 3353, loss: 1.4689128398895264\n",
            "epoch: 1, iteratation 3354, loss: 1.4058316946029663\n",
            "epoch: 1, iteratation 3355, loss: 1.503542423248291\n",
            "epoch: 1, iteratation 3356, loss: 1.3075528144836426\n",
            "epoch: 1, iteratation 3357, loss: 1.3695437908172607\n",
            "epoch: 1, iteratation 3358, loss: 1.6287983655929565\n",
            "epoch: 1, iteratation 3359, loss: 1.3993117809295654\n",
            "epoch: 1, iteratation 3360, loss: 1.4116662740707397\n",
            "epoch: 1, iteratation 3361, loss: 1.3765361309051514\n",
            "epoch: 1, iteratation 3362, loss: 1.4486674070358276\n",
            "epoch: 1, iteratation 3363, loss: 1.4783519506454468\n",
            "epoch: 1, iteratation 3364, loss: 1.3755468130111694\n",
            "epoch: 1, iteratation 3365, loss: 1.6062660217285156\n",
            "epoch: 1, iteratation 3366, loss: 1.3105568885803223\n",
            "epoch: 1, iteratation 3367, loss: 1.4987812042236328\n",
            "epoch: 1, iteratation 3368, loss: 1.3584978580474854\n",
            "epoch: 1, iteratation 3369, loss: 1.3389976024627686\n",
            "epoch: 1, iteratation 3370, loss: 1.4655349254608154\n",
            "epoch: 1, iteratation 3371, loss: 1.3099035024642944\n",
            "epoch: 1, iteratation 3372, loss: 1.3587753772735596\n",
            "epoch: 1, iteratation 3373, loss: 1.5095365047454834\n",
            "epoch: 1, iteratation 3374, loss: 1.3559787273406982\n",
            "epoch: 1, iteratation 3375, loss: 1.4427083730697632\n",
            "epoch: 1, iteratation 3376, loss: 1.3781704902648926\n",
            "epoch: 1, iteratation 3377, loss: 1.4689702987670898\n",
            "epoch: 1, iteratation 3378, loss: 1.586601734161377\n",
            "epoch: 1, iteratation 3379, loss: 1.4060282707214355\n",
            "epoch: 1, iteratation 3380, loss: 1.3471629619598389\n",
            "epoch: 1, iteratation 3381, loss: 1.5252196788787842\n",
            "epoch: 1, iteratation 3382, loss: 1.242189645767212\n",
            "epoch: 1, iteratation 3383, loss: 1.3917295932769775\n",
            "epoch: 1, iteratation 3384, loss: 1.4507441520690918\n",
            "epoch: 1, iteratation 3385, loss: 1.6920924186706543\n",
            "epoch: 1, iteratation 3386, loss: 1.3577250242233276\n",
            "epoch: 1, iteratation 3387, loss: 1.4222205877304077\n",
            "epoch: 1, iteratation 3388, loss: 1.6946616172790527\n",
            "epoch: 1, iteratation 3389, loss: 1.4479320049285889\n",
            "epoch: 1, iteratation 3390, loss: 1.4634175300598145\n",
            "epoch: 1, iteratation 3391, loss: 1.476662039756775\n",
            "epoch: 1, iteratation 3392, loss: 1.339655876159668\n",
            "epoch: 1, iteratation 3393, loss: 1.502939224243164\n",
            "epoch: 1, iteratation 3394, loss: 1.3381257057189941\n",
            "epoch: 1, iteratation 3395, loss: 1.300916314125061\n",
            "epoch: 1, iteratation 3396, loss: 1.4342563152313232\n",
            "epoch: 1, iteratation 3397, loss: 1.314239740371704\n",
            "epoch: 1, iteratation 3398, loss: 1.1336183547973633\n",
            "epoch: 1, iteratation 3399, loss: 1.3079872131347656\n",
            "epoch: 1, iteratation 3400, loss: 1.4187434911727905\n",
            "epoch: 1, iteratation 3401, loss: 1.543447494506836\n",
            "epoch: 1, iteratation 3402, loss: 1.5614961385726929\n",
            "epoch: 1, iteratation 3403, loss: 1.3770923614501953\n",
            "epoch: 1, iteratation 3404, loss: 1.4024651050567627\n",
            "epoch: 1, iteratation 3405, loss: 1.3970112800598145\n",
            "epoch: 1, iteratation 3406, loss: 1.5479629039764404\n",
            "epoch: 1, iteratation 3407, loss: 1.4135863780975342\n",
            "epoch: 1, iteratation 3408, loss: 1.3341014385223389\n",
            "epoch: 1, iteratation 3409, loss: 1.4928315877914429\n",
            "epoch: 1, iteratation 3410, loss: 1.5391449928283691\n",
            "epoch: 1, iteratation 3411, loss: 1.4456031322479248\n",
            "epoch: 1, iteratation 3412, loss: 1.3702844381332397\n",
            "epoch: 1, iteratation 3413, loss: 1.4409278631210327\n",
            "epoch: 1, iteratation 3414, loss: 1.503247618675232\n",
            "epoch: 1, iteratation 3415, loss: 1.4071754217147827\n",
            "epoch: 1, iteratation 3416, loss: 1.3440465927124023\n",
            "epoch: 1, iteratation 3417, loss: 1.2709678411483765\n",
            "epoch: 1, iteratation 3418, loss: 1.3780169486999512\n",
            "epoch: 1, iteratation 3419, loss: 1.3713595867156982\n",
            "epoch: 1, iteratation 3420, loss: 1.6143848896026611\n",
            "epoch: 1, iteratation 3421, loss: 1.5337879657745361\n",
            "epoch: 1, iteratation 3422, loss: 1.4548949003219604\n",
            "epoch: 1, iteratation 3423, loss: 1.386932134628296\n",
            "epoch: 1, iteratation 3424, loss: 1.5058587789535522\n",
            "epoch: 1, iteratation 3425, loss: 1.3732928037643433\n",
            "epoch: 1, iteratation 3426, loss: 1.6636264324188232\n",
            "epoch: 1, iteratation 3427, loss: 1.5201352834701538\n",
            "epoch: 1, iteratation 3428, loss: 1.3324835300445557\n",
            "epoch: 1, iteratation 3429, loss: 1.418803095817566\n",
            "epoch: 1, iteratation 3430, loss: 1.4739784002304077\n",
            "epoch: 1, iteratation 3431, loss: 1.3308491706848145\n",
            "epoch: 1, iteratation 3432, loss: 1.187680721282959\n",
            "epoch: 1, iteratation 3433, loss: 1.4286617040634155\n",
            "epoch: 1, iteratation 3434, loss: 1.4075944423675537\n",
            "epoch: 1, iteratation 3435, loss: 1.2119386196136475\n",
            "epoch: 1, iteratation 3436, loss: 1.8079307079315186\n",
            "epoch: 1, iteratation 3437, loss: 1.5856444835662842\n",
            "epoch: 1, iteratation 3438, loss: 1.7428773641586304\n",
            "epoch: 1, iteratation 3439, loss: 1.526845932006836\n",
            "epoch: 1, iteratation 3440, loss: 1.4735244512557983\n",
            "epoch: 1, iteratation 3441, loss: 1.4457134008407593\n",
            "epoch: 1, iteratation 3442, loss: 1.339037299156189\n",
            "epoch: 1, iteratation 3443, loss: 1.3282768726348877\n",
            "epoch: 1, iteratation 3444, loss: 1.3404210805892944\n",
            "epoch: 1, iteratation 3445, loss: 1.3952527046203613\n",
            "epoch: 1, iteratation 3446, loss: 1.5006388425827026\n",
            "epoch: 1, iteratation 3447, loss: 1.2889631986618042\n",
            "epoch: 1, iteratation 3448, loss: 1.4316377639770508\n",
            "epoch: 1, iteratation 3449, loss: 1.4493119716644287\n",
            "epoch: 1, iteratation 3450, loss: 1.601449966430664\n",
            "epoch: 1, iteratation 3451, loss: 1.563158392906189\n",
            "epoch: 1, iteratation 3452, loss: 1.5230534076690674\n",
            "epoch: 1, iteratation 3453, loss: 1.3347234725952148\n",
            "epoch: 1, iteratation 3454, loss: 1.5124629735946655\n",
            "epoch: 1, iteratation 3455, loss: 1.3585208654403687\n",
            "epoch: 1, iteratation 3456, loss: 1.4155311584472656\n",
            "epoch: 1, iteratation 3457, loss: 1.457292079925537\n",
            "epoch: 1, iteratation 3458, loss: 1.2067649364471436\n",
            "epoch: 1, iteratation 3459, loss: 1.3247716426849365\n",
            "epoch: 1, iteratation 3460, loss: 1.1997501850128174\n",
            "epoch: 1, iteratation 3461, loss: 1.3120050430297852\n",
            "epoch: 1, iteratation 3462, loss: 1.3783005475997925\n",
            "epoch: 1, iteratation 3463, loss: 1.5047719478607178\n",
            "epoch: 1, iteratation 3464, loss: 1.3555700778961182\n",
            "epoch: 1, iteratation 3465, loss: 1.4306552410125732\n",
            "epoch: 1, iteratation 3466, loss: 1.4140205383300781\n",
            "epoch: 1, iteratation 3467, loss: 1.534111738204956\n",
            "epoch: 1, iteratation 3468, loss: 1.7085864543914795\n",
            "epoch: 1, iteratation 3469, loss: 1.4638222455978394\n",
            "epoch: 1, iteratation 3470, loss: 1.2886277437210083\n",
            "epoch: 1, iteratation 3471, loss: 1.4666965007781982\n",
            "epoch: 1, iteratation 3472, loss: 1.3105504512786865\n",
            "epoch: 1, iteratation 3473, loss: 1.4133846759796143\n",
            "epoch: 1, iteratation 3474, loss: 1.334282636642456\n",
            "epoch: 1, iteratation 3475, loss: 1.3729887008666992\n",
            "epoch: 1, iteratation 3476, loss: 1.5008505582809448\n",
            "epoch: 1, iteratation 3477, loss: 1.4559153318405151\n",
            "epoch: 1, iteratation 3478, loss: 1.4834070205688477\n",
            "epoch: 1, iteratation 3479, loss: 1.3994286060333252\n",
            "epoch: 1, iteratation 3480, loss: 1.5847457647323608\n",
            "epoch: 1, iteratation 3481, loss: 1.509459376335144\n",
            "epoch: 1, iteratation 3482, loss: 1.4594062566757202\n",
            "epoch: 1, iteratation 3483, loss: 1.4136378765106201\n",
            "epoch: 1, iteratation 3484, loss: 1.4770679473876953\n",
            "epoch: 1, iteratation 3485, loss: 1.4234079122543335\n",
            "epoch: 1, iteratation 3486, loss: 1.376704454421997\n",
            "epoch: 1, iteratation 3487, loss: 1.2727043628692627\n",
            "epoch: 1, iteratation 3488, loss: 1.370842695236206\n",
            "epoch: 1, iteratation 3489, loss: 1.5814884901046753\n",
            "epoch: 1, iteratation 3490, loss: 1.5915673971176147\n",
            "epoch: 1, iteratation 3491, loss: 1.3121083974838257\n",
            "epoch: 1, iteratation 3492, loss: 1.3526678085327148\n",
            "epoch: 1, iteratation 3493, loss: 1.3137930631637573\n",
            "epoch: 1, iteratation 3494, loss: 1.5516550540924072\n",
            "epoch: 1, iteratation 3495, loss: 1.5926332473754883\n",
            "epoch: 1, iteratation 3496, loss: 1.4145748615264893\n",
            "epoch: 1, iteratation 3497, loss: 1.4147199392318726\n",
            "epoch: 1, iteratation 3498, loss: 1.4443734884262085\n",
            "epoch: 1, iteratation 3499, loss: 1.5041861534118652\n",
            "epoch: 1, iteratation 3500, loss: 1.3841593265533447\n",
            "epoch: 1, iteratation 3501, loss: 1.4381749629974365\n",
            "epoch: 1, iteratation 3502, loss: 1.4372180700302124\n",
            "epoch: 1, iteratation 3503, loss: 1.3981927633285522\n",
            "epoch: 1, iteratation 3504, loss: 1.3516000509262085\n",
            "epoch: 1, iteratation 3505, loss: 1.5335344076156616\n",
            "epoch: 1, iteratation 3506, loss: 1.356799840927124\n",
            "epoch: 1, iteratation 3507, loss: 1.363472819328308\n",
            "epoch: 1, iteratation 3508, loss: 1.3536760807037354\n",
            "epoch: 1, iteratation 3509, loss: 1.2581886053085327\n",
            "epoch: 1, iteratation 3510, loss: 1.3577426671981812\n",
            "epoch: 1, iteratation 3511, loss: 1.5261796712875366\n",
            "epoch: 1, iteratation 3512, loss: 1.2710682153701782\n",
            "epoch: 1, iteratation 3513, loss: 1.3366479873657227\n",
            "epoch: 1, iteratation 3514, loss: 1.4081023931503296\n",
            "epoch: 1, iteratation 3515, loss: 1.3363755941390991\n",
            "epoch: 1, iteratation 3516, loss: 1.418697714805603\n",
            "epoch: 1, iteratation 3517, loss: 1.4168426990509033\n",
            "epoch: 1, iteratation 3518, loss: 1.4796570539474487\n",
            "epoch: 1, iteratation 3519, loss: 1.4803667068481445\n",
            "epoch: 1, iteratation 3520, loss: 1.3713741302490234\n",
            "epoch: 1, iteratation 3521, loss: 1.2954920530319214\n",
            "epoch: 1, iteratation 3522, loss: 1.3107677698135376\n",
            "epoch: 1, iteratation 3523, loss: 1.444331169128418\n",
            "epoch: 1, iteratation 3524, loss: 1.4311742782592773\n",
            "epoch: 1, iteratation 3525, loss: 1.3075865507125854\n",
            "epoch: 1, iteratation 3526, loss: 1.5327280759811401\n",
            "epoch: 1, iteratation 3527, loss: 1.3127344846725464\n",
            "epoch: 1, iteratation 3528, loss: 1.5372350215911865\n",
            "epoch: 1, iteratation 3529, loss: 1.4815213680267334\n",
            "epoch: 1, iteratation 3530, loss: 1.434406042098999\n",
            "epoch: 1, iteratation 3531, loss: 1.3443081378936768\n",
            "epoch: 1, iteratation 3532, loss: 1.4390802383422852\n",
            "epoch: 1, iteratation 3533, loss: 1.3633931875228882\n",
            "epoch: 1, iteratation 3534, loss: 1.2894467115402222\n",
            "epoch: 1, iteratation 3535, loss: 1.5559444427490234\n",
            "epoch: 1, iteratation 3536, loss: 1.3222815990447998\n",
            "epoch: 1, iteratation 3537, loss: 1.294668197631836\n",
            "epoch: 1, iteratation 3538, loss: 1.5032638311386108\n",
            "epoch: 1, iteratation 3539, loss: 1.4024900197982788\n",
            "epoch: 1, iteratation 3540, loss: 1.2383482456207275\n",
            "epoch: 1, iteratation 3541, loss: 1.4070873260498047\n",
            "epoch: 1, iteratation 3542, loss: 1.236188292503357\n",
            "epoch: 1, iteratation 3543, loss: 1.3885471820831299\n",
            "epoch: 1, iteratation 3544, loss: 1.3986324071884155\n",
            "epoch: 1, iteratation 3545, loss: 1.5093822479248047\n",
            "epoch: 1, iteratation 3546, loss: 1.7500938177108765\n",
            "epoch: 1, iteratation 3547, loss: 1.516880750656128\n",
            "epoch: 1, iteratation 3548, loss: 1.4164321422576904\n",
            "epoch: 1, iteratation 3549, loss: 1.389343023300171\n",
            "epoch: 1, iteratation 3550, loss: 1.3236441612243652\n",
            "epoch: 1, iteratation 3551, loss: 1.4104608297348022\n",
            "epoch: 1, iteratation 3552, loss: 1.2441686391830444\n",
            "epoch: 1, iteratation 3553, loss: 1.193192720413208\n",
            "epoch: 1, iteratation 3554, loss: 1.4097588062286377\n",
            "epoch: 1, iteratation 3555, loss: 1.5246117115020752\n",
            "epoch: 1, iteratation 3556, loss: 1.6853599548339844\n",
            "epoch: 1, iteratation 3557, loss: 1.323940634727478\n",
            "epoch: 1, iteratation 3558, loss: 1.3557956218719482\n",
            "epoch: 1, iteratation 3559, loss: 1.343837022781372\n",
            "epoch: 1, iteratation 3560, loss: 1.2045987844467163\n",
            "epoch: 1, iteratation 3561, loss: 1.2599085569381714\n",
            "epoch: 1, iteratation 3562, loss: 1.3896112442016602\n",
            "epoch: 1, iteratation 3563, loss: 1.4229421615600586\n",
            "epoch: 1, iteratation 3564, loss: 1.5022401809692383\n",
            "epoch: 1, iteratation 3565, loss: 1.3874648809432983\n",
            "epoch: 1, iteratation 3566, loss: 1.436202049255371\n",
            "epoch: 1, iteratation 3567, loss: 1.2570990324020386\n",
            "epoch: 1, iteratation 3568, loss: 1.1353490352630615\n",
            "epoch: 1, iteratation 3569, loss: 1.1881322860717773\n",
            "epoch: 1, iteratation 3570, loss: 1.4323511123657227\n",
            "epoch: 1, iteratation 3571, loss: 1.3722553253173828\n",
            "epoch: 1, iteratation 3572, loss: 1.46897554397583\n",
            "epoch: 1, iteratation 3573, loss: 1.446722388267517\n",
            "epoch: 1, iteratation 3574, loss: 1.3761329650878906\n",
            "epoch: 1, iteratation 3575, loss: 1.3229941129684448\n",
            "epoch: 1, iteratation 3576, loss: 1.307112455368042\n",
            "epoch: 1, iteratation 3577, loss: 1.328935146331787\n",
            "epoch: 1, iteratation 3578, loss: 1.3857688903808594\n",
            "epoch: 1, iteratation 3579, loss: 1.3594727516174316\n",
            "epoch: 1, iteratation 3580, loss: 1.4884699583053589\n",
            "epoch: 1, iteratation 3581, loss: 1.4137367010116577\n",
            "epoch: 1, iteratation 3582, loss: 1.325608253479004\n",
            "epoch: 1, iteratation 3583, loss: 1.1422613859176636\n",
            "epoch: 1, iteratation 3584, loss: 1.4997400045394897\n",
            "epoch: 1, iteratation 3585, loss: 1.3287622928619385\n",
            "epoch: 1, iteratation 3586, loss: 1.4055182933807373\n",
            "epoch: 1, iteratation 3587, loss: 1.5953021049499512\n",
            "epoch: 1, iteratation 3588, loss: 1.5160850286483765\n",
            "epoch: 1, iteratation 3589, loss: 1.3967807292938232\n",
            "epoch: 1, iteratation 3590, loss: 1.728947639465332\n",
            "epoch: 1, iteratation 3591, loss: 1.6034736633300781\n",
            "epoch: 1, iteratation 3592, loss: 1.3217538595199585\n",
            "epoch: 1, iteratation 3593, loss: 1.3076701164245605\n",
            "epoch: 1, iteratation 3594, loss: 1.4763214588165283\n",
            "epoch: 1, iteratation 3595, loss: 1.4241633415222168\n",
            "epoch: 1, iteratation 3596, loss: 1.3482449054718018\n",
            "epoch: 1, iteratation 3597, loss: 1.4798247814178467\n",
            "epoch: 1, iteratation 3598, loss: 1.40488600730896\n",
            "epoch: 1, iteratation 3599, loss: 1.3158648014068604\n",
            "epoch: 1, iteratation 3600, loss: 1.5345087051391602\n",
            "epoch: 1, iteratation 3601, loss: 1.3936452865600586\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-23d2c41c3802>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch: {j+1}, iteratation {i}, loss: {loss.item()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer setup\n",
        "gpt_encoder = tiktoken.get_encoding('gpt2')\n",
        "tokens = gpt_encoder.encode(\"تم اليوم\")\n",
        "tokens = torch.tensor(tokens, dtype=torch.long).unsqueeze(0)\n",
        "tokens = tokens.repeat(Batch_size, 1)\n",
        "\n",
        "# Sampling loop\n",
        "sample_rng = torch.Generator(device=get_device())\n",
        "sample_rng.manual_seed(42)\n",
        "\n",
        "while tokens.size(1) < Block_size:\n",
        "    with torch.no_grad():\n",
        "        tokens = tokens.to(get_device())\n",
        "        logits, _ = model(tokens)\n",
        "        logits = logits[:, -1, :]\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
        "        ix = torch.multinomial(topk_probs, 1, generator=sample_rng).to(get_device())\n",
        "        xcol = torch.gather(topk_indices, -1, ix)\n",
        "        tokens = torch.cat((tokens, xcol), dim=1)\n",
        "\n",
        "# Decode and print generated sequences\n",
        "generated_text = ''\n",
        "for i in range(Batch_size):\n",
        "    generated_tokens = tokens[i, :].tolist()\n",
        "    generated_text = gpt_encoder.decode(generated_tokens)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJqnbddRwdCe",
        "outputId": "ce12a441-1538-4d8b-d5ef-2c6ae5008cb8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تم اليومياناتون للمنتخبات السابعة على الملاعبين، الجدارة الامريكية دفيلل اموندين في التأخر التنس خلال الأولمبيات المحفظة الى منصبه في تاريخه، والمفارقة في مطلع الجامايكه للغاية على بداية الإنجليزية السبت في اتلتيكو مدريد الجماعية مع الأرجنتيني الميزاي، ويأمل جديد الفتار من خلرا منحانا الاوقت من هزت الجار والحسن في المستعلين. واعتبر موصلة مدينة أعلن على انقل ان جاكسه في مدينة بلماية المستوى مدة 8 مرات انها انجلترا. وأشاد شجار الاعتباؤ اللقاء والحر هو تقيدها اللعب بالوالدة الى البلاحلية التي انفرد فعلت الكرة المتزايد بالمك منذ بدرات للا\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Slfb7-lXaomF",
        "outputId": "b15b8b39-2134-40e7-b08c-22d6e5a4d904"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'drive/MyDrive/model_weights.pth')"
      ],
      "metadata": {
        "id": "bpGKHlO7aSmG"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}